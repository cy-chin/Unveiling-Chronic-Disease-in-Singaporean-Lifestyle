{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 4 - Unveiling Chronic Disease in Singaporean Lifestyle\n",
    "\n",
    "> Authors: Chung Yau, Gilbert, Han Kiong, Zheng Gang\n",
    "---\n",
    "\n",
    "**Problem Statement:**  \n",
    "In Singapore, the increasing prevalence of chronic diseases presents a pressing public health concern, underscoring the need for proactive intervention strategies. \n",
    "\n",
    "How can we identify individuals at high risk for chronic diseases based on their behavioral habits? By doing so, we can enable early detection and provide recommendations, fostering a proactive approach to preventing various chronic diseases.\n",
    "\n",
    "  \n",
    "**Target Audience:**  \n",
    "Product team in Synapxe, in preparation for Healthier SG 2025 roadmap workshop. \n",
    "\n",
    "These are the notebooks for this project:  \n",
    " 1. `01_Data_Collection_Food.ipynb`  \n",
    " 2. `02_Data_Preprocessing.ipynb`   \n",
    " 3. `03_FeatureEngineering_and_EDA.ipynb`\n",
    " 4. `04_Data_Modelling.ipynb` \n",
    " 5. `05_Hyperparameter_Model Fitting_Evaluation.ipynb`\n",
    " 6. `05a_Model_Pickling.ipynb`\n",
    " 7. `06_Implementation_FoodRecommender.ipynb` \n",
    "\n",
    " ---\n",
    "\n",
    "# This Notebook: 04 Data Modelling\n",
    "- We will evaluate the various models in searching for the baseline model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the suitable baseline models, we first consider the interpretability and performance of the models as seen in the graph. Interpretability refers to the ease with which a model's predictions can be understood and explained while performance relates to whether the model can effectively captures patterns in the data and generalizes well to new instances.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"../assets/interpretability-vs-performance-trade-off.png\" style=\"height: 500px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below compares the pros and cons of the different classification models:\n",
    "\n",
    "| Classification Method           | Pros                                     | Cons                                                       | Usage Suggestions                                                                                                                  |\n",
    "|--------------------------------|------------------------------------------|------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Logistic Regression             | - Interpretable coefficients             | - Assumes linear relationship                             | Use for straightforward interpretation of how each feature influences the risk of chronic diseases. Suitable for cases where linear relationships between features and outcome are plausible. |\n",
    "| Decision Trees                  | - Easy to interpret and visualize       | - Prone to overfitting                                    | Use for initial exploration of feature importance and identification of relevant predictors. Prune the tree to prevent overfitting. Suitable for both numerical and categorical data. |\n",
    "| Random Forest                   | - Reduces overfitting                   | - Less interpretable than Decision Trees                  | Use for improved generalization by combining multiple decision trees. Utilize feature importance measures to understand which lifestyle factors contribute most to the risk of chronic diseases. Suitable for large datasets. |\n",
    "| Extra Trees                     | - Reduces variance further              | - Sacrifices interpretability for improved performance   | Use for faster training and potentially better performance compared to Random Forest. Particularly useful when computational resources are limited, and interpretability is not the primary concern. |\n",
    "| Support Vector Machines (SVM)   | - Effective in high-dimensional spaces | - Complexity in choosing the appropriate kernel          | Use for finding optimal hyperplanes to separate high-risk and low-risk individuals. Requires careful selection of hyperparameters and choice of kernel function. Suitable for cases with complex, non-linear relationships. |\n",
    "| k-Nearest Neighbors (k-NN)     | - Simple and intuitive                  | - Sensitive to irrelevant features                        | Use for identifying high-risk individuals based on similarity to other high-risk cases in the dataset. Normalize features and tune the number of neighbors to improve performance. Suitable for small to medium-sized datasets. |\n",
    "| Naive Bayes                     | - Computationally efficient            | - Assumes strong independence between features            | Use for quick classification of high-risk individuals based on conditional probabilities. Suitable for cases with categorical features and where independence assumptions are not severely violated. |\n",
    "| Gradient Boosting Machines (GBM)| - Combines weak learners to improve accuracy | - Can be computationally expensive and prone to overfitting | Use for building a strong predictive model by sequentially correcting errors of weak models. Regularize hyperparameters to prevent overfitting. Suitable for datasets with complex relationships and high predictive accuracy requirements. |\n",
    "| AdaBoost                        | - Sequentially combines weak learners   | - Sensitive to noisy data                                 | Use for iteratively adjusting weights to focus on previously misclassified cases. Prune weak learners to improve generalization. Suitable for ensemble learning when there's a large imbalance between high-risk and low-risk individuals. |\n",
    "| XGBoost                         | - High performance and scalability     | - Less interpretable than simpler models                  | Use for maximizing predictive accuracy and handling large datasets. Tune hyperparameters to balance bias and variance. Suitable for situations where interpretability is less critical compared to predictive power. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After considering the pros and cons in terms of interpretability and performance, we have narrowed to 5 baseline models with a good balance of interpretability and performance. \n",
    "\n",
    "| Classifier                   | Interpretability | Performance | Recommendations                                                                                                                                                                  |\n",
    "|------------------------------|------------------|-------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Logistic Regression          | High             | Moderate    | Suitable for linearly separable data, easy to interpret coefficients, works well with small to medium-sized datasets.                                                  |\n",
    "| Random Forest                | Moderate         | High        | Combines multiple decision trees to reduce overfitting, robust to noise and outliers, suitable for large datasets with high dimensionality.                            |\n",
    "| Support Vector Machines (SVM)| Low              | High        | Effective in high-dimensional spaces, versatile due to different kernel functions, can be memory intensive, suitable for small to medium-sized datasets.            |\n",
    "| Gradient Boosting Machines (GBM)| Low           | High        | Ensemble method that combines weak learners to improve accuracy, less interpretable due to complexity, suitable for various types of data.                            |\n",
    "| XGBoost                      | Low              | High        | Optimized implementation of gradient boosting, often outperforms other algorithms, less interpretable but highly accurate, suitable for large datasets.               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Obtaining cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section involves the following: \n",
    "1. importing the dataset after exploratory data analysis (EDA) is performed\n",
    "2. inspection of the dataframe, checking of null values\n",
    "3. dropping of the '_RACE' column since the dataset has been filtered to include only asian during EDA\n",
    "4. checking for the 'CD' class distribution (1: chronic and 0: not chronic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Importing the dataset after EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = '../data/03_asian_data.csv'\n",
    "\n",
    "df = pd.read_csv(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Quick view of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_attack</th>\n",
       "      <th>stroke</th>\n",
       "      <th>asthma</th>\n",
       "      <th>skin_cancer</th>\n",
       "      <th>other_cancer</th>\n",
       "      <th>cpd_bronchitis</th>\n",
       "      <th>depression</th>\n",
       "      <th>kidney_disease</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>sex</th>\n",
       "      <th>martial</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>blind</th>\n",
       "      <th>diff_walking</th>\n",
       "      <th>occasion_drink_30days</th>\n",
       "      <th>high_bp</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>arthritis</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>education</th>\n",
       "      <th>smoker_status</th>\n",
       "      <th>one_alc_per_day</th>\n",
       "      <th>binge_drink</th>\n",
       "      <th>ave_drink_week</th>\n",
       "      <th>fruit</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>exercise_cat</th>\n",
       "      <th>high_cholesterol</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>173.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.330000e+02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6804.000000</td>\n",
       "      <td>22.733803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>157.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5897.000000</td>\n",
       "      <td>23.923891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>173.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6350.000000</td>\n",
       "      <td>21.216880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>169.36927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8048.087779</td>\n",
       "      <td>28.055853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.170000e+02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7484.000000</td>\n",
       "      <td>23.098765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9072.000000</td>\n",
       "      <td>29.622857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5897.000000</td>\n",
       "      <td>21.660239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4536.000000</td>\n",
       "      <td>19.632964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>168.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6577.000000</td>\n",
       "      <td>23.302863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4445.000000</td>\n",
       "      <td>16.326905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   heart_attack  stroke  asthma  skin_cancer  other_cancer  cpd_bronchitis  \\\n",
       "0             0       0       0            0             0               0   \n",
       "1             0       0       0            0             0               0   \n",
       "2             0       0       0            0             0               0   \n",
       "3             0       0       0            0             0               1   \n",
       "4             0       0       0            0             0               0   \n",
       "5             0       0       0            0             0               0   \n",
       "6             0       0       0            0             0               0   \n",
       "7             0       0       0            0             0               0   \n",
       "8             0       0       0            0             0               0   \n",
       "9             0       0       0            0             0               0   \n",
       "\n",
       "   depression  kidney_disease  diabetes  sex  martial  employment_status  \\\n",
       "0           0               0         0    1        1                  1   \n",
       "1           0               0         0    1        1                  1   \n",
       "2           0               0         0    1        1                  0   \n",
       "3           1               0         0    0        0                  0   \n",
       "4           0               0         0    1        1                  0   \n",
       "5           0               0         0    0        0                  1   \n",
       "6           0               0         1    1        1                  1   \n",
       "7           0               0         0    0        0                  0   \n",
       "8           0               0         0    1        0                  1   \n",
       "9           0               0         0    0        0                  1   \n",
       "\n",
       "   blind  diff_walking  occasion_drink_30days  high_bp  heart_disease  \\\n",
       "0      0             0                      5        0              0   \n",
       "1      0             0                      0        0              0   \n",
       "2      0             0                      0        1              0   \n",
       "3      0             1                      0        1              0   \n",
       "4      0             0                      5        0              0   \n",
       "5      0             0                      1        0              0   \n",
       "6      0             0                      0        0              0   \n",
       "7      0             0                      0        0              0   \n",
       "8      0             0                      0        0              0   \n",
       "9      0             0                      0        0              0   \n",
       "\n",
       "   arthritis  race   age     height  education  smoker_status  \\\n",
       "0          0     4   7.0  173.00000          2              0   \n",
       "1          0     4   3.0  157.00000          1              0   \n",
       "2          0     4  10.0  173.00000          2              0   \n",
       "3          1     4   8.0  169.36927          1              0   \n",
       "4          0     4   9.0  180.00000          2              1   \n",
       "5          0     4   1.0  175.00000          1              0   \n",
       "6          0     4   5.0  165.00000          2              1   \n",
       "7          0     4   1.0  152.00000          1              0   \n",
       "8          0     4   2.0  168.00000          2              0   \n",
       "9          0     4   1.0  165.00000          0              0   \n",
       "\n",
       "   one_alc_per_day  binge_drink  ave_drink_week  fruit  vegetable  \\\n",
       "0                1            0    2.330000e+02      0          0   \n",
       "1                0            0    5.397605e-79      0          0   \n",
       "2                0            0    5.397605e-79      0          1   \n",
       "3                0            0    5.397605e-79      0          0   \n",
       "4                1            0    1.170000e+02      1          1   \n",
       "5                1            0    4.700000e+01      1          1   \n",
       "6                0            0    5.397605e-79      0          1   \n",
       "7                0            0    5.397605e-79      0          0   \n",
       "8                0            0    5.397605e-79      0          1   \n",
       "9                0            0    5.397605e-79      1          1   \n",
       "\n",
       "   exercise_cat  high_cholesterol       weight        BMI  CD  \n",
       "0             2                 1  6804.000000  22.733803   0  \n",
       "1             0                 0  5897.000000  23.923891   0  \n",
       "2             1                 1  6350.000000  21.216880   0  \n",
       "3             1                 1  8048.087779  28.055853   1  \n",
       "4             2                 0  7484.000000  23.098765   0  \n",
       "5             1                 0  9072.000000  29.622857   0  \n",
       "6             0                 1  5897.000000  21.660239   1  \n",
       "7             1                 0  4536.000000  19.632964   0  \n",
       "8             1                 0  6577.000000  23.302863   0  \n",
       "9             2                 0  4445.000000  16.326905   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first 10 rows of the dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16104, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the rows and columns in the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['heart_attack', 'stroke', 'asthma', 'skin_cancer', 'other_cancer',\n",
       "       'cpd_bronchitis', 'depression', 'kidney_disease', 'diabetes', 'sex',\n",
       "       'martial', 'employment_status', 'blind', 'diff_walking',\n",
       "       'occasion_drink_30days', 'high_bp', 'heart_disease', 'arthritis',\n",
       "       'race', 'age', 'height', 'education', 'smoker_status',\n",
       "       'one_alc_per_day', 'binge_drink', 'ave_drink_week', 'fruit',\n",
       "       'vegetable', 'exercise_cat', 'high_cholesterol', 'weight', 'BMI', 'CD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the columns in the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "heart_attack             0\n",
       "stroke                   0\n",
       "asthma                   0\n",
       "skin_cancer              0\n",
       "other_cancer             0\n",
       "cpd_bronchitis           0\n",
       "depression               0\n",
       "kidney_disease           0\n",
       "diabetes                 0\n",
       "sex                      0\n",
       "martial                  0\n",
       "employment_status        0\n",
       "blind                    0\n",
       "diff_walking             0\n",
       "occasion_drink_30days    0\n",
       "high_bp                  0\n",
       "heart_disease            0\n",
       "arthritis                0\n",
       "race                     0\n",
       "age                      0\n",
       "height                   0\n",
       "education                0\n",
       "smoker_status            0\n",
       "one_alc_per_day          0\n",
       "binge_drink              0\n",
       "ave_drink_week           0\n",
       "fruit                    0\n",
       "vegetable                0\n",
       "exercise_cat             0\n",
       "high_cholesterol         0\n",
       "weight                   0\n",
       "BMI                      0\n",
       "CD                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null/nan values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Dropping of '_RACE' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for '_RACE'=4 (Asian)\n",
    "df['race'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this check, there is only 1 unique values in the '_RACE' column and confirms that the dataset has been filtered for asian during the EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop '_RACE' column\n",
    "df.drop(columns=['race'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['heart_attack', 'stroke', 'asthma', 'skin_cancer', 'other_cancer',\n",
       "       'cpd_bronchitis', 'depression', 'kidney_disease', 'diabetes', 'sex',\n",
       "       'martial', 'employment_status', 'blind', 'diff_walking',\n",
       "       'occasion_drink_30days', 'high_bp', 'heart_disease', 'arthritis', 'age',\n",
       "       'height', 'education', 'smoker_status', 'one_alc_per_day',\n",
       "       'binge_drink', 'ave_drink_week', 'fruit', 'vegetable', 'exercise_cat',\n",
       "       'high_cholesterol', 'weight', 'BMI', 'CD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns to ensure '_RACE' has been dropped\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Checking the class distribution in 'CD' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "CD\n",
      "0    10631\n",
      "1     5473\n",
      "Name: count, dtype: int64\n",
      "CD\n",
      "0    66.014655\n",
      "1    33.985345\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# finding the unique values in 'CD' column\n",
    "print(df['CD'].unique())\n",
    "\n",
    "# finding the count and percentage of 1: chronic and 0: not chronic in the 'CD' column\n",
    "print(df['CD'].value_counts())\n",
    "print(df['CD'].value_counts(normalize = True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As seen, the classes are unbalanced with 66.0% for 0 (not chronic) and 34.0% for 1 (chronic).\n",
    "- There are 2 options to balance the classes, namely undersampling or oversampling. \n",
    "- We will try both options and compare the scores for the baseline models based on undersampling and oversampling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Transforming and Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create the models, we will be applying a few tools or techniques to do data preprocessing, feature engineering and dimensionality reduction as follows: \n",
    "\n",
    "1. Class Balancing: \n",
    "- `RandomUnderSampler` aims to balance the class distribution by randomly selecting a subset of instances from the majority class (or classes) such that the resulting dataset is more balanced. The idea is to reduce the number of instances in the majority class to match the number of instances in the minority class, thus creating a more balanced dataset for training the model.\n",
    "- `ADASYN` algorithm aims to balance the class distribution by generating synthetic samples for the minority class (class 1 in your case). However, it doesn't guarantee an exact balance between the classes after resampling. The imbalance might still exist due to the nature of the algorithm and the distribution of instances in the feature space.\n",
    "2. PolynomialFeatures: `PolynomialFeatures` is a preprocessing module that generates polynomial features from the original features useful for capturing non-linear relationships between features. For example, if you have a feature x, PolynomialFeatures can create new features like x^2, x^3, etc.\n",
    "3. StandardScaler: `StandardScaler` is a preprocessing technique used to standardize features by removing the mean and scaling to unit variance. We apply to numerical features to ensure that they have a mean of 0 and a standard deviation of 1. This is important for many machine learning algorithms that assume data is centered and has a consistent scale.\n",
    "4. Principal Component Analysis: `PCA` is a dimensionality reduction technique used to reduce the number of features in a dataset while preserving most of the information. It does this by transforming the original features into a new set of orthogonal (uncorrelated) features called principal components. These principal components are ordered by the amount of variance they explain in the data, allowing you to select a subset of components to represent the data more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Determine the n_component for PCA\n",
    "\n",
    "As we will be generating polynomial features from the original features, we are interested in reducing the dimensions as a result of these additional polynomial features. \n",
    "\n",
    "In order to determine the n_component for PCA, we will perform the following steps:\n",
    "1. Balance our data by undersampling (with RandomUnderSampler) or oversampling (with ADASYN) (undersamping is chosen eventually)\n",
    "2. Polynomial feature the numeric continous columns \n",
    "2. Standardscale our data before applying PCA (to prevent features with high scale from dominating the calculation)\n",
    "2. Instantiate, fit and transform PCA on the scaled training data\n",
    "3. Transform PCA on the test data\n",
    "4. Pull the explained variance attribute (to explain the amount of variance by each of the newly created principal components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data into training and testing sets.\n",
    "# set a custom test size of 20% for model evaluation.\n",
    "columns_to_check = [\n",
    "    'cpd_bronchitis',  \n",
    "    'depression',    \n",
    "    'arthritis',      \n",
    "    'heart_attack',   \n",
    "    'stroke',        \n",
    "    'asthma',       \n",
    "    'diabetes',      \n",
    "    'kidney_disease', \n",
    "    'heart_disease',  \n",
    "    'CD',        \n",
    "    'height',        \n",
    "    'weight'        \n",
    "]\n",
    "\n",
    "X_pca = df.drop(columns=['CD'])\n",
    "y_pca = df['CD']\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y_pca, test_size=0.2, random_state=42, stratify=y_pca)\n",
    "\n",
    "# Apply ADASYN to balance the classes\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "X_train_resampled_p, y_train_resampled_p = rus.fit_resample(X_train_pca, y_train_pca)\n",
    "\n",
    "# Define columns you want to apply polynomial features to\n",
    "poly_cols = [\n",
    "    'occasion_drink_30days', \n",
    "    'BMI',                \n",
    "    'education',          \n",
    "    'smoker_status',       \n",
    "    'exercise_cat',    \n",
    "    'ave_drink_week',     \n",
    "    'age'              \n",
    "]\n",
    "\n",
    "# Create a ColumnTransformer to apply PolynomialFeatures to selected columns\n",
    "poly_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), poly_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through columns not specified for polynomial features\n",
    ")\n",
    "\n",
    "# Fit and transform the resampled data with polynomial features\n",
    "X_train_poly_resampled = poly_transformer.fit_transform(X_train_resampled_p)\n",
    "X_test_poly = poly_transformer.transform(X_test_pca)\n",
    "\n",
    "# Standard scale the resampled data\n",
    "scaler = StandardScaler()\n",
    "X_train_sc_resampled = scaler.fit_transform(X_train_poly_resampled)\n",
    "X_test_sc = scaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.601840</td>\n",
       "      <td>-0.640847</td>\n",
       "      <td>-0.983666</td>\n",
       "      <td>0.026669</td>\n",
       "      <td>0.774594</td>\n",
       "      <td>-1.874834</td>\n",
       "      <td>-0.378492</td>\n",
       "      <td>-1.894257</td>\n",
       "      <td>0.019284</td>\n",
       "      <td>0.283224</td>\n",
       "      <td>-0.151174</td>\n",
       "      <td>-0.254283</td>\n",
       "      <td>-0.106419</td>\n",
       "      <td>0.355358</td>\n",
       "      <td>0.673602</td>\n",
       "      <td>0.830963</td>\n",
       "      <td>0.193680</td>\n",
       "      <td>0.222186</td>\n",
       "      <td>0.116804</td>\n",
       "      <td>0.435427</td>\n",
       "      <td>-0.433507</td>\n",
       "      <td>-0.407057</td>\n",
       "      <td>0.124259</td>\n",
       "      <td>-0.023591</td>\n",
       "      <td>0.390032</td>\n",
       "      <td>-1.717121</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>-0.168488</td>\n",
       "      <td>0.186589</td>\n",
       "      <td>-0.289199</td>\n",
       "      <td>0.368435</td>\n",
       "      <td>0.165026</td>\n",
       "      <td>-0.238586</td>\n",
       "      <td>-0.063236</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.319738</td>\n",
       "      <td>-0.073011</td>\n",
       "      <td>0.093482</td>\n",
       "      <td>-0.054032</td>\n",
       "      <td>0.020647</td>\n",
       "      <td>0.232622</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>-0.030311</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>-0.028131</td>\n",
       "      <td>0.259480</td>\n",
       "      <td>-0.143949</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>-0.038614</td>\n",
       "      <td>-0.004471</td>\n",
       "      <td>0.054296</td>\n",
       "      <td>-0.025513</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>-0.012486</td>\n",
       "      <td>-0.076529</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>0.051977</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>2.088207e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.231852</td>\n",
       "      <td>-2.346142</td>\n",
       "      <td>-0.996811</td>\n",
       "      <td>2.698839</td>\n",
       "      <td>0.405108</td>\n",
       "      <td>0.323427</td>\n",
       "      <td>-0.908849</td>\n",
       "      <td>-0.785838</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.428181</td>\n",
       "      <td>-0.021008</td>\n",
       "      <td>0.215787</td>\n",
       "      <td>-0.019156</td>\n",
       "      <td>-0.287076</td>\n",
       "      <td>-0.056573</td>\n",
       "      <td>0.590981</td>\n",
       "      <td>-0.452951</td>\n",
       "      <td>0.372590</td>\n",
       "      <td>-0.148825</td>\n",
       "      <td>0.257114</td>\n",
       "      <td>-0.093216</td>\n",
       "      <td>0.448759</td>\n",
       "      <td>-0.358268</td>\n",
       "      <td>-0.198548</td>\n",
       "      <td>0.505185</td>\n",
       "      <td>1.422810</td>\n",
       "      <td>-0.149852</td>\n",
       "      <td>-0.427276</td>\n",
       "      <td>-0.339285</td>\n",
       "      <td>-0.067443</td>\n",
       "      <td>0.426936</td>\n",
       "      <td>-0.231448</td>\n",
       "      <td>0.080221</td>\n",
       "      <td>0.037616</td>\n",
       "      <td>0.067108</td>\n",
       "      <td>-0.187752</td>\n",
       "      <td>-0.173375</td>\n",
       "      <td>0.163607</td>\n",
       "      <td>-0.409616</td>\n",
       "      <td>-0.020111</td>\n",
       "      <td>-0.192068</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.040471</td>\n",
       "      <td>0.083877</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>-0.050653</td>\n",
       "      <td>-0.054207</td>\n",
       "      <td>-0.066739</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>0.040304</td>\n",
       "      <td>-0.050093</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>-0.008864</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>-0.006014</td>\n",
       "      <td>6.152584e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.377791</td>\n",
       "      <td>-1.174135</td>\n",
       "      <td>-1.960025</td>\n",
       "      <td>1.842926</td>\n",
       "      <td>-0.784641</td>\n",
       "      <td>-0.450303</td>\n",
       "      <td>0.531102</td>\n",
       "      <td>0.602361</td>\n",
       "      <td>0.563252</td>\n",
       "      <td>0.194218</td>\n",
       "      <td>-1.127771</td>\n",
       "      <td>-0.283244</td>\n",
       "      <td>0.525885</td>\n",
       "      <td>0.398710</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>0.220244</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>-0.015110</td>\n",
       "      <td>0.072242</td>\n",
       "      <td>0.231779</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.461692</td>\n",
       "      <td>0.245807</td>\n",
       "      <td>1.072430</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>-1.267783</td>\n",
       "      <td>0.807717</td>\n",
       "      <td>0.357322</td>\n",
       "      <td>0.353899</td>\n",
       "      <td>-0.155698</td>\n",
       "      <td>-0.270258</td>\n",
       "      <td>0.071122</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.122814</td>\n",
       "      <td>0.102884</td>\n",
       "      <td>-0.045922</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>-0.107396</td>\n",
       "      <td>0.074456</td>\n",
       "      <td>-0.009381</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>-0.138601</td>\n",
       "      <td>-0.048610</td>\n",
       "      <td>-0.071922</td>\n",
       "      <td>-0.141192</td>\n",
       "      <td>-0.021444</td>\n",
       "      <td>0.175808</td>\n",
       "      <td>0.035646</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.043521</td>\n",
       "      <td>-0.003171</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>-0.088369</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>4.694717e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.123105</td>\n",
       "      <td>2.529432</td>\n",
       "      <td>1.755920</td>\n",
       "      <td>-2.939549</td>\n",
       "      <td>0.265498</td>\n",
       "      <td>-0.689957</td>\n",
       "      <td>0.907990</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>-0.330340</td>\n",
       "      <td>-0.812595</td>\n",
       "      <td>1.154606</td>\n",
       "      <td>0.170770</td>\n",
       "      <td>-0.747311</td>\n",
       "      <td>0.497810</td>\n",
       "      <td>-0.695236</td>\n",
       "      <td>-0.373344</td>\n",
       "      <td>0.062177</td>\n",
       "      <td>0.456499</td>\n",
       "      <td>-0.597408</td>\n",
       "      <td>-0.295702</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>1.085464</td>\n",
       "      <td>-0.158075</td>\n",
       "      <td>0.048308</td>\n",
       "      <td>-1.235012</td>\n",
       "      <td>-0.384014</td>\n",
       "      <td>-2.001023</td>\n",
       "      <td>-1.953641</td>\n",
       "      <td>-0.978375</td>\n",
       "      <td>-0.285097</td>\n",
       "      <td>-0.171234</td>\n",
       "      <td>-0.596076</td>\n",
       "      <td>0.469973</td>\n",
       "      <td>-0.023008</td>\n",
       "      <td>0.404738</td>\n",
       "      <td>-0.600903</td>\n",
       "      <td>0.115645</td>\n",
       "      <td>0.130373</td>\n",
       "      <td>-0.214514</td>\n",
       "      <td>0.107131</td>\n",
       "      <td>0.154791</td>\n",
       "      <td>0.225228</td>\n",
       "      <td>-0.193171</td>\n",
       "      <td>0.108287</td>\n",
       "      <td>-0.257320</td>\n",
       "      <td>-0.192196</td>\n",
       "      <td>0.128299</td>\n",
       "      <td>-0.086849</td>\n",
       "      <td>0.101524</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>-0.020154</td>\n",
       "      <td>0.017666</td>\n",
       "      <td>0.056740</td>\n",
       "      <td>0.095671</td>\n",
       "      <td>0.066224</td>\n",
       "      <td>-0.012885</td>\n",
       "      <td>0.069428</td>\n",
       "      <td>0.017746</td>\n",
       "      <td>-0.011683</td>\n",
       "      <td>1.105160e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.761358</td>\n",
       "      <td>-2.251735</td>\n",
       "      <td>0.878684</td>\n",
       "      <td>1.131911</td>\n",
       "      <td>-2.250111</td>\n",
       "      <td>1.961381</td>\n",
       "      <td>0.142625</td>\n",
       "      <td>0.443099</td>\n",
       "      <td>0.465713</td>\n",
       "      <td>0.240151</td>\n",
       "      <td>-0.402122</td>\n",
       "      <td>-0.209633</td>\n",
       "      <td>0.672818</td>\n",
       "      <td>0.616404</td>\n",
       "      <td>-0.213678</td>\n",
       "      <td>-0.430959</td>\n",
       "      <td>0.423286</td>\n",
       "      <td>-0.131839</td>\n",
       "      <td>-0.260334</td>\n",
       "      <td>-0.466644</td>\n",
       "      <td>-0.002420</td>\n",
       "      <td>0.309171</td>\n",
       "      <td>0.174355</td>\n",
       "      <td>-0.347072</td>\n",
       "      <td>-0.475326</td>\n",
       "      <td>1.145155</td>\n",
       "      <td>-0.563235</td>\n",
       "      <td>0.403334</td>\n",
       "      <td>0.039631</td>\n",
       "      <td>0.509803</td>\n",
       "      <td>-0.554643</td>\n",
       "      <td>-0.384968</td>\n",
       "      <td>0.314884</td>\n",
       "      <td>0.091894</td>\n",
       "      <td>0.058430</td>\n",
       "      <td>-0.265742</td>\n",
       "      <td>0.254026</td>\n",
       "      <td>0.063820</td>\n",
       "      <td>-0.384125</td>\n",
       "      <td>0.219231</td>\n",
       "      <td>0.227178</td>\n",
       "      <td>-0.354058</td>\n",
       "      <td>0.326576</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>-0.028200</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>0.031667</td>\n",
       "      <td>-0.133025</td>\n",
       "      <td>-0.005694</td>\n",
       "      <td>-0.064845</td>\n",
       "      <td>-0.020966</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>0.014850</td>\n",
       "      <td>-0.040136</td>\n",
       "      <td>-0.075612</td>\n",
       "      <td>0.052611</td>\n",
       "      <td>-0.032804</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>-0.001397</td>\n",
       "      <td>1.733881e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.601840 -0.640847 -0.983666  0.026669  0.774594 -1.874834 -0.378492   \n",
       "1  1.231852 -2.346142 -0.996811  2.698839  0.405108  0.323427 -0.908849   \n",
       "2 -1.377791 -1.174135 -1.960025  1.842926 -0.784641 -0.450303  0.531102   \n",
       "3 -2.123105  2.529432  1.755920 -2.939549  0.265498 -0.689957  0.907990   \n",
       "4 -1.761358 -2.251735  0.878684  1.131911 -2.250111  1.961381  0.142625   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -1.894257  0.019284  0.283224 -0.151174 -0.254283 -0.106419  0.355358   \n",
       "1 -0.785838  0.014770  0.428181 -0.021008  0.215787 -0.019156 -0.287076   \n",
       "2  0.602361  0.563252  0.194218 -1.127771 -0.283244  0.525885  0.398710   \n",
       "3  0.016157 -0.330340 -0.812595  1.154606  0.170770 -0.747311  0.497810   \n",
       "4  0.443099  0.465713  0.240151 -0.402122 -0.209633  0.672818  0.616404   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0  0.673602  0.830963  0.193680  0.222186  0.116804  0.435427 -0.433507   \n",
       "1 -0.056573  0.590981 -0.452951  0.372590 -0.148825  0.257114 -0.093216   \n",
       "2  0.196922  0.041428  0.220244  0.014736 -0.015110  0.072242  0.231779   \n",
       "3 -0.695236 -0.373344  0.062177  0.456499 -0.597408 -0.295702  0.331352   \n",
       "4 -0.213678 -0.430959  0.423286 -0.131839 -0.260334 -0.466644 -0.002420   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0 -0.407057  0.124259 -0.023591  0.390032 -1.717121  0.243338 -0.168488   \n",
       "1  0.448759 -0.358268 -0.198548  0.505185  1.422810 -0.149852 -0.427276   \n",
       "2 -0.004365  0.461692  0.245807  1.072430  0.621528 -1.267783  0.807717   \n",
       "3  1.085464 -0.158075  0.048308 -1.235012 -0.384014 -2.001023 -1.953641   \n",
       "4  0.309171  0.174355 -0.347072 -0.475326  1.145155 -0.563235  0.403334   \n",
       "\n",
       "         28        29        30        31        32        33        34  \\\n",
       "0  0.186589 -0.289199  0.368435  0.165026 -0.238586 -0.063236  0.012520   \n",
       "1 -0.339285 -0.067443  0.426936 -0.231448  0.080221  0.037616  0.067108   \n",
       "2  0.357322  0.353899 -0.155698 -0.270258  0.071122  0.002615  0.122814   \n",
       "3 -0.978375 -0.285097 -0.171234 -0.596076  0.469973 -0.023008  0.404738   \n",
       "4  0.039631  0.509803 -0.554643 -0.384968  0.314884  0.091894  0.058430   \n",
       "\n",
       "         35        36        37        38        39        40        41  \\\n",
       "0  0.319738 -0.073011  0.093482 -0.054032  0.020647  0.232622  0.004366   \n",
       "1 -0.187752 -0.173375  0.163607 -0.409616 -0.020111 -0.192068  0.094978   \n",
       "2  0.102884 -0.045922  0.075392 -0.107396  0.074456 -0.009381  0.000629   \n",
       "3 -0.600903  0.115645  0.130373 -0.214514  0.107131  0.154791  0.225228   \n",
       "4 -0.265742  0.254026  0.063820 -0.384125  0.219231  0.227178 -0.354058   \n",
       "\n",
       "         42        43        44        45        46        47        48  \\\n",
       "0 -0.030311  0.005392 -0.028131  0.259480 -0.143949 -0.002596 -0.038614   \n",
       "1  0.006406  0.040471  0.083877 -0.090021  0.014841 -0.050653 -0.054207   \n",
       "2 -0.138601 -0.048610 -0.071922 -0.141192 -0.021444  0.175808  0.035646   \n",
       "3 -0.193171  0.108287 -0.257320 -0.192196  0.128299 -0.086849  0.101524   \n",
       "4  0.326576  0.013438 -0.028200 -0.036865  0.031667 -0.133025 -0.005694   \n",
       "\n",
       "         49        50        51        52        53        54        55  \\\n",
       "0 -0.004471  0.054296 -0.025513  0.008078 -0.012486 -0.076529  0.003102   \n",
       "1 -0.066739 -0.015158  0.040304 -0.050093  0.007385  0.003378  0.008272   \n",
       "2  0.001228  0.043521 -0.003171  0.001530  0.027751  0.024552 -0.088369   \n",
       "3 -0.009368 -0.020154  0.017666  0.056740  0.095671  0.066224 -0.012885   \n",
       "4 -0.064845 -0.020966  0.021561  0.014850 -0.040136 -0.075612  0.052611   \n",
       "\n",
       "         56        57        58            59  \n",
       "0  0.025376  0.051977  0.003774  2.088207e-14  \n",
       "1 -0.008864  0.015461 -0.006014  6.152584e-18  \n",
       "2  0.023391  0.009392  0.010279  4.694717e-18  \n",
       "3  0.069428  0.017746 -0.011683  1.105160e-17  \n",
       "4 -0.032804  0.013523 -0.001397  1.733881e-17  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PCA.\n",
    "pca = PCA(random_state = 42)\n",
    "\n",
    "# Fit and Transform PCA on the scaled training data from X_train_sc to Z_train (PC) features.\n",
    "Z_train = pca.fit_transform(X_train_sc_resampled)\n",
    "\n",
    "# Check out the results in a dataframe.\n",
    "pd.DataFrame(Z_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828254</td>\n",
       "      <td>0.119166</td>\n",
       "      <td>0.135020</td>\n",
       "      <td>3.671401</td>\n",
       "      <td>-1.020140</td>\n",
       "      <td>-1.229569</td>\n",
       "      <td>-0.465638</td>\n",
       "      <td>-0.521695</td>\n",
       "      <td>0.601154</td>\n",
       "      <td>0.176956</td>\n",
       "      <td>-0.309730</td>\n",
       "      <td>0.167770</td>\n",
       "      <td>0.033939</td>\n",
       "      <td>-0.433906</td>\n",
       "      <td>-0.122126</td>\n",
       "      <td>0.656998</td>\n",
       "      <td>-0.132899</td>\n",
       "      <td>0.510841</td>\n",
       "      <td>-0.082842</td>\n",
       "      <td>0.324439</td>\n",
       "      <td>-0.086460</td>\n",
       "      <td>0.445156</td>\n",
       "      <td>-0.453181</td>\n",
       "      <td>0.070990</td>\n",
       "      <td>-0.148505</td>\n",
       "      <td>0.626066</td>\n",
       "      <td>-0.982034</td>\n",
       "      <td>0.712641</td>\n",
       "      <td>-0.010345</td>\n",
       "      <td>0.154753</td>\n",
       "      <td>0.032808</td>\n",
       "      <td>0.807478</td>\n",
       "      <td>-0.971187</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>-0.131402</td>\n",
       "      <td>-0.198993</td>\n",
       "      <td>0.612741</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>-0.333821</td>\n",
       "      <td>0.169366</td>\n",
       "      <td>-0.082504</td>\n",
       "      <td>0.343993</td>\n",
       "      <td>-0.236122</td>\n",
       "      <td>0.226492</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>-0.212631</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.134088</td>\n",
       "      <td>-0.031998</td>\n",
       "      <td>-0.017881</td>\n",
       "      <td>-0.013068</td>\n",
       "      <td>-0.059459</td>\n",
       "      <td>0.073184</td>\n",
       "      <td>0.124520</td>\n",
       "      <td>-0.019338</td>\n",
       "      <td>0.044046</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>-0.029107</td>\n",
       "      <td>-0.008535</td>\n",
       "      <td>2.593443e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.848268</td>\n",
       "      <td>2.326184</td>\n",
       "      <td>5.530766</td>\n",
       "      <td>2.633174</td>\n",
       "      <td>-0.285820</td>\n",
       "      <td>-4.469285</td>\n",
       "      <td>0.478753</td>\n",
       "      <td>0.695374</td>\n",
       "      <td>0.631102</td>\n",
       "      <td>-1.128967</td>\n",
       "      <td>0.924448</td>\n",
       "      <td>-0.418833</td>\n",
       "      <td>-0.186514</td>\n",
       "      <td>-0.751774</td>\n",
       "      <td>-1.689482</td>\n",
       "      <td>0.311650</td>\n",
       "      <td>0.528028</td>\n",
       "      <td>0.534501</td>\n",
       "      <td>-0.031267</td>\n",
       "      <td>0.418879</td>\n",
       "      <td>0.240262</td>\n",
       "      <td>0.273396</td>\n",
       "      <td>-0.261327</td>\n",
       "      <td>0.802925</td>\n",
       "      <td>-0.488801</td>\n",
       "      <td>-0.459396</td>\n",
       "      <td>-0.056920</td>\n",
       "      <td>0.314993</td>\n",
       "      <td>-0.254198</td>\n",
       "      <td>0.637259</td>\n",
       "      <td>0.605876</td>\n",
       "      <td>-2.075718</td>\n",
       "      <td>0.640686</td>\n",
       "      <td>-0.019890</td>\n",
       "      <td>-1.701113</td>\n",
       "      <td>0.871178</td>\n",
       "      <td>1.704187</td>\n",
       "      <td>-0.715255</td>\n",
       "      <td>0.433265</td>\n",
       "      <td>-0.275521</td>\n",
       "      <td>-0.920652</td>\n",
       "      <td>-0.404637</td>\n",
       "      <td>0.234945</td>\n",
       "      <td>0.184116</td>\n",
       "      <td>0.497862</td>\n",
       "      <td>0.269911</td>\n",
       "      <td>-0.118069</td>\n",
       "      <td>0.201996</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>0.045696</td>\n",
       "      <td>-0.034928</td>\n",
       "      <td>-0.085613</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.172408</td>\n",
       "      <td>0.170384</td>\n",
       "      <td>0.277750</td>\n",
       "      <td>0.151340</td>\n",
       "      <td>-0.058419</td>\n",
       "      <td>-0.021100</td>\n",
       "      <td>8.375107e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.960326</td>\n",
       "      <td>1.272612</td>\n",
       "      <td>-2.402175</td>\n",
       "      <td>-1.403092</td>\n",
       "      <td>-3.448164</td>\n",
       "      <td>0.468886</td>\n",
       "      <td>0.814892</td>\n",
       "      <td>0.393272</td>\n",
       "      <td>-0.035223</td>\n",
       "      <td>0.209374</td>\n",
       "      <td>0.125957</td>\n",
       "      <td>0.373020</td>\n",
       "      <td>-0.421528</td>\n",
       "      <td>1.134400</td>\n",
       "      <td>-0.362347</td>\n",
       "      <td>-0.642886</td>\n",
       "      <td>-1.713634</td>\n",
       "      <td>-0.301525</td>\n",
       "      <td>-0.650167</td>\n",
       "      <td>-0.186636</td>\n",
       "      <td>-0.425797</td>\n",
       "      <td>-2.587938</td>\n",
       "      <td>1.291566</td>\n",
       "      <td>0.051774</td>\n",
       "      <td>-0.138538</td>\n",
       "      <td>-0.400764</td>\n",
       "      <td>-0.709612</td>\n",
       "      <td>-0.477415</td>\n",
       "      <td>1.282393</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>0.518860</td>\n",
       "      <td>0.135723</td>\n",
       "      <td>0.204726</td>\n",
       "      <td>-0.114863</td>\n",
       "      <td>-0.314939</td>\n",
       "      <td>0.067155</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>-0.337146</td>\n",
       "      <td>0.429561</td>\n",
       "      <td>-0.161309</td>\n",
       "      <td>-0.313517</td>\n",
       "      <td>0.033219</td>\n",
       "      <td>0.188475</td>\n",
       "      <td>0.191447</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>-0.134077</td>\n",
       "      <td>0.112312</td>\n",
       "      <td>-0.299560</td>\n",
       "      <td>0.081411</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.049621</td>\n",
       "      <td>-0.060027</td>\n",
       "      <td>-0.025852</td>\n",
       "      <td>-0.104491</td>\n",
       "      <td>-0.097263</td>\n",
       "      <td>0.042904</td>\n",
       "      <td>-0.033106</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>2.225037e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.721622</td>\n",
       "      <td>-1.771054</td>\n",
       "      <td>0.601862</td>\n",
       "      <td>1.024124</td>\n",
       "      <td>-2.045282</td>\n",
       "      <td>2.014134</td>\n",
       "      <td>-0.571373</td>\n",
       "      <td>-0.254063</td>\n",
       "      <td>-0.137017</td>\n",
       "      <td>-0.139633</td>\n",
       "      <td>0.884626</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.295163</td>\n",
       "      <td>0.791238</td>\n",
       "      <td>-0.141246</td>\n",
       "      <td>-1.322553</td>\n",
       "      <td>0.544381</td>\n",
       "      <td>-0.378826</td>\n",
       "      <td>-0.236459</td>\n",
       "      <td>-0.646737</td>\n",
       "      <td>0.309525</td>\n",
       "      <td>0.322643</td>\n",
       "      <td>0.402555</td>\n",
       "      <td>0.052024</td>\n",
       "      <td>-0.588946</td>\n",
       "      <td>-0.017743</td>\n",
       "      <td>0.065785</td>\n",
       "      <td>0.390461</td>\n",
       "      <td>-1.852833</td>\n",
       "      <td>0.598112</td>\n",
       "      <td>0.192919</td>\n",
       "      <td>-0.098404</td>\n",
       "      <td>-1.012435</td>\n",
       "      <td>-0.044070</td>\n",
       "      <td>-0.068865</td>\n",
       "      <td>-0.347044</td>\n",
       "      <td>0.110554</td>\n",
       "      <td>0.105284</td>\n",
       "      <td>-0.312198</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.268424</td>\n",
       "      <td>-0.297244</td>\n",
       "      <td>0.332091</td>\n",
       "      <td>-0.006504</td>\n",
       "      <td>0.030045</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.063937</td>\n",
       "      <td>0.038348</td>\n",
       "      <td>-0.062740</td>\n",
       "      <td>-0.016695</td>\n",
       "      <td>0.044203</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>-0.042630</td>\n",
       "      <td>-0.096724</td>\n",
       "      <td>0.037589</td>\n",
       "      <td>-0.034523</td>\n",
       "      <td>-0.007910</td>\n",
       "      <td>-0.007255</td>\n",
       "      <td>7.004372e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.863347</td>\n",
       "      <td>3.744723</td>\n",
       "      <td>5.950885</td>\n",
       "      <td>4.325532</td>\n",
       "      <td>-4.330916</td>\n",
       "      <td>-0.298262</td>\n",
       "      <td>0.723980</td>\n",
       "      <td>0.814940</td>\n",
       "      <td>0.459177</td>\n",
       "      <td>-0.638528</td>\n",
       "      <td>-2.451201</td>\n",
       "      <td>0.498072</td>\n",
       "      <td>0.891528</td>\n",
       "      <td>-0.095250</td>\n",
       "      <td>1.195335</td>\n",
       "      <td>0.106233</td>\n",
       "      <td>-0.290831</td>\n",
       "      <td>-0.279587</td>\n",
       "      <td>-0.154653</td>\n",
       "      <td>-0.226517</td>\n",
       "      <td>0.342977</td>\n",
       "      <td>1.229269</td>\n",
       "      <td>0.656798</td>\n",
       "      <td>-1.831250</td>\n",
       "      <td>1.477580</td>\n",
       "      <td>-0.585054</td>\n",
       "      <td>0.312511</td>\n",
       "      <td>-0.201685</td>\n",
       "      <td>-0.220040</td>\n",
       "      <td>-2.000678</td>\n",
       "      <td>-0.629451</td>\n",
       "      <td>1.602714</td>\n",
       "      <td>0.490555</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>-0.999357</td>\n",
       "      <td>1.538656</td>\n",
       "      <td>-0.965553</td>\n",
       "      <td>0.593470</td>\n",
       "      <td>-0.775236</td>\n",
       "      <td>0.393924</td>\n",
       "      <td>-0.050962</td>\n",
       "      <td>-0.469339</td>\n",
       "      <td>0.413895</td>\n",
       "      <td>-0.151793</td>\n",
       "      <td>0.242871</td>\n",
       "      <td>-0.192525</td>\n",
       "      <td>0.142467</td>\n",
       "      <td>-0.097485</td>\n",
       "      <td>0.212941</td>\n",
       "      <td>0.220781</td>\n",
       "      <td>-0.029249</td>\n",
       "      <td>-0.378663</td>\n",
       "      <td>0.225277</td>\n",
       "      <td>0.074959</td>\n",
       "      <td>-0.018888</td>\n",
       "      <td>0.186607</td>\n",
       "      <td>0.084210</td>\n",
       "      <td>-0.090319</td>\n",
       "      <td>0.066228</td>\n",
       "      <td>-3.556460e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.828254  0.119166  0.135020  3.671401 -1.020140 -1.229569 -0.465638   \n",
       "1 -0.848268  2.326184  5.530766  2.633174 -0.285820 -4.469285  0.478753   \n",
       "2 -1.960326  1.272612 -2.402175 -1.403092 -3.448164  0.468886  0.814892   \n",
       "3 -1.721622 -1.771054  0.601862  1.024124 -2.045282  2.014134 -0.571373   \n",
       "4  4.863347  3.744723  5.950885  4.325532 -4.330916 -0.298262  0.723980   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.521695  0.601154  0.176956 -0.309730  0.167770  0.033939 -0.433906   \n",
       "1  0.695374  0.631102 -1.128967  0.924448 -0.418833 -0.186514 -0.751774   \n",
       "2  0.393272 -0.035223  0.209374  0.125957  0.373020 -0.421528  1.134400   \n",
       "3 -0.254063 -0.137017 -0.139633  0.884626  0.331600  0.295163  0.791238   \n",
       "4  0.814940  0.459177 -0.638528 -2.451201  0.498072  0.891528 -0.095250   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0 -0.122126  0.656998 -0.132899  0.510841 -0.082842  0.324439 -0.086460   \n",
       "1 -1.689482  0.311650  0.528028  0.534501 -0.031267  0.418879  0.240262   \n",
       "2 -0.362347 -0.642886 -1.713634 -0.301525 -0.650167 -0.186636 -0.425797   \n",
       "3 -0.141246 -1.322553  0.544381 -0.378826 -0.236459 -0.646737  0.309525   \n",
       "4  1.195335  0.106233 -0.290831 -0.279587 -0.154653 -0.226517  0.342977   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0  0.445156 -0.453181  0.070990 -0.148505  0.626066 -0.982034  0.712641   \n",
       "1  0.273396 -0.261327  0.802925 -0.488801 -0.459396 -0.056920  0.314993   \n",
       "2 -2.587938  1.291566  0.051774 -0.138538 -0.400764 -0.709612 -0.477415   \n",
       "3  0.322643  0.402555  0.052024 -0.588946 -0.017743  0.065785  0.390461   \n",
       "4  1.229269  0.656798 -1.831250  1.477580 -0.585054  0.312511 -0.201685   \n",
       "\n",
       "         28        29        30        31        32        33        34  \\\n",
       "0 -0.010345  0.154753  0.032808  0.807478 -0.971187 -0.011545 -0.131402   \n",
       "1 -0.254198  0.637259  0.605876 -2.075718  0.640686 -0.019890 -1.701113   \n",
       "2  1.282393  0.022755  0.518860  0.135723  0.204726 -0.114863 -0.314939   \n",
       "3 -1.852833  0.598112  0.192919 -0.098404 -1.012435 -0.044070 -0.068865   \n",
       "4 -0.220040 -2.000678 -0.629451  1.602714  0.490555  0.013600 -0.999357   \n",
       "\n",
       "         35        36        37        38        39        40        41  \\\n",
       "0 -0.198993  0.612741  0.061333 -0.333821  0.169366 -0.082504  0.343993   \n",
       "1  0.871178  1.704187 -0.715255  0.433265 -0.275521 -0.920652 -0.404637   \n",
       "2  0.067155  0.014881 -0.337146  0.429561 -0.161309 -0.313517  0.033219   \n",
       "3 -0.347044  0.110554  0.105284 -0.312198  0.256797  0.268424 -0.297244   \n",
       "4  1.538656 -0.965553  0.593470 -0.775236  0.393924 -0.050962 -0.469339   \n",
       "\n",
       "         42        43        44        45        46        47        48  \\\n",
       "0 -0.236122  0.226492  0.022399 -0.212631  0.011712  0.134088 -0.031998   \n",
       "1  0.234945  0.184116  0.497862  0.269911 -0.118069  0.201996 -0.014644   \n",
       "2  0.188475  0.191447  0.134293 -0.134077  0.112312 -0.299560  0.081411   \n",
       "3  0.332091 -0.006504  0.030045 -0.003095  0.000611 -0.063937  0.038348   \n",
       "4  0.413895 -0.151793  0.242871 -0.192525  0.142467 -0.097485  0.212941   \n",
       "\n",
       "         49        50        51        52        53        54        55  \\\n",
       "0 -0.017881 -0.013068 -0.059459  0.073184  0.124520 -0.019338  0.044046   \n",
       "1  0.045696 -0.034928 -0.085613  0.048076  0.172408  0.170384  0.277750   \n",
       "2  0.012269  0.004247  0.049621 -0.060027 -0.025852 -0.104491 -0.097263   \n",
       "3 -0.062740 -0.016695  0.044203  0.013206 -0.042630 -0.096724  0.037589   \n",
       "4  0.220781 -0.029249 -0.378663  0.225277  0.074959 -0.018888  0.186607   \n",
       "\n",
       "         56        57        58            59  \n",
       "0  0.082331 -0.029107 -0.008535  2.593443e-18  \n",
       "1  0.151340 -0.058419 -0.021100  8.375107e-18  \n",
       "2  0.042904 -0.033106  0.003704  2.225037e-18  \n",
       "3 -0.034523 -0.007910 -0.007255  7.004372e-18  \n",
       "4  0.084210 -0.090319  0.066228 -3.556460e-18  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "Z_test = pca.transform(X_test_sc)\n",
    "\n",
    "# Check out the results in a dataframe.\n",
    "pd.DataFrame(Z_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance (first 40 components): [0.197 0.104 0.091 0.071 0.058 0.048 0.032 0.027 0.023 0.022 0.02  0.018\n",
      " 0.018 0.018 0.017 0.016 0.015 0.015 0.015 0.014 0.014 0.014 0.013 0.012\n",
      " 0.012 0.011 0.011 0.01  0.01  0.007 0.006 0.005 0.005 0.004 0.004 0.003\n",
      " 0.003 0.002 0.002 0.002]\n"
     ]
    }
   ],
   "source": [
    "# Pull the explained variance attribute using ready-to-use method from sklearn's PCA.\n",
    "# We can directly use this to explain the amount of variance explained by each of our newly created principal components\n",
    "var_exp = pca.explained_variance_ratio_\n",
    "print(f'Explained variance (first 40 components): {np.round(var_exp[:40],3)}') # examine only 1st 40 variances, rounded to 3 decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "- The 1st principal component alone, can explain 19.% of the entire variation in the data\n",
    "- The 2nd principal component alone, can explain 10.% of the entire variation in the data\n",
    "- The 3rd principal component alone, can explain 9.1% of the entire variation in the data\n",
    "and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative explained variance (first 40 components): [0.197 0.301 0.393 0.463 0.521 0.569 0.601 0.628 0.651 0.673 0.693 0.712\n",
      " 0.73  0.747 0.764 0.78  0.795 0.81  0.825 0.839 0.853 0.867 0.88  0.892\n",
      " 0.904 0.915 0.926 0.936 0.946 0.953 0.958 0.964 0.969 0.973 0.977 0.98\n",
      " 0.982 0.985 0.987 0.989]\n"
     ]
    }
   ],
   "source": [
    "# Generate the cumulative explained variance.\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(f'Cumulative explained variance (first 40 components): {np.round(cum_var_exp[:40],3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "- 1st 3 principal components can explain 39.3% of the variation in the data\n",
    "- 1st 18 principal components can explain 81% of the variation in the data\n",
    "- 1st 30 principal components can explain 95.3% of the variation in the data\n",
    "\n",
    "Given that we want to explain at least 95% of the variability in my data with principal components, the smallest number of principal components that we would need to keep is 30. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the classification models, we will do the following:\n",
    "1. Define X and y\n",
    "2. Create a train-test split of X and y\n",
    "3. Create a pipeline for the RandomUnderSampler/ ADASYN, PolynomialFeatures, StandardScaler, PCA (with identified n_components) and the classifiers<br>\n",
    "4. Call and fit the respective classification models\n",
    "5. Generate scoring metrics (accuracy, precision, recall, F1 score) to see how well the baseline model is performing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Transforming and Modelling using RandomUnderSampler dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and RandomUnderSampling sampling\n",
    "columns_to_check = [\n",
    "    'cpd_bronchitis',  \n",
    "    'depression',    \n",
    "    'arthritis',      \n",
    "    'heart_attack',   \n",
    "    'stroke',        \n",
    "    'asthma',       \n",
    "    'diabetes',      \n",
    "    'kidney_disease', \n",
    "    'heart_disease',  \n",
    "    'CD',        \n",
    "    'height',        \n",
    "    'weight'        \n",
    "]\n",
    "\n",
    "X = df.drop(columns=columns_to_check)\n",
    "y = df['CD']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Perform RandomUnderSampler for class imbalance\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define columns you want to apply polynomial features to\n",
    "\n",
    "poly_cols = [\n",
    "    'occasion_drink_30days', \n",
    "    'BMI',                \n",
    "    'education',          \n",
    "    'smoker_status',       \n",
    "    'exercise_cat',    \n",
    "    'ave_drink_week',     \n",
    "    'age'              \n",
    "]\n",
    "\n",
    "# Create a ColumnTransformer to apply PolynomialFeatures to selected columns\n",
    "poly_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), poly_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through columns not specified for polynomial features\n",
    ")\n",
    "\n",
    "# Define PCA with n_components=30\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Classifier': SVC(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "# Create an empty list to store the results\n",
    "cv_results_list = []\n",
    "train_results_list = []\n",
    "test_results_list = []\n",
    "\n",
    "# Perform cross-validation, train, and test scoring for each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    # Create pipeline for each classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('poly_transformer', poly_transformer),  # Apply polynomial features only to specified columns\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('pca', pca),  # Apply PCA with n_components=30\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_validate(pipeline, X_train_resampled, y_train_resampled, cv=5, scoring=['precision', 'recall', 'f1', 'accuracy'])\n",
    "    cv_results_list.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': cv_scores['test_precision'].mean(),\n",
    "        'Recall': cv_scores['test_recall'].mean(),\n",
    "        'F1': cv_scores['test_f1'].mean(),\n",
    "        'Accuracy': cv_scores['test_accuracy'].mean()\n",
    "    })\n",
    "\n",
    "    # Train scores\n",
    "    pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "    train_preds = pipeline.predict(X_train_resampled)\n",
    "    train_accuracy = accuracy_score(y_train_resampled, train_preds)\n",
    "    train_precision = precision_score(y_train_resampled, train_preds)\n",
    "    train_recall = recall_score(y_train_resampled, train_preds)\n",
    "    train_f1 = f1_score(y_train_resampled, train_preds)\n",
    "    train_results_list.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': train_precision,\n",
    "        'Recall': train_recall,\n",
    "        'F1': train_f1,\n",
    "        'Accuracy': train_accuracy\n",
    "    })\n",
    "\n",
    "    # Test scores\n",
    "    test_preds = pipeline.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    test_precision = precision_score(y_test, test_preds)\n",
    "    test_recall = recall_score(y_test, test_preds)\n",
    "    test_f1 = f1_score(y_test, test_preds)\n",
    "    test_results_list.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': test_precision,\n",
    "        'Recall': test_recall,\n",
    "        'F1': test_f1,\n",
    "        'Accuracy': test_accuracy\n",
    "    })\n",
    "\n",
    "# Create DataFrames for cross-validation, train, and test results\n",
    "cv_results_df = pd.DataFrame(cv_results_list)\n",
    "train_results_df = pd.DataFrame(train_results_list)\n",
    "test_results_df = pd.DataFrame(test_results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721346</td>\n",
       "      <td>0.626320</td>\n",
       "      <td>0.670351</td>\n",
       "      <td>0.692211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.660420</td>\n",
       "      <td>0.676110</td>\n",
       "      <td>0.668159</td>\n",
       "      <td>0.664229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.707471</td>\n",
       "      <td>0.632027</td>\n",
       "      <td>0.667590</td>\n",
       "      <td>0.685358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.704099</td>\n",
       "      <td>0.648932</td>\n",
       "      <td>0.675311</td>\n",
       "      <td>0.688098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.661198</td>\n",
       "      <td>0.649385</td>\n",
       "      <td>0.655201</td>\n",
       "      <td>0.658290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.721346  0.626320  0.670351  0.692211\n",
       "1                 Random Forest   0.660420  0.676110  0.668159  0.664229\n",
       "2     Support Vector Classifier   0.707471  0.632027  0.667590  0.685358\n",
       "3  Gradient Boosting Classifier   0.704099  0.648932  0.675311  0.688098\n",
       "4                       XGBoost   0.661198  0.649385  0.655201  0.658290"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation scores for the 5 baseline models\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.726816</td>\n",
       "      <td>0.628369</td>\n",
       "      <td>0.674017</td>\n",
       "      <td>0.696094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.997031</td>\n",
       "      <td>0.998285</td>\n",
       "      <td>0.998287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>0.659890</td>\n",
       "      <td>0.701043</td>\n",
       "      <td>0.718593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.751747</td>\n",
       "      <td>0.688214</td>\n",
       "      <td>0.718579</td>\n",
       "      <td>0.730471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.984586</td>\n",
       "      <td>0.948378</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>0.966766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.726816  0.628369  0.674017  0.696094\n",
       "1                 Random Forest   0.999542  0.997031  0.998285  0.998287\n",
       "2     Support Vector Classifier   0.747671  0.659890  0.701043  0.718593\n",
       "3  Gradient Boosting Classifier   0.751747  0.688214  0.718579  0.730471\n",
       "4                       XGBoost   0.984586  0.948378  0.966143  0.966766"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train scores for the 5 baseline models\n",
    "train_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.581981</td>\n",
       "      <td>0.654795</td>\n",
       "      <td>0.616244</td>\n",
       "      <td>0.722757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.482781</td>\n",
       "      <td>0.665753</td>\n",
       "      <td>0.559693</td>\n",
       "      <td>0.643899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.566008</td>\n",
       "      <td>0.653881</td>\n",
       "      <td>0.606780</td>\n",
       "      <td>0.711891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.553788</td>\n",
       "      <td>0.667580</td>\n",
       "      <td>0.605383</td>\n",
       "      <td>0.704129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.489377</td>\n",
       "      <td>0.631050</td>\n",
       "      <td>0.551256</td>\n",
       "      <td>0.650730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.581981  0.654795  0.616244  0.722757\n",
       "1                 Random Forest   0.482781  0.665753  0.559693  0.643899\n",
       "2     Support Vector Classifier   0.566008  0.653881  0.606780  0.711891\n",
       "3  Gradient Boosting Classifier   0.553788  0.667580  0.605383  0.704129\n",
       "4                       XGBoost   0.489377  0.631050  0.551256  0.650730"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test scores for the 5 baseline models\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine resampled features with labels into a single DataFrame\n",
    "undersampled_df = pd.DataFrame(X_train_resampled, columns=X.columns)\n",
    "undersampled_df['CD'] = y_train_resampled\n",
    "\n",
    "# Export the resampled DataFrame to a CSV file\n",
    "undersampled_df.to_csv('../data/undersampled_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Transforming and Modelling using ADASYN oversampled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and ADASYN sampling\n",
    "\n",
    "columns_to_check2 = [\n",
    "    'cpd_bronchitis', \n",
    "    'depression',    \n",
    "    'arthritis',    \n",
    "    'heart_attack',   \n",
    "    'stroke',       \n",
    "    'asthma',     \n",
    "    'diabetes',      \n",
    "    'kidney_disease', \n",
    "    'heart_disease', \n",
    "    'CD',           \n",
    "    'height',         \n",
    "    'weight'      \n",
    "]\n",
    "\n",
    "X2 = df.drop(columns=columns_to_check2)\n",
    "y2 = df['CD']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)\n",
    "\n",
    "# Perform ADASYN sampling for class imbalance\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X2_train_resampled, y2_train_resampled = adasyn.fit_resample(X2_train, y2_train)\n",
    "\n",
    "# Define columns you want to apply polynomial features to\n",
    "poly_cols = [\n",
    "    'occasion_drink_30days',\n",
    "    'BMI',             \n",
    "    'education',   \n",
    "    'smoker_status',   \n",
    "    'exercise_cat',      \n",
    "    'ave_drink_week',    \n",
    "    'age'              \n",
    "]\n",
    "\n",
    "# Create a ColumnTransformer to apply PolynomialFeatures to selected columns\n",
    "poly_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), poly_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through columns not specified for polynomial features\n",
    ")\n",
    "\n",
    "# Define PCA with n_components=30\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers2 = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Classifier': SVC(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "# Create an empty list to store the results\n",
    "cv_results_list2 = []\n",
    "train_results_list2 = []\n",
    "test_results_list2 = []\n",
    "\n",
    "# Perform cross-validation, train, and test scoring for each classifier\n",
    "for clf_name, clf in classifiers2.items():\n",
    "    # Create pipeline for each classifier\n",
    "    pipeline2 = Pipeline([\n",
    "        ('poly_transformer', poly_transformer),  # Apply polynomial features only to specified columns\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('pca', pca),  # Apply PCA with n_components=18\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv_scores2 = cross_validate(pipeline2, X2_train_resampled, y2_train_resampled, cv=5, scoring=['precision', 'recall', 'f1', 'accuracy'])\n",
    "    cv_results_list2.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': cv_scores2['test_precision'].mean(),\n",
    "        'Recall': cv_scores2['test_recall'].mean(),\n",
    "        'F1': cv_scores2['test_f1'].mean(),\n",
    "        'Accuracy': cv_scores2['test_accuracy'].mean()\n",
    "    })\n",
    "\n",
    "    # Train scores\n",
    "    pipeline2.fit(X2_train_resampled, y2_train_resampled)\n",
    "    train_preds2 = pipeline2.predict(X2_train_resampled)\n",
    "    train_accuracy2 = accuracy_score(y2_train_resampled, train_preds2)\n",
    "    train_precision2 = precision_score(y2_train_resampled, train_preds2)\n",
    "    train_recall2 = recall_score(y2_train_resampled, train_preds2)\n",
    "    train_f1_2 = f1_score(y2_train_resampled, train_preds2)\n",
    "    train_results_list2.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': train_precision2,\n",
    "        'Recall': train_recall2,\n",
    "        'F1': train_f1_2,\n",
    "        'Accuracy': train_accuracy2\n",
    "    })\n",
    "\n",
    "    # Test scores\n",
    "    test_preds2 = pipeline2.predict(X2_test)\n",
    "    test_accuracy2 = accuracy_score(y2_test, test_preds2)\n",
    "    test_precision2 = precision_score(y2_test, test_preds2)\n",
    "    test_recall2 = recall_score(y2_test, test_preds2)\n",
    "    test_f1_2 = f1_score(y2_test, test_preds2)\n",
    "    test_results_list2.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': test_precision2,\n",
    "        'Recall': test_recall2,\n",
    "        'F1': test_f1_2,\n",
    "        'Accuracy': test_accuracy2\n",
    "    })\n",
    "\n",
    "# Create DataFrames for cross-validation, train, and test results\n",
    "cv_results_df2 = pd.DataFrame(cv_results_list2)\n",
    "train_results_df2 = pd.DataFrame(train_results_list2)\n",
    "test_results_df2 = pd.DataFrame(test_results_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.675770</td>\n",
       "      <td>0.590264</td>\n",
       "      <td>0.629615</td>\n",
       "      <td>0.652517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.697813</td>\n",
       "      <td>0.732935</td>\n",
       "      <td>0.714713</td>\n",
       "      <td>0.706925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.685092</td>\n",
       "      <td>0.612716</td>\n",
       "      <td>0.646501</td>\n",
       "      <td>0.664536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.672169</td>\n",
       "      <td>0.643238</td>\n",
       "      <td>0.657109</td>\n",
       "      <td>0.663716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.684112</td>\n",
       "      <td>0.685577</td>\n",
       "      <td>0.684645</td>\n",
       "      <td>0.683650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.675770  0.590264  0.629615  0.652517\n",
       "1                 Random Forest   0.697813  0.732935  0.714713  0.706925\n",
       "2     Support Vector Classifier   0.685092  0.612716  0.646501  0.664536\n",
       "3  Gradient Boosting Classifier   0.672169  0.643238  0.657109  0.663716\n",
       "4                       XGBoost   0.684112  0.685577  0.684645  0.683650"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation scores for the 5 baseline models\n",
    "cv_results_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.687712</td>\n",
       "      <td>0.616464</td>\n",
       "      <td>0.650142</td>\n",
       "      <td>0.667351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.997896</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>0.998183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.726339</td>\n",
       "      <td>0.661366</td>\n",
       "      <td>0.692331</td>\n",
       "      <td>0.705282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.708338</td>\n",
       "      <td>0.688377</td>\n",
       "      <td>0.698215</td>\n",
       "      <td>0.701647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.924147</td>\n",
       "      <td>0.908910</td>\n",
       "      <td>0.916465</td>\n",
       "      <td>0.916926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.687712  0.616464  0.650142  0.667351\n",
       "1                 Random Forest   0.997896  0.998480  0.998188  0.998183\n",
       "2     Support Vector Classifier   0.726339  0.661366  0.692331  0.705282\n",
       "3  Gradient Boosting Classifier   0.708338  0.688377  0.698215  0.701647\n",
       "4                       XGBoost   0.924147  0.908910  0.916465  0.916926"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train scores for the 5 baseline models\n",
    "train_results_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.532567</td>\n",
       "      <td>0.634703</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>0.686433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.614612</td>\n",
       "      <td>0.551639</td>\n",
       "      <td>0.660354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.550623</td>\n",
       "      <td>0.645662</td>\n",
       "      <td>0.594367</td>\n",
       "      <td>0.700404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.518625</td>\n",
       "      <td>0.661187</td>\n",
       "      <td>0.581293</td>\n",
       "      <td>0.676188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.503666</td>\n",
       "      <td>0.627397</td>\n",
       "      <td>0.558764</td>\n",
       "      <td>0.663148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.532567  0.634703  0.579167  0.686433\n",
       "1                 Random Forest   0.500372  0.614612  0.551639  0.660354\n",
       "2     Support Vector Classifier   0.550623  0.645662  0.594367  0.700404\n",
       "3  Gradient Boosting Classifier   0.518625  0.661187  0.581293  0.676188\n",
       "4                       XGBoost   0.503666  0.627397  0.558764  0.663148"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test scores for the 5 baseline models\n",
    "test_results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine resampled features with labels into a single DataFrame\n",
    "oversampled_df = pd.DataFrame(X2_train_resampled, columns=X2.columns)\n",
    "oversampled_df['CD'] = y2_train_resampled\n",
    "\n",
    "# Export the resampled DataFrame to a CSV file\n",
    "oversampled_df.to_csv('../data/oversampled_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skin_cancer</th>\n",
       "      <th>other_cancer</th>\n",
       "      <th>sex</th>\n",
       "      <th>martial</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>blind</th>\n",
       "      <th>diff_walking</th>\n",
       "      <th>occasion_drink_30days</th>\n",
       "      <th>high_bp</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>smoker_status</th>\n",
       "      <th>one_alc_per_day</th>\n",
       "      <th>binge_drink</th>\n",
       "      <th>ave_drink_week</th>\n",
       "      <th>fruit</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>exercise_cat</th>\n",
       "      <th>high_cholesterol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.694303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.731303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.038567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.027384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.399184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   skin_cancer  other_cancer  sex  martial  employment_status  blind  \\\n",
       "0            0             1    1        1                  1      0   \n",
       "1            0             0    0        1                  0      0   \n",
       "2            0             0    1        0                  1      0   \n",
       "3            0             0    0        0                  1      0   \n",
       "4            0             0    1        1                  1      0   \n",
       "\n",
       "   diff_walking  occasion_drink_30days  high_bp   age  education  \\\n",
       "0             1                      0        1  10.0          2   \n",
       "1             0                      0        0   3.0          1   \n",
       "2             0                      4        0   1.0          1   \n",
       "3             0                      1        0   6.0          1   \n",
       "4             0                      0        0   3.0          2   \n",
       "\n",
       "   smoker_status  one_alc_per_day  binge_drink  ave_drink_week  fruit  \\\n",
       "0              0                0            0    0.000000e+00      1   \n",
       "1              0                0            0    0.000000e+00      1   \n",
       "2              0                0            0    0.000000e+00      0   \n",
       "3              3                1            0    2.100000e+01      1   \n",
       "4              0                0            0    5.397605e-79      1   \n",
       "\n",
       "   vegetable  exercise_cat  high_cholesterol        BMI  CD  \n",
       "0          1             2                 0  21.694303   1  \n",
       "1          0             1                 0  30.731303   0  \n",
       "2          0             1                 0  22.038567   0  \n",
       "3          0             0                 0  25.027384   0  \n",
       "4          1             0                 0  27.399184   0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations about applying principal component analysis:\n",
    "- While PCA (Principal Component Analysis) is often used for dimensionality reduction, it can sometimes lead to a loss of information, particularly if the original dimensions contain important features for classification. This loss of information can result in decreased accuracy, precision, recall, and F1 score, especially if the reduced dimensions do not capture enough variability in the data to effectively distinguish between classes. \n",
    "- Since we have managed to reduce the number of columns from the original 60 to 30, and managed to retain > 95% of the information. **We have decided to proceed with having n_components = 30 for our analysis.**\n",
    "\n",
    "The main benefits of PCA that made the team come to this conclusion are: \n",
    "1. **Removes Correlated Features:** By converting correlated variables into a set of linearly uncorrelated variables (principal components), PCA helps in removing redundancy in the dataset. This can be particularly useful in models where multicollinearity may be a problem.\n",
    "\n",
    "2. **Optimizes Performance:** Reducing the dimensionality of the data can lead to faster training times and can help in combating the curse of dimensionality, where the feature space becomes so large that the model starts to overfit. By focusing on the most informative aspects of the original data, PCA can lead to more generalized models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 3: Export Model Evaluation Result \n",
    "For offline reference and recording purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling using RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>cv_precision</th>\n",
       "      <th>cv_recall</th>\n",
       "      <th>cv_f1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721346</td>\n",
       "      <td>0.626320</td>\n",
       "      <td>0.670351</td>\n",
       "      <td>0.692211</td>\n",
       "      <td>0.726816</td>\n",
       "      <td>0.628369</td>\n",
       "      <td>0.674017</td>\n",
       "      <td>0.696094</td>\n",
       "      <td>0.581981</td>\n",
       "      <td>0.654795</td>\n",
       "      <td>0.616244</td>\n",
       "      <td>0.722757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.660420</td>\n",
       "      <td>0.676110</td>\n",
       "      <td>0.668159</td>\n",
       "      <td>0.664229</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.997031</td>\n",
       "      <td>0.998285</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>0.482781</td>\n",
       "      <td>0.665753</td>\n",
       "      <td>0.559693</td>\n",
       "      <td>0.643899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.707471</td>\n",
       "      <td>0.632027</td>\n",
       "      <td>0.667590</td>\n",
       "      <td>0.685358</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>0.659890</td>\n",
       "      <td>0.701043</td>\n",
       "      <td>0.718593</td>\n",
       "      <td>0.566008</td>\n",
       "      <td>0.653881</td>\n",
       "      <td>0.606780</td>\n",
       "      <td>0.711891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.704099</td>\n",
       "      <td>0.648932</td>\n",
       "      <td>0.675311</td>\n",
       "      <td>0.688098</td>\n",
       "      <td>0.751747</td>\n",
       "      <td>0.688214</td>\n",
       "      <td>0.718579</td>\n",
       "      <td>0.730471</td>\n",
       "      <td>0.553788</td>\n",
       "      <td>0.667580</td>\n",
       "      <td>0.605383</td>\n",
       "      <td>0.704129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.661198</td>\n",
       "      <td>0.649385</td>\n",
       "      <td>0.655201</td>\n",
       "      <td>0.658290</td>\n",
       "      <td>0.984586</td>\n",
       "      <td>0.948378</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>0.966766</td>\n",
       "      <td>0.489377</td>\n",
       "      <td>0.631050</td>\n",
       "      <td>0.551256</td>\n",
       "      <td>0.650730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  cv_precision  cv_recall     cv_f1  \\\n",
       "0           Logistic Regression      0.721346   0.626320  0.670351   \n",
       "1                 Random Forest      0.660420   0.676110  0.668159   \n",
       "2     Support Vector Classifier      0.707471   0.632027  0.667590   \n",
       "3  Gradient Boosting Classifier      0.704099   0.648932  0.675311   \n",
       "4                       XGBoost      0.661198   0.649385  0.655201   \n",
       "\n",
       "   cv_accuracy  train_precision  train_recall  train_f1  train_accuracy  \\\n",
       "0     0.692211         0.726816      0.628369  0.674017        0.696094   \n",
       "1     0.664229         0.999542      0.997031  0.998285        0.998287   \n",
       "2     0.685358         0.747671      0.659890  0.701043        0.718593   \n",
       "3     0.688098         0.751747      0.688214  0.718579        0.730471   \n",
       "4     0.658290         0.984586      0.948378  0.966143        0.966766   \n",
       "\n",
       "   test_precision  test_recall   test_f1  test_accuracy  \n",
       "0        0.581981     0.654795  0.616244       0.722757  \n",
       "1        0.482781     0.665753  0.559693       0.643899  \n",
       "2        0.566008     0.653881  0.606780       0.711891  \n",
       "3        0.553788     0.667580  0.605383       0.704129  \n",
       "4        0.489377     0.631050  0.551256       0.650730  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate cross-validation, train, and test results DataFrames\n",
    "merged_df = pd.concat([cv_results_df.set_index('Classifier'), \n",
    "                       train_results_df.set_index('Classifier'), \n",
    "                       test_results_df.set_index('Classifier')],\n",
    "                      axis=1, keys=['cv', 'train', 'test'])\n",
    "\n",
    "# Reset index to make 'Classifier' a column again\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "merged_df.columns = ['Classifier', \n",
    "                     'cv_precision', 'cv_recall', 'cv_f1', 'cv_accuracy',\n",
    "                     'train_precision', 'train_recall', 'train_f1', 'train_accuracy',\n",
    "                     'test_precision', 'test_recall', 'test_f1', 'test_accuracy']\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data to csv\n",
    "merged_df.to_csv('../data/04_model_evaluation_result_undersampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling using ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>cv_precision</th>\n",
       "      <th>cv_recall</th>\n",
       "      <th>cv_f1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.675770</td>\n",
       "      <td>0.590264</td>\n",
       "      <td>0.629615</td>\n",
       "      <td>0.652517</td>\n",
       "      <td>0.687712</td>\n",
       "      <td>0.616464</td>\n",
       "      <td>0.650142</td>\n",
       "      <td>0.667351</td>\n",
       "      <td>0.532567</td>\n",
       "      <td>0.634703</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>0.686433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.697813</td>\n",
       "      <td>0.732935</td>\n",
       "      <td>0.714713</td>\n",
       "      <td>0.706925</td>\n",
       "      <td>0.997896</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>0.998183</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.614612</td>\n",
       "      <td>0.551639</td>\n",
       "      <td>0.660354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.685092</td>\n",
       "      <td>0.612716</td>\n",
       "      <td>0.646501</td>\n",
       "      <td>0.664536</td>\n",
       "      <td>0.726339</td>\n",
       "      <td>0.661366</td>\n",
       "      <td>0.692331</td>\n",
       "      <td>0.705282</td>\n",
       "      <td>0.550623</td>\n",
       "      <td>0.645662</td>\n",
       "      <td>0.594367</td>\n",
       "      <td>0.700404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.672169</td>\n",
       "      <td>0.643238</td>\n",
       "      <td>0.657109</td>\n",
       "      <td>0.663716</td>\n",
       "      <td>0.708338</td>\n",
       "      <td>0.688377</td>\n",
       "      <td>0.698215</td>\n",
       "      <td>0.701647</td>\n",
       "      <td>0.518625</td>\n",
       "      <td>0.661187</td>\n",
       "      <td>0.581293</td>\n",
       "      <td>0.676188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.684112</td>\n",
       "      <td>0.685577</td>\n",
       "      <td>0.684645</td>\n",
       "      <td>0.683650</td>\n",
       "      <td>0.924147</td>\n",
       "      <td>0.908910</td>\n",
       "      <td>0.916465</td>\n",
       "      <td>0.916926</td>\n",
       "      <td>0.503666</td>\n",
       "      <td>0.627397</td>\n",
       "      <td>0.558764</td>\n",
       "      <td>0.663148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  cv_precision  cv_recall     cv_f1  \\\n",
       "0           Logistic Regression      0.675770   0.590264  0.629615   \n",
       "1                 Random Forest      0.697813   0.732935  0.714713   \n",
       "2     Support Vector Classifier      0.685092   0.612716  0.646501   \n",
       "3  Gradient Boosting Classifier      0.672169   0.643238  0.657109   \n",
       "4                       XGBoost      0.684112   0.685577  0.684645   \n",
       "\n",
       "   cv_accuracy  train_precision  train_recall  train_f1  train_accuracy  \\\n",
       "0     0.652517         0.687712      0.616464  0.650142        0.667351   \n",
       "1     0.706925         0.997896      0.998480  0.998188        0.998183   \n",
       "2     0.664536         0.726339      0.661366  0.692331        0.705282   \n",
       "3     0.663716         0.708338      0.688377  0.698215        0.701647   \n",
       "4     0.683650         0.924147      0.908910  0.916465        0.916926   \n",
       "\n",
       "   test_precision  test_recall   test_f1  test_accuracy  \n",
       "0        0.532567     0.634703  0.579167       0.686433  \n",
       "1        0.500372     0.614612  0.551639       0.660354  \n",
       "2        0.550623     0.645662  0.594367       0.700404  \n",
       "3        0.518625     0.661187  0.581293       0.676188  \n",
       "4        0.503666     0.627397  0.558764       0.663148  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate cross-validation, train, and test results DataFrames\n",
    "merged_df1 = pd.concat([cv_results_df2.set_index('Classifier'), \n",
    "                        train_results_df2.set_index('Classifier'), \n",
    "                        test_results_df2.set_index('Classifier')],\n",
    "                        axis=1, keys=['cv', 'train', 'test'])\n",
    "\n",
    "# Reset index to make 'Classifier' a column again\n",
    "merged_df1.reset_index(inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "merged_df1.columns = ['Classifier', \n",
    "                     'cv_precision', 'cv_recall', 'cv_f1', 'cv_accuracy',\n",
    "                     'train_precision', 'train_recall', 'train_f1', 'train_accuracy',\n",
    "                     'test_precision', 'test_recall', 'test_f1', 'test_accuracy']\n",
    "\n",
    "merged_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data to csv\n",
    "merged_df1.to_csv('../data/04_model_evaluation_result_oversampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model Evaluation Outcome\n",
    "\n",
    "Based on our problem statement, the task is to identify individuals at high risk for chronic diseases based on their lifestyle data. The significance of the evaluation metrics are as follows: \n",
    "- Accuracy: measures the proportion of correctly classified instances among all instances. In this context, accuracy indicates how well the model predicts both high-risk and not high-risk individuals. \n",
    "- Precision: measures the proportion of true high-risk individuals among all instances classified as high-risk. It focuses on minimizing false positives, i.e., instances wrongly classified as high-risk individuals. In this context, precision indicates the reliability of the model in correctly identifying high-risk individuals.\n",
    "- Recall/ Sensitivity: measures the proportion of true high-risk individuals that are correctly identified by the classifier. It focuses on minimizing false negatives, i.e., high-risk individuals wrongly classified as not high-risk. In this context, recall indicates the ability of the model to capture all actual high-risk individuals.\n",
    "- F1 Score: harmonic mean of precision and recall. It provides a balance between precision and recall, giving equal weight to both metrics. It summarizes the overall performance of the classifier, taking into account both precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team has chosen F1 score to be the main metric to focus on for the below reason: \n",
    "\n",
    "**Balanced Trade-Off**  \n",
    "When both false positives and false negatives are equally undesirable:\n",
    "\n",
    "- **False Positive (Wrongly identify an individual as high risk)**: Causes a false alarm, leading to unnecessary stress and resource allocation.\n",
    "- **False Negative (Wrongly identify an individual as low risk)**: Fails to provide timely intervention, potentially leading to adverse health outcomes.\n",
    "\n",
    "**Sensitivity to Class Imbalance**  \n",
    "- Approximately 30% of Asians are medically diagnosed with a chronic disease in our dataset, indicating a significant prevalence that should be taken into account when designing and training predictive models to ensure they are sensitive to class imbalances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Comparison of Sampling Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These are the advantages and disadvantages for both methods:\n",
    "\n",
    "Advantages: \n",
    "- RandomUnderSampler: Generally provides a balanced dataset by randomly removing samples from the majority class.\n",
    "- ADASYN (Adaptive Synthetic Sampling): Generates synthetic samples for the minority class, focusing on areas where the class distribution is sparse.\n",
    "\n",
    "Disadvantages: \n",
    "- RandomUnderSampler: It may discard potentially useful data, leading to loss of information.\n",
    "- ADASYN (Adaptive Synthetic Sampling): May introduce noise into the dataset if not used carefully.\n",
    "\n",
    "Based on the 4 metrics (accuracy, precision, recall and F1 score): \n",
    "\n",
    "| Classifier                     | Metric        | RandomUnderSampler | ADASYN    | Better Sampling Method |\n",
    "|--------------------------------|---------------|--------------------|-----------|------------------------|\n",
    "| Logistic Regression            | Precision     | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | Recall        | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | F1-score      | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | Accuracy      | Higher             | Lower     | RandomUnderSampler     |\n",
    "| Random Forest                  | Precision     | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Recall        | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | F1-score      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Accuracy      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "| Support Vector Classifier      | Precision     | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | Recall        | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | F1-score      | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | Accuracy      | Higher             | Lower     | RandomUnderSampler     |\n",
    "| Gradient Boosting Classifier   | Precision     | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Recall        | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | F1-score      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Accuracy      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "| XGBoost                        | Precision     | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Recall        | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | F1-score      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Accuracy      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "\n",
    "- RandomUnderSampler generally performs better than ADASYN across most classifiers, especially in terms of testing set metrics such as precision, recall, F1-score, and accuracy.\n",
    "- However, the choice between sampling methods may also depend on the specific requirements of the problem and the importance of different evaluation metrics. For instance, if you prioritize generalization performance on unseen data (testing set), RandomUnderSampler might be preferred. However, if you prioritize maximizing recall or sensitivity, ADASYN might be more suitable as it tends to balance the class distribution more effectively.\n",
    "\n",
    "**Overall, based on the comparison, we will take scores from the undersampling with RandomUnderSampler.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Model Evaluation based on Under Sampling\n",
    "\n",
    "Comparison of the baseline models' cross-validation and train scores\n",
    "\n",
    "In general, a smaller difference between the train score and cross-validation score is preferred, as it suggests better generalization performance and less overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:\n",
    "\n",
    "| Model                        | Cross-Validation Score | Train Score | Difference |\n",
    "|------------------------------|------------------------|-------------|------------|\n",
    "| Logistic Regression          | 0.691868               | 0.696094    | 0.004226   |\n",
    "| Random Forest                | 0.662859               | 0.998401    | 0.335542   |\n",
    "| Support Vector Classifier    | 0.685358               | 0.718593    | 0.033235   |\n",
    "| Gradient Boosting Classifier | 0.688669               | 0.730699    | 0.042030   |\n",
    "| XGBoost                      | 0.650410               | 0.963796    | 0.313386   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision:\n",
    "\n",
    "| Model                        | Cross-Validation Score | Train Score | Difference |\n",
    "|------------------------------|------------------------|-------------|------------|\n",
    "| Logistic Regression          | 0.721112               | 0.726816    | 0.005704   |\n",
    "| Random Forest                | 0.659726               | 0.999085    | 0.339359   |\n",
    "| Support Vector Classifier    | 0.707471               | 0.747671    | 0.040200   |\n",
    "| Gradient Boosting Classifier | 0.704440               | 0.752753    | 0.048313   |\n",
    "| XGBoost                      | 0.653205               | 0.986814    | 0.333609   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (Sensitivity):\n",
    "\n",
    "| Model                        | Cross-Validation Score | Train Score | Difference |\n",
    "|------------------------------|------------------------|-------------|------------|\n",
    "| Logistic Regression          | 0.625635               | 0.628369    | 0.002734   |\n",
    "| Random Forest                | 0.672686               | 0.997716    | 0.325030   |\n",
    "| Support Vector Classifier    | 0.632027               | 0.659890    | 0.027863   |\n",
    "| Gradient Boosting Classifier | 0.650075               | 0.687072    | 0.036997   |\n",
    "| XGBoost                      | 0.641390               | 0.940155    | 0.298765   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score:\n",
    "\n",
    "| Model                        | Cross-Validation Score | Train Score | Difference |\n",
    "|------------------------------|------------------------|-------------|------------|\n",
    "| Logistic Regression          | 0.669848               | 0.674017    | 0.004169   |\n",
    "| Random Forest                | 0.666116               | 0.998400    | 0.332284   |\n",
    "| Support Vector Classifier    | 0.667590               | 0.701043    | 0.033453   |\n",
    "| Gradient Boosting Classifier | 0.676086               | 0.718414    | 0.042328   |\n",
    "| XGBoost                      | 0.647210               | 0.962920    | 0.315710   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these comparisons, we make the following observations:\n",
    "\n",
    "1. Random Forest: Shows the largest difference between the train scores and cross-validation scores for all four metrics, indicating a high degree of overfitting on the training data.\n",
    "  \n",
    "2. Logistic Regression: Has small negative differences between the train scores and cross-validation scores for accuracy, precision, and F1-score, and a small positive difference for recall. This suggests a slight underfitting on the training data, but with relatively good generalization performance.\n",
    "  \n",
    "3. Support Vector Classifier: Has negative differences between the train scores and cross-validation scores for all four metrics, indicating potential underfitting on the training data, and better performance on the unseen data.\n",
    "  \n",
    "4. Gradient Boosting Classifier: Small to moderate positive differences between the train scores and cross-validation scores for all four metrics, suggesting some degree of overfitting on the training data.  \n",
    "  \n",
    "5. XGBoost: Moderate to large positive differences between the train scores and cross-validation scores for all four metrics, indicating a significant degree of overfitting on the training data.  \n",
    "  \n",
    "A smaller difference between the train score and cross-validation score suggests better generalization performance. Models with larger positive differences, like the Random Forest and XGBoost models, may be overfitting the training data, while models with negative differences or small positive differences, like the Logistic Regression and Support Vector Classifier models, tend to generalize better or may be slightly underfitting the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the baseline models' train and test scores\n",
    "\n",
    "In general, a smaller difference between the train score and test score is preferred, as it suggests better generalization performance and less overfitting or underfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:\n",
    "\n",
    "| Model                        | Train Score | Test Score | Difference |\n",
    "|------------------------------|-------------|------------|------------|\n",
    "| Logistic Regression          | 0.696094    | 0.722757   | -0.026663  |\n",
    "| Random Forest                | 0.998401    | 0.647004   | 0.351397   |\n",
    "| Support Vector Classifier    | 0.718593    | 0.711891   | 0.006702   |\n",
    "| Gradient Boosting Classifier | 0.730699    | 0.705992   | 0.024707   |\n",
    "| XGBoost                      | 0.963796    | 0.656007   | 0.307789   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision:\n",
    "\n",
    "| Model                        | Train Score | Test Score | Difference |\n",
    "|------------------------------|-------------|------------|------------|\n",
    "| Logistic Regression          | 0.726816    | 0.581981   | 0.144835   |\n",
    "| Random Forest                | 0.999085    | 0.486399   | 0.512686   |\n",
    "| Support Vector Classifier    | 0.747671    | 0.566008   | 0.181663   |\n",
    "| Gradient Boosting Classifier | 0.752753    | 0.556402   | 0.196351   |\n",
    "| XGBoost                      | 0.986814    | 0.495400   | 0.491414   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (Sensitivity):\n",
    "\n",
    "| Model                        | Train Score | Test Score | Difference |\n",
    "|------------------------------|-------------|------------|------------|\n",
    "| Logistic Regression          | 0.628369    | 0.654795   | -0.026426  |\n",
    "| Random Forest                | 0.997716    | 0.685845   | 0.311871   |\n",
    "| Support Vector Classifier    | 0.659890    | 0.653881   | 0.006009   |\n",
    "| Gradient Boosting Classifier | 0.687072    | 0.666667   | 0.020405   |\n",
    "| XGBoost                      | 0.940155    | 0.639269   | 0.300886   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score:\n",
    "\n",
    "| Model                        | Train Score | Test Score | Difference |\n",
    "|------------------------------|-------------|------------|------------|\n",
    "| Logistic Regression          | 0.674017    | 0.616244   | 0.057773   |\n",
    "| Random Forest                | 0.998400    | 0.569155   | 0.429245   |\n",
    "| Support Vector Classifier    | 0.701043    | 0.606780   | 0.094263   |\n",
    "| Gradient Boosting Classifier | 0.718414    | 0.606564   | 0.111850   |\n",
    "| XGBoost                      | 0.962920    | 0.558214   | 0.404706   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these comparisons, we can make the following observations:\n",
    "\n",
    "1. Random Forest: Difference between train scores and test scores are too huge (accuracy: 0.35, precision: 0.512, recall: 0.311, F1-score: 0.429).indicating a high degree of overfitting on the training data.  \n",
    "\n",
    "2. Logistic Regression: Has small negative differences between the train and test scores for accuracy (-0.02) and recall (-0.03), and positive differences for precision (0.144) and F1-score (0.057). This suggests relatively good generalization performance overall compared to model such as Random Forest.\n",
    "  \n",
    "3. Support Vector Classifier: Positive differences between the train and test scores for all four metrics (accuracy: 0.0067, precision: 0.181, recall: 0.006, F1-score: 0.09). This suggests relatively good generalization performance overall compared to model such as Random Forest.\n",
    "\n",
    "4. Gradient Boosting Classifier: Shows positive differences between the train and test scores for all four metrics (accuracy: 0.024, precision: 0.196, recall: 0.02, F1-score: 0.111). This suggests relatively good generalization performance overall.  \n",
    "    \n",
    "5. XGBoost: Large positive differences between the train and test scores for all four metrics (accuracy: 0.3, precision: 0.49141, recall: 0.3, F1-score: 0.404). Indicate a significant degree of overfitting on the training data.\n",
    "\n",
    "In summary, a smaller difference between the train score and test score is preferred, as it suggests better generalization performance and less overfitting or underfitting. Models with larger positive differences, like the Random Forest and XGBoost models in this case, are likely overfitting the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At the end of this notebook, we have decided on the following: \n",
    "1. Use PCA with n_components = 30 to reduce our model training time while retaining more than 95% of our information by using explained variance analysis.\n",
    "2. We have tested out both undersampling and oversampling methods. Both produced similar results with undersampling having slight better test scores throughout. It is then a clear choice to use undersampling since undersampling do not artifically increases the train set which in turn increases model training time.\n",
    "3. We did a quick baselining of the various models and have decided to go with Logistic Regression and SVC to hypertune. The other models either see severe overfitting or have lower F1 scores. \n",
    "\n",
    "In the next notebook, we will hypertune both Logistic Regression and SVC to determine which will be used for our classification model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation Scores for Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Create a list of model names\n",
    "models = merged_df['Classifier'].tolist()\n",
    "\n",
    "# Extract the cross-validation scores for each metric\n",
    "cv_scores = merged_df[['cv_accuracy', 'cv_precision', 'cv_recall', 'cv_f1']].values\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set the bar width and positions\n",
    "bar_width = 0.15\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "# Loop through each model and create a bar for each metric\n",
    "for i, model in enumerate(models):\n",
    "    ax.bar(r + i * bar_width, cv_scores[i] * 100, bar_width, label=model)\n",
    "    for j, score in enumerate(cv_scores[i]):\n",
    "        ax.text(r[j] + i * bar_width, score * 100 + 1, '{:.2f}'.format(score * 100), ha='center', fontsize=6)\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks(r + bar_width * 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Score (%)')\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Metric')\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the y-axis limits\n",
    "ax.set_ylim(45, 75)  # Adjust the limits as needed\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Cross-Validation Scores for Baseline Models')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of comparison of the 4 metrics for the 5 baseline models:\n",
    "- Accuracy:\n",
    "For accuracy, Logistic Regression performs the best with a score of around 69.19%, followed closely by Gradient Boosting Classifier at around 68.58%.\n",
    "\n",
    "- Precision:\n",
    "In terms of precision, Logistic Regression achieves the highest score of approximately 72.11%, while Random Forest and XGBoost have relatively lower scores of around 65.69% and 65.98%, respectively.\n",
    "\n",
    "- Recall:\n",
    "For recall, Random Forest has the highest score of around 66.86%, followed by Gradient Boosting Classifier at around 64.62%. Logistic Regression and Support Vector Classifier have slightly lower recall scores.\n",
    "\n",
    "- F1 Score:\n",
    "The F1 scores, which combine precision and recall, show Gradient Boosting Classifier performing the best with a score of around 67.28%, closely followed by Logistic Regression at around 66.98%.\n",
    "\n",
    "Gradient Boosting Classifier appears to be the most consistent performer, achieving high scores in accuracy, precision and F1 scores, while also having a competitive recall score. It is followed closely by Logistic Regression which has the highest scores in accuracy and precision and competitive F1 scores. Support Vector Classifier performs well in accuracy and precision but has lower recall scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Scores for Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Create a list of model names\n",
    "models = merged_df['Classifier'].tolist()\n",
    "\n",
    "# Extract the cross-validation scores for each metric\n",
    "cv_scores = merged_df[['train_accuracy', 'train_precision', 'train_recall', 'train_f1']].values\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set the bar width and positions\n",
    "bar_width = 0.15\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "# Loop through each model and create a bar for each metric\n",
    "for i, model in enumerate(models):\n",
    "    ax.bar(r + i * bar_width, cv_scores[i] * 100, bar_width, label=model)\n",
    "    for j, score in enumerate(cv_scores[i]):\n",
    "        ax.text(r[j] + i * bar_width, score * 100 + 1, '{:.2f}'.format(score * 100), ha='center', fontsize=6)\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks(r + bar_width * 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Score (%)')\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Metric')\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the y-axis limits\n",
    "ax.set_ylim(40, 105)  # Adjust the limits as needed\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Train Scores for Baseline Models')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of comparison of the 4 metrics for the 5 baseline models:\n",
    "- Accuracy:\n",
    "For accuracy, 2 models, namely Random Forest and XGBoost perform exceptionally well on the training data, with scores ranging from around 99.84% for Random Forest to around 96.28% for XGBoost. The other 3 models have lower accuracy ranging from 69.61% to 72.91%.\n",
    "\n",
    "- Precision:\n",
    "In terms of precision, it follows similar trend with accuracy. Random Forest and XGBoost perform exceptionally well on the training data, with scores ranging from 99.84% for Random Forest to 98.54% for XGBoost. The other 3 models have lower accuracy ranging from 72.68% to 75.14%.\n",
    "\n",
    "- Recall:\n",
    "For recall, Random Forest and XGBoost again perform the best, with scores around 99.84% and 93.95%, respectively. Logistic Regression and Support Vector Classifier have lower recall scores of around 62.84% and 65.99%, respectively.\n",
    "\n",
    "- F1 Score:\n",
    "The F1 scores, which combine precision and recall, show a similar pattern. Random Forest and XGBoost have the highest F1 scores of around 99.84% and 96.19%, respectively, while Logistic Regression and Support Vector Classifier have lower F1 scores of around 67.40% and 70.10%, respectively.\n",
    "\n",
    "It is important to note that these scores are obtained on the training data, which means they may not accurately reflect the models' performance on unseen data due to potential overfitting. However, the high scores across most models and metrics suggest that the models are able to learn the patterns in the training data effectively.\n",
    "\n",
    "Random Forest and XGBoost appear to be the top performers on the training data, achieving high scores across all metrics. Logistic Regression and Support Vector Classifier, while still lag behind the two leader in the 4 metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores for Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+cAAAJbCAYAAACGgeUGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACh10lEQVR4nOzdd3QV1d7G8eekF0ghAgkthA4CiqG3BJAmTaKAxgKCFAkiVWlegghEBEQvUgUk0hEEQZGeIEVBivQrvaihCUmQJKTM+weX83IIcAHJmQS+n7XOMmdmz8xvkiHmOXvPHothGIYAAAAAAIBpHMwuAAAAAACAxx3hHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4RwAAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAHIwi8VyT6+YmJh/fKyrV68qMjLyvvZ1+vRpde/eXaVKlZK7u7vy5MmjChUqqHPnzjp9+vQ/rik7+ve//60SJUrIxcVFFotFly9fzrJjffnll5l+1nnz5lVoaKhWrFiRZce9H6GhoQoNDbVZZrFYFBkZafdaYmJirN+nL7/88rZt6tevL4vFoqJFiz7UYxctWlQdOnR4oG3N+n4BAOzLyewCAAAPbuvWrTbvhw8frg0bNmj9+vU2y8uVK/ePj3X16lUNGzZMkjKFrds5c+aMnnnmGfn4+Khv374qXbq04uPjdeDAAS1cuFDHjh1T4cKF/3Fd2cnu3bvVs2dPvfnmm2rfvr2cnJyUO3fuLD/uzJkzVaZMGRmGobi4OE2YMEEtWrTQt99+qxYtWmT58e/X1q1bVahQIdOOnzt3bk2fPj1TWD5+/LhiYmLk5eVlTmEAgMca4RwAcrDq1avbvM+bN68cHBwyLTfDtGnTdOHCBW3btk1BQUHW5c8//7wGDRqkjIwMu9WSlJQkNzc3WSyWLD3O/v37JUmdO3dW1apVH8o+r169Kg8Pj7u2KV++vCpXrmx936RJE/n6+mrevHnZMpybfX22a9dOX3zxhQ4fPqySJUtal8+YMUMFCxZUhQoVdODAARMrBAA8jhjWDgCPuGvXrunDDz9UmTJl5Orqqrx58+qNN97Q+fPnbdqtX79eoaGh8vPzk7u7u4oUKaIXXnhBV69e1YkTJ5Q3b15J0rBhw6xDg+82TPfixYtycHBQvnz5brvewcH2f0E///yzWrRoIT8/P7m5ual48eLq1auXTZtNmzapQYMGyp07tzw8PFSzZk199913Nm1uDPVevXq1OnbsqLx588rDw0MpKSmSpAULFqhGjRry9PRUrly51LhxY+3atctmH8eOHdNLL72kAgUKyNXVVfnz51eDBg20e/fuO55vaGioXn31VUlStWrVMn1/ZsyYoaeeekpubm7KkyePWrdurYMHD9rso0OHDsqVK5f27t2rRo0aKXfu3GrQoMEdj3knbm5ucnFxkbOzs83yYcOGqVq1asqTJ4+8vLz0zDPPaPr06TIMw6bd3a6FG+71urqdW4dp3/iZbdiwQW+99ZaeeOIJ+fn5KSwsTH/88Uem7e/lZ3g3DRs2VOHChTVjxgzrsoyMDM2aNUvt27fPdG1KUnJysgYOHKigoCC5uLioYMGCioiIyHTbQmpqqt599135+/vLw8NDtWvX1rZt225bR1xcnLp27apChQrJxcVFQUFBGjZsmNLS0u5a/9WrV9WvXz8FBQVZr6fKlStr3rx59/w9AABkP4RzAHiEZWRkqFWrVoqKilJ4eLi+++47RUVFac2aNQoNDVVSUpIk6cSJE2rWrJlcXFw0Y8YM/fDDD4qKipKnp6euXbumgIAA/fDDD5KkTp06aevWrdq6davef//9Ox67Ro0aysjIUFhYmFatWqWEhIQ7tl21apXq1KmjU6dOady4cVq5cqWGDBmis2fPWtvExsaqfv36io+P1/Tp0zVv3jzlzp1bLVq00IIFCzLts2PHjnJ2dtZXX32lr7/+Ws7Ozho5cqRefvlllStXTgsXLtRXX32lxMRE1alTx6an9LnnntOOHTs0evRorVmzRpMmTVKlSpXuev/4xIkTNWTIEEnXh5nf/P0ZNWqUOnXqpCeffFJLlizRp59+qj179qhGjRo6fPiwzX6uXbumli1bqn79+lq2bJn1VoK7SU9PV1pamlJTU3XmzBn16tVLf//9t8LDw23anThxQl27dtXChQu1ZMkShYWF6e2339bw4cNt2tztWpDu/bq6X2+++aacnZ01d+5cjR49WjExMdYPPG6415/h3Tg4OKhDhw6Kjo5Wenq6JGn16tU6c+aM3njjjUztDcPQ888/rzFjxui1117Td999pz59+mjWrFmqX7++9YMf6fqoiTFjxuj111/XsmXL9MILLygsLEyXLl2y2WdcXJyqVq2qVatW6V//+pdWrlypTp06adSoUercufNd6+/Tp48mTZqknj176ocfftBXX32lNm3a6OLFi/d0/gCAbMoAADwy2rdvb3h6elrfz5s3z5BkLF682Kbd9u3bDUnGxIkTDcMwjK+//tqQZOzevfuO+z5//rwhyRg6dOg91ZKRkWF07drVcHBwMCQZFovFKFu2rNG7d2/j+PHjNm2LFy9uFC9e3EhKSrrj/qpXr27ky5fPSExMtC5LS0szypcvbxQqVMjIyMgwDMMwZs6caUgyXn/9dZvtT506ZTg5ORlvv/22zfLExETD39/faNu2rWEYhnHhwgVDkjF+/Ph7Os+b3Tj29u3brcsuXbpkuLu7G88991ymelxdXY3w8HDrsvbt2xuSjBkzZtzX8W59ubq6Wn+2d5Kenm6kpqYaH3zwgeHn52f9/t3LtXCv15VhGEZISIgREhJi0+7W6+jGeXTv3t2m3ejRow1Jxp9//mkYxr3/DO9kw4YNhiRj0aJFxrFjxwyLxWKsWLHCMAzDaNOmjREaGmoYhmE0a9bMCAwMtG73ww8/GJKM0aNH2+xvwYIFhiRj6tSphmEYxsGDBw1JRu/evW3azZkzx5BktG/f3rqsa9euRq5cuYyTJ0/atB0zZowhydi/f/8dv1/ly5c3nn/++bueKwAg56HnHAAeYStWrJCPj49atGihtLQ06+vpp5+Wv7+/deb1p59+Wi4uLurSpYtmzZqlY8eO/eNjWywWTZ48WceOHdPEiRP1xhtvKDU1VZ988omefPJJxcbGSpJ+++03HT16VJ06dZKbm9tt9/X333/r559/1osvvqhcuXJZlzs6Ouq1117TmTNn9J///MdmmxdeeMHm/apVq5SWlqbXX3/d5nvh5uamkJAQ6/ciT548Kl68uD7++GONGzdOu3bt+kf3x2/dulVJSUmZbgEoXLiw6tevr3Xr1mXa5tba/5fo6Ght375d27dv18qVK9W+fXtFRERowoQJNu3Wr1+vZ599Vt7e3nJ0dJSzs7P+9a9/6eLFizp37pyke7sW7vW6ul8tW7a0eV+xYkVJ0smTJyXd+8/wXgQFBSk0NFQzZszQxYsXtWzZMnXs2PG2bW9MsHjrz7BNmzby9PS0/gw3bNggSXrllVds2rVt21ZOTrbT/KxYsUL16tVTgQIFbM6ladOmkmT993E7VatW1cqVKzVgwADFxMQ88EgFAED2QjgHgEfY2bNndfnyZev9xze/4uLidOHCBUlS8eLFtXbtWuXLl08REREqXry4ihcvrk8//fQf1xAYGKi33npL06dP1+HDh7VgwQIlJyerf//+kmS9R/lus3dfunRJhmEoICAg07oCBQpIUqYhvbe2vTFEvkqVKpm+FwsWLLB+LywWi9atW6fGjRtr9OjReuaZZ5Q3b1717NlTiYmJ933+N+q6U+231u3h4XHfs4WXLVtWlStXVuXKldWkSRNNmTJFjRo10rvvvmsdir9t2zY1atRI0vXJ+jZv3qzt27dr8ODBkmQNePdyLdzrdXW//Pz8bN67urra1HavP8N71alTJy1fvlzjxo2Tu7u7Xnzxxdu2u3jxopycnKzzLtxgsVjk7+9v/Rne+K+/v79NOycnp0zndvbsWS1fvjzTeTz55JOSdNdz+eyzz/Tee+9p6dKlqlevnvLkyaPnn38+0y0SAICchdnaAeARdmNirRv3i9/q5sd81alTR3Xq1FF6erp++eUX/fvf/1avXr2UP39+vfTSSw+tprZt22rUqFHat2+fJFkDz5kzZ+64ja+vrxwcHPTnn39mWndjwrAnnnjCZvmtM7PfWP/1118rMDDwrjUGBgZq+vTpkq737C9cuFCRkZG6du2aJk+efNdtb3UjlN2p9v9V94OqWLGiVq1apd9++01Vq1bV/Pnz5ezsrBUrVtiMUFi6dGmmbf/XtXA/19XDdD8/w3sRFhamiIgIRUVFqXPnznJ3d79tOz8/P6Wlpen8+fM2Ad3476PrqlSpYm0nXb+fvGDBgtZ2aWlpmT6EeeKJJ1SxYkWNGDHitse88aHT7Xh6emrYsGEaNmyYzp49a+1Fb9GihQ4dOnRvJw8AyHYI5wDwCGvevLnmz5+v9PR0VatW7Z62cXR0VLVq1VSmTBnNmTNHO3fu1EsvvZSpF/N/+fPPP2/bW3zlyhWdPn3aGj5KlSql4sWLa8aMGerTp4/1ODfz9PRUtWrVtGTJEo0ZM8YaojIyMjR79mwVKlRIpUqVums9jRs3lpOTk44ePXpfw8ZLlSqlIUOGaPHixdq5c+c9b3dDjRo15O7urtmzZ6tNmzbW5WfOnNH69evv2Fv7T92YWf5GmLRYLHJycpKjo6O1TVJSkr766qs77uNO18KDXFcPw4P+DO/E3d1d//rXv7Rx40a99dZbd2zXoEEDjR49WrNnz1bv3r2tyxcvXqy///7bOqN+aGioJGnOnDkKDg62tlu4cGGmGdibN2+u77//XsWLF5evr+8Dn0P+/PnVoUMH/frrrxo/fvw9PXoPAJA9Ec4B4BH20ksvac6cOXruuef0zjvvqGrVqnJ2dtaZM2e0YcMGtWrVSq1bt9bkyZO1fv16NWvWTEWKFFFycrL1MVPPPvuspOu9oYGBgVq2bJkaNGigPHny6IknnlDRokVve+wRI0Zo8+bNateunZ5++mm5u7vr+PHjmjBhgi5evKiPP/7Y2vbzzz9XixYtVL16dfXu3VtFihTRqVOntGrVKs2ZM0fS9RnPGzZsqHr16qlfv35ycXHRxIkTtW/fPs2bN+9/9jgXLVpUH3zwgQYPHqxjx45ZnwV+9uxZbdu2zdobuWfPHvXo0UNt2rRRyZIl5eLiovXr12vPnj0aMGDAff8MfHx89P7772vQoEF6/fXX9fLLL+vixYsaNmyY3NzcNHTo0Pve56327dtnDX8XL17UkiVLtGbNGrVu3dr6jPlmzZpp3LhxCg8PV5cuXXTx4kWNGTMm04ch93It3Ot19bDd68/wfvTp00d9+vS5a5uGDRuqcePGeu+995SQkKBatWppz549Gjp0qCpVqqTXXntN0vXbC1599VWNHz9ezs7OevbZZ7Vv3z6NGTMm060KH3zwgdasWaOaNWuqZ8+eKl26tJKTk3XixAl9//33mjx58h1v9ahWrZqaN2+uihUrytfXVwcPHtRXX32lGjVqEMwBICcze0Y6AMDDc+ts7YZhGKmpqcaYMWOMp556ynBzczNy5cpllClTxujatatx+PBhwzAMY+vWrUbr1q2NwMBAw9XV1fDz8zNCQkKMb7/91mZfa9euNSpVqmS4urpmmn36Vj/99JMRERFhPPXUU0aePHkMR0dHI2/evEaTJk2M77//PlP7rVu3Gk2bNjW8vb0NV1dXo3jx4plmvf7xxx+N+vXrG56enoa7u7tRvXp1Y/ny5TZtbjdj+s2WLl1q1KtXz/Dy8jJcXV2NwMBA48UXXzTWrl1rGIZhnD171ujQoYNRpkwZw9PT08iVK5dRsWJF45NPPjHS0tLueL7/69hffPGFUbFiRcPFxcXw9vY2WrVqZTMjt2Hc/ud3L8e7+eXt7W08/fTTxrhx44zk5GSb9jNmzDBKly5tuLq6GsWKFTNGjRplTJ8+3ZBknUH/Xq+Fe7muDOP+Zmu/9ft2Y3b1DRs22Cz/Xz/DO7l5tva7uXW2dsMwjKSkJOO9994zAgMDDWdnZyMgIMB46623jEuXLtm0S0lJMfr27Wvky5fPcHNzM6pXr25s3brVCAwMzPTv5fz580bPnj2NoKAgw9nZ2ciTJ48RHBxsDB482Lhy5codv18DBgwwKleubPj6+lp/lr179zYuXLhw1/MCAGRvFsMwDFM+FQAAAAAAAJKYrR0AAAAAANMRzgEAAAAAMBnhHAAAAAAAkxHOs0jRokVlsVgyvSIiIiRJHTp0yLSuevXqJlcNAAAAADADj1LLItu3b1d6err1/b59+9SwYUObZ9w2adJEM2fOtL53cXGxa40AAAAAgOyBcJ5F8ubNa/M+KipKxYsXV0hIiHWZq6ur/P397V0aAAAAACCbIZzbwbVr1zR79mz16dNHFovFujwmJkb58uWTj4+PQkJCNGLECOXLl++O+0lJSVFKSor1fUZGhv766y/5+fnZ7BcAAADA48UwDCUmJqpAgQJycODu5ZyI55zbwcKFCxUeHq5Tp06pQIECkqQFCxYoV65cCgwM1PHjx/X+++8rLS1NO3bskKur6233ExkZqWHDhtmzdAAAAAA5yOnTp1WoUCGzy8ADIJzbQePGjeXi4qLly5ffsc2ff/6pwMBAzZ8/X2FhYbdtc2vPeXx8vIoUKaLTp0/Ly8vrodcNAAAAIGdISEhQ4cKFdfnyZXl7e5tdDh4Aw9qz2MmTJ7V27VotWbLkru0CAgIUGBiow4cP37GNq6vrbXvVvby8COcAAAAAuN01B+NmhCw2c+ZM5cuXT82aNbtru4sXL+r06dMKCAiwU2UAAAAAgOyCcJ6FMjIyNHPmTLVv315OTv8/SOHKlSvq16+ftm7dqhMnTigmJkYtWrTQE088odatW5tYMQAAAADADAxrz0Jr167VqVOn1LFjR5vljo6O2rt3r6Kjo3X58mUFBASoXr16WrBggXLnzm1StQAAAAAAszAhXA6WkJAgb29vxcfHc885AAAA8BgjG+R8DGsHAAAAAMBkhHMAAAAAAExGOAcAAAAAwGSEcwAAAAAATEY4BwAAAADAZIRzAAAAAABMRjgHAAAAAMBkhHMAAAAAAExGOAcAAAAAwGROZheAR9O2bdv07rvvSpL+/PNPPffcc9q/f7+Sk5Pl6OiomTNnqmjRotb2p06d0uuvvy7DMOTh4aF58+bJx8dHixcvVlRUlBwcHPTmm2+qc+fOJp0RAAAAAGQdi2EYhtlF4MEkJCTI29tb8fHx8vLyMrucO3rzzTf12muvqUSJEipYsKBWr16tZcuW6fPPP7e2uXz5sjIyMpQnTx5NnTpV8fHx6t+/vypXrqz169fLw8NDwcHB+vXXX008EwAAACB7yinZAHdGzzmyVFpamn766SdNnTpVDg7X76JwdnaWk5Ptpefj42P9+ub1ZcqUUWJioiwWi7y9ve1WNwAAAADYE+EcWWr9+vUKCQmxBvPU1FR98MEH+uKLL27bPj4+XlOmTNHKlSslSW3atFGVKlXk6OioYcOG2a1uAAAAALAnJoRDllq0aJHatGljfd+lSxd169ZNxYsXz9Q2NTVV4eHhGjNmjHx9fSVJgwYN0r59+3T06FHNnDlTly5dslvtAAAAAGAvhHNkmbS0NG3dulV169aVJH344YcKCgpSu3btbtu+e/fuatu2rWrXrm1d5uLioly5csnFxUUODg5KTk62S+0AAAAAYE+Ec2SZDRs2qG7dunJwcNAff/yhYcOGaf369QoNDdXAgQMlSVFRUTp+/Li2bt2quXPnaubMmQoNDdWnn34qSerfv7/q1Kmj6tWrKyQkRAEBAWaeEgAAAABkCWZrz8GYkREAAACARDZ4FNBzDgAAAACAyQjnAAAAAACYjHAOAAAAAIDJCOcAAAAAAJiMcA4AAAAAgMkI5wAAAAAAmIxwDjygbdu2KTQ0VKGhoSpdurR69+6tN954Q3nz5tWECRNuu03Dhg3l4+OjFStWWJfNmzfP+hz3/fv326t8AAAAANmIk9kFADlV1apVFRMTI0l688039fzzz6tUqVIKCQnRlStXbrtNdHS0pkyZYn2flpam0aNHa9u2bTp37pzeeustffvtt/YoHwAAAEA2Qs858A+lpaXpp59+Up06dRQQEHDXtreuv3jxogoVKiRnZ2cVLFhQv/32W1aWCgAAACCboucc+IfWr1+vkJAQOTjc/2ddefPm1alTpxQfH68zZ87oyJEjSk1NlbOzcxZUCgAAACC7IpwD/9CiRYv0yiuvPNC2Dg4OioqKUsuWLVW0aFFVr16dYA4AAAA8hhjWDvwDaWlp2rp1q+rWrfvA+2jatKliY2M1ePBgVaxY8SFWBwAAACCnoOccD03RAd/Z9XgnoprZ9Xi3s2HDBtWtW9c6pH3gwIH69ttvlZ6erqNHj+qTTz5RVFSU2rVrp6CgIHXs2FExMTFaunSp9u3bpwEDBqhXr17as2eP/Pz8NHnyZJPPCAAAAIAZLIZhGGYXgQeTkJAgb29vxcfHy8vLy+xyHstwDgAAAGQH2S0b4P4xrB0AAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOgRxi27ZtCg0NVWhoqEqXLq3evXtrwYIFqlGjhurXr6/Tp0/fdrutW7fKYrHoypUrkqQhQ4aoQIEC6tevnz3LBwAAAHAXhHMgh6hatapiYmIUExOjOnXq6Pnnn9e4ceMUGxur4cOHa/jw4bfd7rPPPlNwcLD1fY8ePTRnzhx7lQ0AAADgHhDOgRwmLS1NP/30k/Lmzasnn3xSLi4uqlWrlvbu3Zup7aZNm1SxYkXlypXLuszf318Wi8WeJQMAAAD4HwjnQA6zfv16hYSE6PLlyzaPyUhPT8/U9tNPP1WPHj3sWR4AAACAB0A4B3KYRYsWqU2bNvL19VVCQoJ1uaOjo0272NhYPfXUU8qdO7e9SwQAAABwnwjnQA6SlpamrVu3qm7duipRooQOHDiga9euafPmzapYsaJN219//VXr1q1TkyZNtGfPHnXs2NGkqgEAAAD8L05mFwDg3m3YsEF169aVg4ODHBwc1KtXL4WEhMjNzU3R0dGSpKioKLVr1049e/ZUz549JUmhoaGaMWOGpOtD3aOjo3XhwgX9/vvvmjdvnmnnAwAAAOA6i2EYhtlF4MEkJCTI29tb8fHxNvcem6XogO/serwTUc3sejwAAAAgu8pu2QD3j2HtAAAAAACYjGHtwH2oMKuCXY+3t33mx6MBAAAAePTQcw4AAAAAgMkI5wAAAAAAmIxwDgAAAACAyQjnAAAAAACYjHAOAAAAAIDJCOcAAAAAAJiMcA4AAAAAgMkI5wAAAAAAmIxwDgAAAACAyZzMLgDAnR0sU9auxyt76KBdjwcAAADgOnrOAQAAAAAwGeE8ixQtWlQWiyXTKyIiQpJkGIYiIyNVoEABubu7KzQ0VPv37ze5agAAAACAGQjnWWT79u36888/ra81a9ZIktq0aSNJGj16tMaNG6cJEyZo+/bt8vf3V8OGDZWYmGhm2QAAAAAAExDOs0jevHnl7+9vfa1YsULFixdXSEiIDMPQ+PHjNXjwYIWFhal8+fKaNWuWrl69qrlz55pdOgAAAADAzgjndnDt2jXNnj1bHTt2lMVi0fHjxxUXF6dGjRpZ27i6uiokJERbtmy5435SUlKUkJBg8wIAAAAA5HyEcztYunSpLl++rA4dOkiS4uLiJEn58+e3aZc/f37rutsZNWqUvL29ra/ChQtnWc0AAAAAAPshnNvB9OnT1bRpUxUoUMBmucVisXlvGEamZTcbOHCg4uPjra/Tp09nSb0AAAAAAPviOedZ7OTJk1q7dq2WLFliXebv7y/peg96QECAdfm5c+cy9abfzNXVVa6urllXLAAAAADAFPScZ7GZM2cqX758atasmXVZUFCQ/P39rTO4S9fvS4+NjVXNmjXNKBMAAAAAYCJ6zrNQRkaGZs6cqfbt28vJ6f+/1RaLRb169dLIkSNVsmRJlSxZUiNHjpSHh4fCw8NNrBgAAAAAYAbCeRZau3atTp06pY4dO2Za9+677yopKUndu3fXpUuXVK1aNa1evVq5c+c2oVIAAAAAgJkI51moUaNGMgzjtussFosiIyMVGRlp36IAAAAAANkO95wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAmCwmJkYNGjRQSEiIli1bpjNnzqhly5YKDQ3VsGHDbNqeOnVKoaGhCg0N1VNPPaXWrVtLki5fvqyXX35Z9erVU7du3cw4DQDAP+BkdgEAAACPs+TkZI0dO1YrV66Ui4uLJOnll1/WpEmTVLBgwUztixQpopiYGEnShx9+qMKFC0uShg4dqnfffVeVKlWyW+0AgIeHnnMAAJCt3U+vsiTlzp3b2rO8d+9eSdLixYtVpUoVVatWTdOmTbP3KdzVli1b5O7urhYtWqh169Y6ffq0Tpw4ob59+6p+/frasmXLHbddtmyZWrVqJUnatWuXJk6cqNDQUC1dutRO1QMAHhZ6zgEAQLZ1v73KklS6dGlrz/INo0aN0vr16+Xh4aHg4GB17tw5q0u/Z2fPntXx48e1efNmrVu3Th9++KH27NmjRYsWycnJSS1bttS2bdsybffbb78pX7588vHxkSRt27ZN48ePV6lSpVS3bl01bdpUrq6udj4bAMCDouccAABkWw/Sq3z06FHVrVtXb731lpKTkyVJZcqUUWJiopKSkuTt7W3v07grHx8f1a5dWy4uLqpfv7527typUqVKqVChQvL395eTk5PS0tIybbdo0SK1adPG+r5o0aJ65plnlCtXLpUuXVq///67PU8DAPAPEc4BAEC2daNXefny5erSpYu1V3nMmDGaO3euevXqlWmbI0eOaOPGjQoICNDEiRMlSW3atFGVKlVUrlw5dejQwb4n8T9UrVpVBw4ckHR9aPqTTz4pHx8fxcfH6++//9a1a9fk5JR5sOPNQ9olqXz58jp+/LjS09N19OhR+fv72+0cAAD/HMPaAQBAtnVrr/K//vUva6+yJGuv8s3h1c/PT9L1QD5q1ChJ0qBBg7Rv3z7lypVLDRo0UOvWreXr62v/E7oNPz8/tWzZUnXr1pWDg4NmzJihuLg4NW/eXKmpqRo+fLgkKSoqSu3atVNQUJAOHz6sJ554wuYcRowYoY4dOyopKUndunWTh4eHWacEAHgAhHMAAJBtVa1aVePHj5f0/73KJ0+eVHx8vJycnDL1Kv/9999yc3OTo6OjNm7cqBIlSkiSXFxclCtXLrm4uMjBwcE63D27iIiIUEREhPV9sWLF9OOPP9q0GTBggPXrkiVL6vvvv7dZX7p0aW3YsCFrCwUAZBnCOQAAyLbut1c5Pj5eHTt2VK5cueTr66vo6GhJUv/+/VWnTh1ZLBY1atRIAQEBZp4WAACZWAzDMMwuAg8mISFB3t7eio+Pl5eXl9nlqOiA7+x6vBNRzex6PEmqMKuCXY+3cFTmCYCyUtlDB+16PAAAADwc2S0b4P4xIRwAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAgPsSExOjBg0aKCQkRMuWLVPJkiUVGhqq0NBQrVmz5rbbbN26VRaLRVeuXJEkLV68WFWqVFG1atU0bdo0e5YPAEC2RDgHAAD3LDk5WWPHjtXKlSsVGxurVq1aydvbWzExMYqJiVHDhg1vu91nn32m4OBg6/tRo0Zp3bp12rx5syZMmGCv8u/J/Xz4cOHCBdWqVUshISGqV6+e/vjjD0nSvHnzVL16dYWEhGj//v1mnAYAIIdxMrsAAACQc2zZskXu7u5q0aKFPDw8NGnSJF25ckUhISEqWLCgJkyYoDx58thss2nTJlWsWFF//vmndVmZMmWUmJgoi8Uib29ve5/GHd384YOLi4skafjw4YqJiblte19fX23cuFGOjo6aNWuWpk+froEDB2r06NHatm2bzp07p7feekvffvutzXYHy5TN6lOxUfbQQbseDwBw/+g5BwAA9+zs2bM6fvy4li9fri5duigyMlKbN29WbGysmjRposjIyEzbfPrpp+rRo4fNsjZt2qhKlSoqV66cOnToYJ/i78HNHz60bt1acXFx1g8fwsPD9ddff9m0d3R0lKOjoyQpISFB5cuX18WLF1WoUCE5OzurYMGC+u2338w4FQBADkM4BwAA98zHx0e1a9eWi4uL6tevrwMHDsjPz0/S9cC9e/dum/axsbF66qmnlDt3bpvlgwYN0r59+3T06FHNnDlTly5dstcp3NWDfPiwd+9eVatWTRMmTFClSpWUN29enTp1SvHx8dq/f7+OHDmi1NRU+58MACBHYVg7gDuKiYnR8OHDlZaWpj59+qhfv34qWLCgJGnw4MGZ7i395JNP9PXXX8vX11dz5syRt7e3wsLC9Ndff8kwDO3Zsyfb/AEO4MFUrVpV48ePlyTt2rVLhQoVUkpKilxdXbVx40aVKFHCpv2vv/6qdevWadOmTdqzZ486duyohQsXysXFRbly5ZKLi4scHByUnJz8/xtF2nmYe2S89ctbP3wYNWqUzYcPX3zxRabNK1SooJ9//lkLFy5UVFSUJk+erKioKLVs2VJFixZV9erV5ezsbLfTAQDkTIRzALd1v/ddnj9/XsuXL9emTZs0d+5cff755xo0aJCWLFki6fo9p9OnT7dX+QCyiJ+fn1q2bKm6devKwcFBH330kWrWrClPT0+5urpqxowZkqSoqCi1a9dOPXv2VM+ePSVJoaGh1vX9+/dXnTp1ZLFY1KhRIwUEBJh2Tje73w8frl27Zv0d6e3tLU9PT0lS06ZN1bRpU/3222/W/QEAcDeEcwC3db+TPm3fvl2hoaGyWCxq0qSJ2rdvb7O/RYsWqU2bNvY+DQBZICIiQhEREdb3O3bsyNRmwIABmZbd/OFeeHi4wsPDs6S+f+J+P3z466+/1Lt3bzk6OsrDw8P6IWSvXr20Z88e+fn5afLkyWaeEgAghyCcA7itG/ddbt68WevWrbPed+nn56fo6GhFRkbqs88+s7a/fPmyvLy8JF3vPbp50iTDMLRu3Tp9/PHHdj8PALhf9/PhQ1BQkDZu3JhpPb3lAID7xYRwAG7rfid98vX1VUJCgqTrQf3mXvUtW7aocuXK1qGfAAAAAGwRzgHcVtWqVXXgwAFJtvddSrrtfZeVK1e2DlldtWqVatWqZV3HkHYAAADg7hjWDuC27ve+y6CgILVo0UK1atWyztYuXR/SvnbtWo0ePdrM0wEAAACyNYthGIbZReDBJCQkyNvbW/Hx8dZ7fc1UdMB3dj3eiahmdj2eJFWYVcGux1s4Ks2uxyt76KBdjwcAt2Xio9Ts5WCZsnY9Hr/fgUdfdssGuH8MawcAAAAAwGSEczwyYmJi1KBBA4WEhGjZsmWSpFOnTsnV1VX79u2zaXvhwgXVqlVLISEhqlevnv744w9J0rx581S9enWFhIRo//79dj8HAAAAAI8n7jnHIyE5OVljx47VypUrbWYE/+ijj2wmJrvB19dXGzdulKOjo2bNmqXp06dr4MCBGj16tLZt26Zz587prbfe0rfffmvP0wAAAADwmCKc45GwZcsWubu7q0WLFvLw8NCkSZOUlJQki8WiIkWKZGrv6Oho/TohIUHly5fXxYsXVahQITk7O6tgwYL67bff7HkKAAAAAB5jhHM8Es6ePavjx49r8+bNWrdunSIjIyVJAwYMsH59q7179+rNN9/U5cuXtWrVKuXNm1enTp1SfHy8zpw5oyNHjig1NVXOzs72OxEAAAAAjyXuOccjwcfHR7Vr15aLi4vq16+v7767PnN80aJF77hNhQoV9PPPP2v48OGKioqSg4ODoqKi1LJlS40ePVrVq1cnmAMAAACwC3rO8UioWrWqxo8fL0natWuX4uPjtX//fjVp0kR79+7VkSNHtGHDBmvYvnbtmvXedG9vb3l6ekqSmjZtqqZNm+q3336z7g8AHnd2f1Smm10PBwBAtkA4xyPBz89PLVu2VN26deXg4KDdu3erWLFikqQOHTqoX79+cnZ2VlRUlNq1a6e//vpLvXv3lqOjozw8PDR9+nRJUq9evbRnzx75+flp8uTJZp4SAAAAgMeIxTAMw+wi8GASEhLk7e2t+Ph4eXl5mV2O/XtWoprZ9XiSVGFWBbseb+GoNLser+yhg3Y9HoCcwf495+F2PV6FoMwTh2Y1fr8DeNiyWzbA/eOe8yz0+++/69VXX5Wfn588PDz09NNPa8eOHdb1HTp0kMVisXlVr17dxIoBAAAAAGZgWHsWuXTpkmrVqqV69epp5cqVypcvn44ePSofHx+bdk2aNNHMmTOt729+RjcAAAAA4PFAOM8iH330kQoXLmwTvG83c7irq6v8/f3tWBkAAAAAILshnGeRb7/9Vo0bN1abNm0UGxurggULqnv37urcubNNu5iYGOXLl08+Pj4KCQnRiBEjlC9fvtvuMyUlRSkpKdb3CQkJWXoOePx83m29XY8XMbm+XY8HAAAAZFfcc55Fjh07pkmTJqlkyZJatWqVunXrpp49eyo6OtrapmnTppozZ47Wr1+vsWPHavv27apfv75NAL/ZqFGj5O3tbX0VLlzYXqcDAAAAAMhC9JxnkYyMDFWuXFkjR46UJFWqVEn79+/XpEmT9Prrr0uS2rVrZ21fvnx5Va5cWYGBgfruu+8UFhaWaZ8DBw5Unz59rO8TEhII6AAAAADwCKDnPIsEBASoXLlyNsvKli2rU6dO3XWbwMBAHT58+LbrXV1d5eXlZfMCAAAAAOR8hPMsUqtWLf3nP/+xWfbbb78pMDDwjttcvHhRp0+fVkBAQFaXBwAAAADIRgjnWaR379766aefNHLkSB05ckRz587V1KlTFRERIUm6cuWK+vXrp61bt+rEiROKiYlRixYt9MQTT6h169YmVw8AAAAAsCfCeRapUqWKvvnmG82bN0/ly5fX8OHDNX78eL3yyiuSJEdHR+3du1etWrVSqVKl1L59e5UqVUpbt25V7ty5Ta4eAAA8ymJiYtSgQQOFhIRo2bJlqlu3rkJDQ1WzZk3t27cvU/uGDRvKx8dHK1assC4bMmSIChQooH79+tmzdAB4ZDEhXBZq3ry5mjdvftt17u7uWrVqlZ0rAgAAj7vk5GSNHTtWK1eulIuLiyTpueeek7Ozs2JjY/XJJ59o+vTpNttER0drypQpNst69OihBg0a6LvvvrNb7QDwKKPnHAAA4DGyZcsWubu7q0WLFmrdurXi4uLk7Ows6fqTYCpUqJBpm9vNh+Pv7y+LxZLl9QLA44Kec+Rckd72P2ZQEfsfEwCAh+js2bM6fvy4Nm/erHXr1ikyMlLDhw/X888/r1OnTmnZsmVmlwgAjyV6zgEAAB4jPj4+ql27tlxcXFS/fn0dOHBAefPm1ebNm7V48WINGjTI7BIB4LFEOAcAAHiMVK1aVQcOHJAk7dq1S0WKFFFGRoYkydvbW56enmaWBwCPLYa1AwAAPEb8/PzUsmVL1a1bVw4ODhoxYoTq1asnBwcHOTg46PPPP5ckRUVFqV27dgoKClLHjh0VExOjpUuXat++fRowYIA+/fRTRUdH68KFC/r99981b948k88MAHI2wjkAAMBjJiIiQhEREdb3sbGxmdoMGDDA+vWMGTMyrX/nnXf0zjvvZE2BAPAYYlg7AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMiezCwAAAEDW+rzberseL2JyfbseLyvFxMRo+PDhSktLU58+fbR06VKtWLFCQ4cOVY8ePTK137dvn/r27avk5GSFh4era9eueuGFF3Tu3DllZGTos88+U3BwsAlnAiC7I5wDAAAAt5GcnKyxY8dq5cqVcnFxkSRVrVpVISEhunLlym23GThwoBYtWiQvLy/rso8//ljFihXTb7/9pt69e+u7776zS/0AchaGtQMAAAC3sWXLFrm7u6tFixZq3bq14uLiFBAQcMf2x44dU2pqql599VU1btxYhw4dkiQVK1ZMkuTs7CwnJ/rGANwevx0AAACA2zh79qyOHz+uzZs3a926dYqMjNTkyZPv2n7//v3av3+/Tp06pT59+uj777+3ru/fv7/69+9vj9IB5ED0nAMAAAC34ePjo9q1a8vFxUX169fXgQMH/mf7ypUry8vLS+XLl9eFCxes64YOHapq1aqpdu3aWV02gByKcA4AAADcRtWqVa2BfNeuXdbh6XdSsmRJnT9/XqmpqTpz5oz1vvPZs2frzJkz9JoDuCuGtQMAAAC34efnp5YtW6pu3bpycHDQjBkzNHDgQH377bdKT0/X0aNH9cknnygqKkrt2rVTUFCQ+vTpo3r16llnZpekTp06qXLlygoNDVVQUJBmzpxp8pkByI4I5wAAAMAdREREKCIiwvp+1KhRGjVqlE2bAQMGWL8OCwtTWFiYzfqUlJSsLRLAI4Fh7QAAAAAAmIxwDgAAAACAyQjnAAAAAACYjHAOAAAAAIDJCOcAAADAYyomJkYNGjRQSEiIli1bpgULFqhGjRqqX7++Tp8+nan9vn371LhxY4WEhGjKlCmSpMWLF6tKlSqqVq2apk2bZu9TAB4ZzNYOAAAAPIaSk5M1duxYrVy5Ui4uLkpNTVXt2rX1448/avv27Ro+fLimTp1qs83AgQO1aNEi6zPcpesz2K9fv14eHh4KDg5W586d7X0qwCOBnnMAAADgMbRlyxa5u7urRYsWat26tbZv364nn3xSLi4uqlWrlvbu3WvT/tixY0pNTdWrr76qxo0b69ChQ5KkMmXKKDExUUlJSfL29r7rMe+3pz537twKDQ1VaGioTT1XrlxR3rx5tWLFiofwnQCyB3rOAQAAgMfQ2bNndfz4cW3evFnr1q1TZGSkypUrZ12fnp6eqf3+/fu1f/9+nTp1Sn369NH333+vNm3aqEqVKnJ0dNSwYcPueLwH6akvXbq0YmJiMu3rs88+U3Bw8D/7BgDZDD3nAAAAwGPIx8dHtWvXlouLi+rXr69du3YpISHBut7R0TFT+8qVK8vLy0vly5fXhQsXJEmDBg3Svn37dPToUc2cOVOXLl267fHut6deko4ePaq6devqrbfeUnJysiQpISFBe/fuVfXq1R/WtwLIFgjnAAAAwGOoatWqOnDggCRp165datSokQ4cOKBr165p8+bNqlixok37kiVL6vz580pNTdWZM2es9527uLgoV65ccnFxkYODgzVE3+pGT/3y5cvVpUsXRUZG2ty7fmtPvSQdOXJEGzduVEBAgCZOnChJ+vTTT9WjR4+H8j0AshOGtQMAAACPIT8/P7Vs2VJ169aVg4ODZsyYoW3btikkJERubm6Kjo6WJEVFRaldu3YKCgpSnz59VK9ePWVkZOizzz6TJPXv31916tSRxWJRo0aNFBAQcNvj3dpT//rrr6tQoULW9bf21N+oUZLatGmjUaNGKT4+Xnv27NH777+vNWvWPOxvCWAqwjkAAADwX0UHfGfX452IambX490qIiJCERER1vfFihXTSy+9ZNNmwIAB1q/DwsIUFhZmsz48PFzh4eH/81hVq1bV+PHjJWXuqd++fXumnvq///5bbm5ucnR01MaNG1WiRAkdOnRIp0+fVpMmTXTkyBEtX75cTz/9tE3IB3IqwjkAAACALHe/PfXx8fHq2LGjcuXKJV9fX0VHR8vb21s//fSTJCkyMlKVK1cmmOORQTgHAAAAYBf321O/c+fOO+4rMjLyodcHmIkJ4QAAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4RwAAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTOZldAAAAAAD7qDCrgl2Pt7f9XrseD8jJ6DkHAAAAAMBk9JwDAAAAyBIHy5S1+zHLHjpo92MCDwM95wAAAAAAmIxwDgAAAACAyQjnWej333/Xq6++Kj8/P3l4eOjpp5/Wjh07rOsNw1BkZKQKFCggd3d3hYaGav/+/SZWDAAAAAAwA+E8i1y6dEm1atWSs7OzVq5cqQMHDmjs2LHy8fGxthk9erTGjRunCRMmaPv27fL391fDhg2VmJhoXuEAAAAAALtjQrgs8tFHH6lw4cKaOXOmdVnRokWtXxuGofHjx2vw4MEKCwuTJM2aNUv58+fX3Llz1bVrV3uXDAAAAAAwCT3nWeTbb79V5cqV1aZNG+XLl0+VKlXStGnTrOuPHz+uuLg4NWrUyLrM1dVVISEh2rJly233mZKSooSEBJsXAAAAACDnI5xnkWPHjmnSpEkqWbKkVq1apW7duqlnz56Kjo6WJMXFxUmS8ufPb7Nd/vz5retuNWrUKHl7e1tfhQsXztqTAAAAAADYBeH8LlJSUh5424yMDD3zzDMaOXKkKlWqpK5du6pz586aNGmSTTuLxWLz3jCMTMtuGDhwoOLj462v06dPP3B9AAAAAIDsg3B+k1WrVqlDhw4qXry4nJ2d5eHhody5cyskJEQjRozQH3/8cc/7CggIULly5WyWlS1bVqdOnZIk+fv7S1KmXvJz585l6k2/wdXVVV5eXjYvAAAAAEDORziXtHTpUpUuXVrt27eXg4OD+vfvryVLlmjVqlWaPn26QkJCtHbtWhUrVkzdunXT+fPn/+c+a9Wqpf/85z82y3777TcFBgZKkoKCguTv7681a9ZY11+7dk2xsbGqWbPmwz1BAAAAAEC2xmztkkaOHKkxY8aoWbNmcnDI/HlF27ZtJV1/bvmnn36q6Oho9e3b96777N27t2rWrKmRI0eqbdu22rZtm6ZOnaqpU6dKuj6cvVevXho5cqRKliypkiVLauTIkfLw8FB4ePjDP0kAWebEiROqUqWKnnzySUnSokWLtGDBAkVHR8tisWjIkCFq0aKFtf2pU6f0+uuvyzAMeXh4aN68efLx8VFsbKwGDBggBwcHTZw4UU899ZRZpwQAAAA7I5xL2rZt2z21K1iwoEaPHn1PbatUqaJvvvlGAwcO1AcffKCgoCCNHz9er7zyirXNu+++q6SkJHXv3l2XLl1StWrVtHr1auXOnfuBzgOAeUJCQvT1119b30+cOFF79uzR1atX1bhxY5tw7uXlpSVLlihPnjyaOnWqpk2bpv79+2vIkCH6/vvvlZiYqK5du2rlypVmnAoAAABMQDj/H65cuaKMjIwHur+7efPmat68+R3XWywWRUZGKjIy8h9UCCA72Lx5s+rUqaM6depoxIgRKlGihJKSkpSYmCg/Pz+btj4+PtavnZ2d5eTkpKtXr8rZ2Vm+vr7y9fXVpUuX7HwGAAAAMBP3nN/BgQMHVLlyZXl5ecnX11cVKlTQL7/8YnZZALKhgIAAHTlyRBs3btS5c+f0zTffqEmTJipXrpyqVKminj173na7+Ph4TZkyRR06dNDly5dtPgR0cnLStWvX7HUKAAAAMBnh/A66du2qHj166MqVK7p48aLCwsLUvn17s8sCkA25urrK09NTFotFL7zwgjZt2qSpU6fq8OHDOnTokAYNGiTDMGy2SU1NVXh4uMaMGWPtLU9ISLCuT0tLk4uLi71PBQAAACYhnP9Xq1at9Pvvv1vfnz9/Xi1btpSHh4d8fHz03HPP6ezZsyZWCCC7SkxMtH69ceNGPf3003Jzc5Orq6s8PDyUkpKSKZx3795dbdu2Ve3atSVJ7u7uSk1N1aVLl3Tq1KlMQ+EBAADwaOOe8/965ZVXVK9ePfXo0UNvv/22evTooSeffFIhISFKTU3V+vXr/+cM7QAeT5s2bdKQIUPk4eGhoKAgDR8+XOfOnVONGjWUnp6uiIgIOTg4KCoqSu3atVNcXJzmzp2rw4cPa+bMmWrdurXeeecdffjhh3ruueess7UDAADg8UE4/6+2bduqUaNGeu+991StWjVNmTJFq1evVkxMjNLT0zVgwABVqVLF7DIBZENNmzZV06ZNbZb169dP/fr1s1k2YMAASVJQUJD+/vvvTPsJCQnR1q1bs65QAAAAZFuE85v4+PhoypQp2rRpk9q3b6+GDRtq+PDh8vDwMLs0AAAAAMAjjHvOb3Lp0iXt2LFDFSpU0I4dO5Q7d25VqlRJ3333ndmlAQAAAAAeYYTz/1qwYIEKFiyoZs2aKTAwUCtXrlRkZKSWLVum0aNHq23btkwIBwAAAADIEoTz/3rvvfc0Y8YMxcXFad26dXr//fclSWXKlFFsbKyeffZZ1ahRw+QqAQAAAACPIsL5fyUmJqp06dKSpOLFi+vq1as267t06aKffvrJjNIAAAAAAI84JoT7r/bt26tZs2YKDQ3VL7/8otdeey1Tm3z58plQGQAAAADgUUc4/69x48apXr16OnTokDp06KBGjRqZXRIAAAAA4DFBOL9JixYt1KJFC7PLAAAAAAA8ZrjnXNL8+fPvue3p06e1efPmLKwGAAAAAPC4IZxLmjRpksqUKaOPPvpIBw8ezLQ+Pj5e33//vcLDwxUcHKy//vrLhCoBAAAAAI8qhrVLio2N1YoVK/Tvf/9bgwYNkqenp/Lnzy83NzddunRJcXFxyps3r9544w3t27ePieEAAAAAAA8V4fy/mjdvrubNm+vixYvatGmTTpw4oaSkJD3xxBOqVKmSKlWqJAcHBhoAuK7ogO/serwTUc3sejwAAADYF+H8Fn5+fmrVqpXZZQAAAAAAHiN0BQMA7urEiRPKmzevQkNDFRoaqvPnz+vMmTNq2bKlQkNDNWzYsEzb7Nu3T40bN1ZISIimTJki6fotRDVq1FCtWrX066+/2vs0AAAAsjV6zgEA/1NISIi+/vpr6/uXX35ZkyZNUsGCBW/bfuDAgVq0aJG8vLysy4YMGaLvv/9eiYmJ6tq1q1auXJnldQMAAOQU9JwDAP6nzZs3q06dOho0aJBSU1N14sQJ9e3bV/Xr19eWLVts2h47dkypqal69dVX1bhxYx06dEhXr16Vs7OzfH19VaRIEV26dMmkMwEAAMie6DkHANxVQECAjhw5Ig8PD3Xu3FkLFy7Unj17tGjRIjk5Oally5batm2btf3Zs2e1f/9+7d+/X6dOnVKfPn30xRdf2PSiOzk56dq1a3JxcTHjlAAAALIdes7v4Nq1a/rPf/6jtLQ0s0sBAFO5urrK09NTFotFL7zwgnbv3q1SpUqpUKFC8vf3l5OTk83vSh8fH1WuXFleXl4qX768Lly4IF9fXyUkJFjbpKWlEcwBAABuQji/xdWrV9WpUyd5eHjoySef1KlTpyRJPXv2VFRUlMnVAYD9JSYmWr/euHGjKlSoIB8fH8XHx+vvv//WtWvX5OT0/wOxSpYsqfPnzys1NVVnzpyRl5eX3N3dlZqaqkuXLunUqVPy8/Mz41QAAACyLcL5LQYOHKhff/1VMTExcnNzsy5/9tlntWDBAhMrAwBzbNq0ScHBwapTp45+//13hYeHa8SIEWrevLkaNGig4cOHS5KioqJ0/PhxOTk5qU+fPqpXr57atm1r/WDzww8/1HPPPaeXX35ZI0eONPOUAAAAsh3uOb/F0qVLtWDBAlWvXl0Wi8W6vFy5cjp69KiJlQGAOZo2baqmTZvaLKtZs6Z+/PFHm2UDBgywfh0WFqawsDCb9SEhIdq6dWvWFQoAAJCD0XN+i/PnzytfvnyZlv/99982YR0AAAB4mE6cOKG8efMqNDRUoaGhOn/+vEqWLGl9v2bNmkzb9O7dW3Xr1lXr1q2tc3uEhYUpNDRUISEh8vX1tfdpAHhA9JzfokqVKvruu+/09ttvS5I1kE+bNk01atQwszQAAAA84kJCQvT1119b33t7eysmJua2bbdv364LFy5o48aNWrhwoSZNmqT33ntPS5YskXT9tqTp06fbo2wADwE957cYNWqUBg8erLfeektpaWn69NNP1bBhQ3355ZcaMWKE2eUBAADgEbZ582bVqVNHgwYNkmEYunLlikJCQhQeHq6//vrLpu2xY8f09NNPS5KeeeaZTLcbLVq0SG3atLFX6QD+IcL5LWrWrKktW7bo6tWrKl68uFavXq38+fNr69atCg4ONrs8AAAAPKICAgJ05MgRbdy4UefOndM333yjzZs3KzY2Vk2aNFFkZKRN+7JlyyomJkaGYWjt2rW6fPmydZ1hGFq3bp2effZZ+54EgAdGOL9Jamqq3njjDXl4eGjWrFnat2+fDhw4oNmzZ6tChQpmlwcAAIBHmKurqzw9PWWxWPTCCy9o9+7d1kdPtmnTRrt377ZpX7FiRdWqVUuhoaE6duyY/P39reu2bNmiypUry8XFxZ6nAOAfIJzfxNnZWd98843ZZQAAAOAxlJiYaP1648aNKlGihFJSUmze32rAgAGKjY1VuXLl9Pzzz1uXM6QdyHkI57do3bq1li5danYZAAAAeMxs2rRJwcHBqlOnjn7//Xc1btxYNWvWVN26dTVmzBgNGzZMkhQVFaXjx49LkkJDQ/Xss89q7969Cg8PlyTrMPeGDRuadi4A7h+ztd+iRIkSGj58uLZs2aLg4GB5enrarO/Zs6dJlQEAAOBR1rRpUzVt2tRm2Y4dOzK1GzBggPXr283kbrFYtG/fvodeH4CsRTi/xRdffCEfHx/t2LEj0y9Di8VCOAcAOzhx4oSqVKmiJ598UtL14Zk1a9ZUwYIFJUmDBw+26RG6cOGCWrVqJScnJzk4OGjOnDkqUKCAFi9erKioKDk4OOjNN99U586dTTkfAACA/4VwfosbQ4QAAOa6n2f9+vr6auPGjXJ0dNSsWbM0ffp0vf/++xo1apTWr18vDw8PBQcHE84BAEC2xT3nd2EYhgzDMLsMAHgs3c+zfh0dHeXo6ChJSkhIUPny5SVJZcqUUWJiopKSkuTt7W33cwAAALhXhPPbiI6OVoUKFeTu7i53d3dVrFhRX331ldllAcBj436f9StJe/fuVbVq1TRhwgRVqlRJ0vVHD1WpUkXlypVThw4d7HsSAADTnThxQnnz5lVoaKhCQ0N1/vx5lSxZ0vp+zZo1mbZp2LChfHx8tGLFCuuydu3aKSQkRFWrVtWGDRvseQp4jDCs/Rbjxo3T+++/rx49eqhWrVoyDEObN29Wt27ddOHCBfXu3dvsEgHALirMqmDX4+1tv9f6taurq1xdXSVJL7zwgrZu3aqwsDBJ1wP3F198kWn7ChUq6Oeff9bChQsVFRWlyZMna9CgQdq3b59y5cqlBg0aqHXr1vL19bXPCQEAsoX7uU1Kut5RN2XKFJtls2fPlrOzs06ePKmOHTuqXr16WVUuHmOE81v8+9//1qRJk/T6669bl7Vq1UpPPvmkIiMjCecAYAeJiYnKnTu3pOvP9i1btqxSUlLk6up622f9Xrt2TS4uLpKu/9F140kbLi4uypUrl1xcXOTg4KDk5GT7nggAwHQ3bpOqU6eORowYYb1NqmDBgpowYYLy5Mlj0z4gICDTPpydnSVdv3WqQgX7fniNxwfh/BZ//vmnatasmWl5zZo19eeff5pQEQA8fjZt2qQhQ4bIw8NDQUFB6tWrl2rWrClPT0+5urpqxowZkq4/67ddu3b666+/1Lt3bzk6OsrDw0PTp0+XJPXv31916tSRxWJRo0aNbvsHFwDg0XXjNikPDw917tzZepuUn5+foqOjFRkZqc8+++ye9lWvXj0dOHBAs2bNyuKq8bginN+iRIkSWrhwoQYNGmSzfMGCBSpZsqRJVQHA4+V+n/UbFBSkjRs3ZlofHh6u8PDwrCkSAJDtPchtUneyYcMGnTp1Si1btlSTJk2ypF483gjntxg2bJjatWunjRs3qlatWrJYLNq0aZPWrVunhQsXml0eAAAAgHt0v7dJ3Y5hGEpLS5Ozs7Ny5colLy+vrC4bjynC+S1eeOEF/fzzz/rkk0+0dOlSGYahcuXKadu2bdbZfwEAAABkf/d7m1RQUJA6duyomJgYLV26VPv27VPfvn3VsGFDWSwWpaena9SoUSafFR5VhPPbCA4O1uzZs80uAwAAAMA/cL+3SUmyBvab3W12d+Bh4Tnnt/j++++1atWqTMtXrVqllStXmlARAAAAAOBRR8/5LQYMGKCoqKhMyw3D0IABAzJ98gYAAAA8sEhv+x4vqIh9jwfgntFzfovDhw+rXLlymZaXKVNGR44cMaEiAAAAAMCjjnB+C29vbx07dizT8iNHjsjT09OEigAAAAAAjzrC+S1atmypXr166ejRo9ZlR44cUd++fdWyZUsTKwMAAAAAPKoI57f4+OOP5enpqTJlyigoKEhBQUEqW7as/Pz8NGbMGLPLAwAAAAA8gpgQ7hbe3t7asmWL1qxZo19//VXu7u6qWLGi6tata3ZpAAAAAIBHFOH8NiwWixo1aqRGjRqZXQoAAAAA4DHAsPb/+vnnnzM9xzw6OlpBQUHKly+funTpopSUFJOqAwAAAAA8yug5/6/IyEiFhoZan2O+d+9ederUSR06dFDZsmX18ccfq0CBAoqMjDS3UAB4RB0sU9auxyt76KBdjwcAAHA39Jz/1+7du9WgQQPr+/nz56tatWqaNm2a+vTpo88++0wLFy685/1FRkbKYrHYvPz9/a3rO3TokGl99erVH+o5AQAAAAByBnrO/+vSpUvKnz+/9X1sbKyaNGlifV+lShWdPn36vvb55JNPau3atdb3jo6ONuubNGmimTNnWt+7uLjcb9kAAAAAgEcA4fy/8ufPr+PHj6tw4cK6du2adu7cqWHDhlnXJyYmytnZ+b726eTkZNNbfitXV9e7rgcAAABwfz7vtt6ux4uYXN+ux8Oji2Ht/9WkSRMNGDBAP/74owYOHCgPDw/VqVPHun7Pnj0qXrz4fe3z8OHDKlCggIKCgvTSSy/p2LFjNutjYmKUL18+lSpVSp07d9a5c+fuur+UlBQlJCTYvAAAAAAAOR/h/L8+/PBDOTo6KiQkRNOmTdO0adNshpnPmDHjvh6tVq1aNUVHR2vVqlWaNm2a4uLiVLNmTV28eFGS1LRpU82ZM0fr16/X2LFjtX37dtWvX/+uM8KPGjVK3t7e1lfhwoUf/IQBAAAAANkGw9r/K2/evPrxxx8VHx+vXLlyZbo/fNGiRcqVK9c97+/GrO+SVKFCBdWoUUPFixfXrFmz1KdPH7Vr1866vnz58qpcubICAwP13XffKSws7Lb7HDhwoPr06WN9n5CQQEAHAAAAgEcA4fwW3t7et12eJ0+ef7RfT09PVahQQYcPH77t+oCAAAUGBt5xvXT9HnVXV9d/VAcAAAAAIPthWLudpKSk6ODBgwoICLjt+osXL+r06dN3XA8AAAAAeHQRzrNIv379FBsbq+PHj+vnn3/Wiy++qISEBLVv315XrlxRv379tHXrVp04cUIxMTFq0aKFnnjiCbVu3drs0gEAAAAAdsaw9ixy5swZvfzyy7pw4YLy5s2r6tWr66efflJgYKCSkpK0d+9eRUdH6/LlywoICFC9evW0YMEC5c6d2+zSAQAAAAB2RjjPIvPnz7/jOnd3d61atcqO1QAAAAAAsjOGtQMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAP81b9485c2bV5I0YcIEVa1aVdWqVdPy5cszte3du7fq1q2r1q1bKyEhwbr8ypUryps3r1asWGG3ugEAQM5HOAcAQFJGRoa+/vprFS5cWJI0ceJEbdmyRWvWrNHIkSNt2m7fvl0XLlzQxo0b9fLLL2vSpEnWdZ999pmCg4PtWjsAAMj5COdZJDIyUhaLxebl7+9vXW8YhiIjI1WgQAG5u7srNDRU+/fvN7FiAHi8zZ07Vy+++KIcHK7/r7FEiRJKSkpSYmKi/Pz8bNoeO3ZMTz/9tCTpmWee0Y8//ihJSkhI0N69e1W9enW71g4AAHI+wnkWevLJJ/Xnn39aX3v37rWuGz16tMaNG6cJEyZo+/bt8vf3V8OGDZWYmGhixQDweEpPT9fChQvVrl0767ImTZqoXLlyqlKlinr27GnTvmzZsoqJiZFhGFq7dq0uX74sSfr000/Vo0cPe5YOAAAeEYTzLOTk5CR/f3/r68Z9jIZhaPz48Ro8eLDCwsJUvnx5zZo1S1evXtXcuXNNrhoAHj+zZ89W27Ztrb3mCQkJmjp1qg4fPqxDhw5p0KBBMgzD2r5ixYqqVauWQkNDdezYMfn7+ys+Pl579uxRrVq1zDoNAACQgxHOs9Dhw4dVoEABBQUF6aWXXtKxY8ckScePH1dcXJwaNWpkbevq6qqQkBBt2bLljvtLSUlRQkKCzQsA8M8dOHBA0dHRatKkiQ4fPqyhQ4fKzc1Nrq6u8vDwUEpKik04l6QBAwYoNjZW5cqV0/PPP69Dhw7p9OnTatKkiWbPnq2hQ4fqzJkzJp0RAADIaZzMLuBRVa1aNUVHR6tUqVI6e/asPvzwQ9WsWVP79+9XXFycJCl//vw22+TPn18nT5684z5HjRqlYcOGZWndAPA4+uijj6xfV65cWZ988onGjBmjGjVqKD09XREREXJwcFBUVJTatWunoKAghYaGysnJSU899ZQ+/vhjOTg46KeffpJ0fd6RypUrq1ChQmadEgAAyGEI51mkadOm1q8rVKigGjVqqHjx4po1a5Z1oiCLxWKzjWEYmZbdbODAgerTp4/1fUJCgnVWYQDAw/HLL79Ikvr166d+/frZrBswYID165iYmDvuIzIyMitKAwAAjzCGtduJp6enKlSooMOHD1tnbb/Rg37DuXPnMvWm38zV1VVeXl42LwAAAABAzkc4t5OUlBQdPHhQAQEBCgoKkr+/v9asWWNdf+3aNcXGxqpmzZomVgkgJ5k3b551oskJEyaoatWqqlatmpYvX27T7tSpUwoNDVVISIiaNm1qnVl88eLFqlKliqpVq6Zp06bZu3wAAADchHCeRfr166fY2FgdP35cP//8s1588UUlJCSoffv2slgs6tWrl0aOHKlvvvlG+/btU4cOHeTh4aHw8HCzSweQA2RkZOjrr7+23toyceJEbdmyRWvWrNHIkSNt2np5eWnJkiWKjY1V69atrUF81KhRWrdunTZv3qwJEybY/RwAAADw/7jnPIucOXNGL7/8si5cuKC8efOqevXq+umnnxQYGChJevfdd5WUlKTu3bvr0qVLqlatmlavXq3cuXObXDmAnGDu3Ll68cUXNXbsWElSiRIllJSUpMTERPn5+dm09fHxsX7t7OwsJ6frv/rLlCmjxMREWSwWeXt72612AAAAZEY4zyLz58+/63qLxaLIyEgmDQJw39LT07Vw4UItXbrUGs6bNGmicuXKKT09XV9++eVtt4uPj9eUKVO0cuVKSVKbNm1UpUoVOTo68iQIAAAAkzGsHQBymNmzZ6tt27ZycLj+KzwhIUFTp07V4cOHdejQIQ0aNCjTM7lTU1MVHh6uMWPGyNfXV5I0aNAg7du3T0ePHtXMmTN16dIlu58LAAAArqPnHABymAMHDmjXrl2aPXu2Dh8+rKFDh8rNzU2urq5ycnJSSkpKpkczdu/eXW3btlXt2rWty1xcXJQrVy65uLjIwcFBycnJZpwOAAAARDgHgBzno48+sn5duXJlffLJJxozZoxq1Kih9PR0RUREyMHBQVFRUWrXrp3i4uI0d+5cHT58WDNnzlTr1q31zjvvqH///qpTp44sFosaNWqkgIAAE88KAADg8UY4B4Ac7JdffpF0/QkR/fr1s1k3YMAASVJQUJD+/vvvTNuGh4fzhAgAAIBsgnvOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ95wDAB5Ln3dbb9fjRUyub9fjAQCAnIWecwAAAAAATEY4BwAAAADAZIRzAAAAAABMRjgHAAAAAMBkhHMAAAAAAExGOAcAAAAAwGSEcwAAAAAATMZzzgEgJ4j0tv8xg4rY/5gAAACPKXrOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4RwAAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4RwAAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4RwAAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4RwAAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4RwAAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4RwAAAAAAJMRzgEAAAAAMBnhHAAAAAAAkxHOAQAAAAAwGeEcAAAAAACTEc4BAAAAADAZ4dwORo0aJYvFol69elmXdejQQRaLxeZVvXp184oEAAAAAJjGyewCHnXbt2/X1KlTVbFixUzrmjRpopkzZ1rfu7i42LM0AAAAAEA2Qc95Frpy5YpeeeUVTZs2Tb6+vpnWu7q6yt/f3/rKkyePCVUCAAAAAMxGOM9CERERatasmZ599tnbro+JiVG+fPlUqlQpde7cWefOnbvr/lJSUpSQkGDzAgAAAADkfAxrzyLz58/Xzp07tX379tuub9q0qdq0aaPAwEAdP35c77//vurXr68dO3bI1dX1ttuMGjVKw4YNy8qyAQAAAAAmIJxngdOnT+udd97R6tWr5ebmdts27dq1s35dvnx5Va5cWYGBgfruu+8UFhZ2220GDhyoPn36WN8nJCSocOHCD7d4AAAAAIDdEc6zwI4dO3Tu3DkFBwdbl6Wnp2vjxo2aMGGCUlJS5OjoaLNNQECAAgMDdfjw4Tvu19XV9Y696gAAAACAnItwngUaNGigvXv32ix74403VKZMGb333nuZgrkkXbx4UadPn1ZAQIC9ygQAAAAAZBOE8yyQO3dulS9f3maZp6en/Pz8VL58eV25ckWRkZF64YUXFBAQoBMnTmjQoEF64okn1Lp1a5OqBgAAAACYhXBuAkdHR+3du1fR0dG6fPmyAgICVK9ePS1YsEC5c+c2uzwAAAAAgJ0Rzu0kJibG+rW7u7tWrVplXjEAAAAAgGyF55wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywrkdjBo1ShaLRb169bIuMwxDkZGRKlCggNzd3RUaGqr9+/ebVyQAAAAAwDSE8yy2fft2TZ06VRUrVrRZPnr0aI0bN04TJkzQ9u3b5e/vr4YNGyoxMdGkSgEAAAAAZiGcZ6ErV67olVde0bRp0+Tr62tdbhiGxo8fr8GDByssLEzly5fXrFmzdPXqVc2dO9fEigEAAAAAZnAyu4BHWUREhJo1a6Znn31WH374oXX58ePHFRcXp0aNGlmXubq6KiQkRFu2bFHXrl1vu7+UlBSlpKRY38fHx0uSEhISsugM7k9GylW7Hi/BYtj1eJKUnpRu1+NdSbfv8ZKu/W3X42WXa/dBcL0/fFzv2dejfr3b+1qXuN6zM673h8ve17r0+F7vN+owDPv/zYCHg3CeRebPn6+dO3dq+/btmdbFxcVJkvLnz2+zPH/+/Dp58uQd9zlq1CgNGzYs0/LChQv/w2pzJm9TjnrQrkeratejSTrS0q6H6z/TrofL0bjeswDXe7Zl/+vdvte6xPWO//eoX+92v9alx/56T0xMlLe3OX854J8hnGeB06dP65133tHq1avl5uZ2x3YWi8XmvWEYmZbdbODAgerTp4/1fUZGhv766y/5+fnddTuYKyEhQYULF9bp06fl5eVldjlAluJ6x+OE6x2PC671nMEwDCUmJqpAgQJml4IHRDjPAjt27NC5c+cUHBxsXZaenq6NGzdqwoQJ+s9//iPpeg96QECAtc25c+cy9abfzNXVVa6urjbLfHx8Hm7xyDJeXl78Dw2PDa53PE643vG44FrP/ugxz9mYEC4LNGjQQHv37tXu3butr8qVK+uVV17R7t27VaxYMfn7+2vNmjXWba5du6bY2FjVrFnTxMoBAAAAAGag5zwL5M6dW+XLl7dZ5unpKT8/P+vyXr16aeTIkSpZsqRKliypkSNHysPDQ+Hh4WaUDAAAAAAwEeHcJO+++66SkpLUvXt3Xbp0SdWqVdPq1auVO3dus0vDQ+bq6qqhQ4dmuiUBeBRxveNxwvWOxwXXOmAfFoO59gEAAAAAMBX3nAMAAAAAYDLCOQAAAAAAJiOcAwAAAABgMsI5AAAAAAAmI5wDAAAAAGAywjmQg/BwBQDIGZKTkyVJGRkZJlcCAMgpCOdADvHZZ59p27ZtkvhjDwCys1mzZqlTp07666+/5ODgwO9s5Eh0CAD2RzgHcojZs2dr+PDhkiQHB/7p4tFDgEFOd+MaPnbsmA4fPqwhQ4bo0qVLBHTkOBkZGbJYLLpw4YJ+//13s8sBHhv8hQ9kczf+oBs4cKAuXryoPXv2SOITbTxaDMOwfui0YsUKTZ48WTt27NDff/9tcmXAvTt8+LAkaejQoWrTpo12796tgQMHEtCRo2RkZMjBwUH79+9X2bJl9cEHHyguLs7ssoDHAuEcyOZuBJaaNWvq3LlzWrRokSTJYrGYWRbwUN24nt977z298sor+uSTT1SnTh2NHDlSR44cMbk64H9bsWKFQkNDtXjxYjk4OKhv375q1aqV9uzZQ0BHjpKWlqa4uDh16tRJJUuW1KxZszRs2DACOmAHhHMgm1qwYIEmTpxofZ8/f34NGTJECxYs0N69e02sDHh4bh4B8vPPP2v79u364YcfdOjQIX388cf6+uuv9fnnnxPQke3ly5dPzz77rIYNG6YlS5bIwcFB/fv3J6AjR+nSpYu6du2q3bt3q1ChQpo9e7aWLVumqVOnEtABO3AyuwAAmV2+fFkzZ87UoUOH9MUXX6hLly5q3LixmjVrpkmTJunXX39VhQoVlJ6eLkdHR7PLBR7YjR7zKVOmaNu2bQoMDFSNGjUkSREREXJ0dNQnn3wii8Wi7t27q0SJEmaWC9xR1apV1adPH3366ad6//33JUlhYWHq37+/JGnZsmUaOHCgRo0aJV9fX+vQYSC7mD9/vpYuXaq1a9eqXLly8vb2VrFixVSsWDGtWLFCzZs3lyT961//UkBAgCRxHQMPGf+agGzmhx9+0OXLl7Vy5Urt2rVLVatW1ZIlS1SlShWtWrVKDg4OGjNmjJKSkgjmeGQcOXJEM2fO1M6dO/XHH39Yl3fr1k19+vTRqlWrNHLkSJ05c8bEKoG7q1Spknr27KkqVaro/fffv20P+pAhQ3Tx4kUCDbKd06dPy8/PTxUrVtSaNWu0ceNGSVJqaqqaNm2q77//XlOnTrXeg56enq5JkyYpNjbW5MqBRwf/ZwCykffee099+vTR4sWLdenSJfn6+mry5MmaPXu23n//fc2cOVPx8fHas2ePli9fLomJ4ZDz3G5I78cff6xRo0bpzz//1IwZM3T27Fnruq5du6pjx45KSkpSgQIF7FkqcN+eeeYZRURE3Dagt27dWhs2bNCIESMY2o5sJzQ0VIZhqH79+mrWrJmKFi0qSXJ2dlZGRoYaN25sDejDhg1Thw4dNHDgQBUsWNDcwoFHiMXgL3sgWxg7dqyioqL07bffqlKlSnJzc8s0XOz06dP6888/1aVLFxUoUEDff/+9iRUD9+/ma/o///mP0tPT5e7urqCgIEnS4MGD9dVXX6l79+564403lD9/fuu2hmHIYrEwjBLZxo1r8vTp07p69aocHBxUsmRJSdfnUJg0aZK2b9+u4cOHKywsTOnp6ZowYYJatWplDT5AdhIREaFJkyapRo0a2rx5syRZb6G7cb1/9913atGihby9vbVu3To988wzJlcNPDq45xwwmWEY+vvvv7V+/XoNHjxYNWrUuGNveKFChVS4cGEtWLBAISEh2rRpk2rXrm3nioEHc/Pj0gYNGqTly5fr5MmTKlmypIKDgzV16lSNGDFCkjRp0iQ5ODjotddes97baLFYbPYBmOlGUFm2bJmGDRumc+fOKSgoSMHBwRo/fryqVatmbTts2DBdu3ZNL730kt555x0TqwbuLCkpSYcOHVKnTp20ZcsWvfrqq5o9e7YcHR2tAT05OVnr16+Xl5eXtmzZorJly5pdNvBI4S8cwGQWi0WOjo46efKkkpOTrcuk649RS05O1sGDB63LDcNQnjx55Ovrq9TUVNPqBu7VjQ+bblzXo0eP1pQpUzR27FgtWbJEHTt21NKlS/XCCy9IkkaMGKEOHTpoyJAhWrdunc2+eIQgsguLxaKVK1fq1VdfVceOHbVu3To1b95cn332md544w1JUrVq1awTGX766ae6cuUKtyIh23J3d9fy5cs1bdo09e3bV7/88oteffVVSbIG9D179mj+/PlavXo1wRzIAgxrB0xmGIauXr2qRo0aqXDhwpo/f761R0aSDh48qM8//1x9+/a1Dv396quv1L59ex09etS6DMiOzp07p3z58lnfJycnKzw8XDVq1LDOYp2amqp169apQ4cOevvttzV48GBJ0vTp09WhQwcmPkS2FBcXp44dO6pRo0bq1auXzp8/r+DgYJUuXVp79uxR48aNFR0dLUnasWOHAgICmDMBOcaVK1e0aNEijR49WsHBwZo9e7YkKTExUWlpafL19TW5QuDRRM85YJJr165ZQ7inp6c++OADLVmyRIMGDVJqaqrS0tKUkJCgvn376uTJkwoMDJR0PcyXKVNGBw4cIJgjW+vRo4dee+01m2UODg46fPiwzXPLnZ2d1aBBA7Vo0UJ79uyxjgjp1KmTtbcGyG78/f317LPPqlGjRjp79qxCQ0PVrFkzLV26VOHh4Zo9e7bCwsIkScHBwQRz5Ci5cuVS27Zt9e677+rXX39Vq1atJEm5c+cmmANZiHvOAROMHz9eP//8s86cOaP27durcePGatCggaZPn65OnTopJiZGDg4OysjI0JUrV7Rjxw7rewcHB1WpUsXsUwD+p4EDB1p7zRMSEuTl5SUXFxe1bt1amzZt0s8//2y9L9fZ2VkFCxbU4cOHMw37pecc2cGND1NvTGRYrlw59enTR5L0+eefKzAwUB988IE8PT2t8yicOnVKZ86cUaFChUyuHrh/np6eatu2rZKTk/Xll1/qjz/+4EMmIIvRcw7Y2cCBAzVixAhVqlRJFStW1MSJE/X+++/rxIkTeu211/Trr7+qYcOGqlGjhl588UXt3LlTzs7OSktLYyIs5CgFCxaUs7OzoqOjFRAQoFOnTkmSGjZsqIsXL2rKlCn68ccfJUnx8fHatGmTSpQoIRcXFzPLBjK5EcyXLFmisLAwLVy40OZxf/v371dcXJzy5s0rSTp+/LiaN2+u2NhYgjlyNE9PT7Vv316rV68mmAN2wD3ngB3NmzdP//rXvzR//nwFBwdr3bp1aty4sUqXLq2KFStqxIgRKlasmHVW1BtufQ9kZ7c+6uz48eN67bXX9PvvvysmJkaBgYFauXKlhg4dqsTERDk6OsrNzU0pKSnWD6NunncByA5Wr16t559/XuPGjdMLL7xgDeKStGLFCvXs2VMVK1aUl5eXli1bpm3btql06dImVgwAyGkY1g7YSUpKinx9ffXyyy8rODhYy5YtU8eOHfX555/r2rVrGjJkiBwdHfWvf/1LpUqVstmWYI6c4uZgvnnzZhUoUEBBQUGaM2eOOnTooNq1a2vTpk1q2rSpihQpohMnTmjLli0KDAxUx44d5eTkpLS0NDk58b8nZA+GYejatWv66quv1L17d3Xr1s1668WND06rV6+ugQMHauHChbJYLPrxxx8J5gCA+0bPOWAHH374oQoVKqTnn39eqampcnBwUPPmzRUWFqb+/fsrKSlJTz31lFJSUtS+fXt98MEHZpcM3Lebg/mgQYO0bNkyRUZG6rnnnpOnp6eOHz+uDh066NixY9q8ebOKFCmSaR+MEkF2VatWLVWrVk3jxo3LtO7ChQt64oknJF1/VrS7u7u9ywMAPAK4gRXIYosWLdKYMWP01FNPydvbW3nz5lVcXJx+//13Va1aVZL0+++/Kzg4WB988IEiIyPNLRh4QDeCeWRkpGbMmKHPPvvMGswlKSgoSHPnzlVQUJBCQkJ0/PjxTPsgmCO7uNF3YRiGrly5Ik9PT+t95jeeIGAYhs6cOaOxY8fq8OHDkkQwBwA8MMI5kIW+/vprxcXF6YMPPlClSpWsf+xZLBblz59f3377rWJiYvTOO+8oJSVFr7/+unVWdiAnmDNnjs37EydOaMmSJZo4caIaNGigq1evaufOnRo5cqTmzJmjggULasGCBfLw8FDfvn1Nqhq4sxu/p//66y9duXJFCQkJypUrl/r06aN58+ZpzJgx1g+RLBaLJk6cqLVr18rb29vMsgEAjwBu6gOyyKVLl9S5c2fFx8erd+/ekv6/Z7FcuXJq3ry5lixZogULFigoKEjr16+XxWKRYRjMyo4c4caokJdfftl6zTo6OsrJyUmXLl3S6tWrNW/ePO3Zs0fJycm6evWq/vrrL7399ttas2aN8ufPb/IZALZuTES4YsUKRUVFKSkpSQkJCYqMjFTz5s3173//W2+//ba2bt2qXLlyKT09XcuXL1dMTIz1sYEAADwoEgCQBZKTk+Xr66tt27bpqaee0tq1a61DeG/0ygwdOlTLli3TqlWrFBsba31cGjNUI6d4/vnntWPHDjk4OGjr1q2Srj8+rUiRIvr888/VtGlT5cmTR1FRUfrpp59UqlQpXb58WZJUoEABOTo6WocHA9mBxWLR999/r7Zt2yosLExffvmlGjdurNdee00HDx5URESEYmNj5eHhoUuXLil37tzaunWrKlWqZHbpAIBHABPCAQ/ZuHHjlJycrC5duuiJJ57Q4cOH1ahRIxUtWlTz589X/vz5b/uYKCbCQk61bds2Va9eXcOHD9fgwYOVnp6urVu3ytPT0ya01KlTR88995wGDhxoYrVAZjf/Tm7fvr0KFiyokSNH6tSpU3r22WcVEhKiadOmWdulpKTI1dWVJwsAAB4qes6Bh+z333+33l978eJFlSxZUqtXr9axY8cUHh6uc+fO3bZ3nGCOnOLmORHS09NVtWpVjRkzRh988IFGjRolR0dH1a5dW5UqVdKVK1d05MgRNW3aVAkJCerfv7+JlQO3Z7FYtHTpUk2YMEEHDhxQvXr1dOXKFdWoUUP16tXT1KlTJUmTJ0/WyZMn5erqKonf2wCAh4twDjxkY8eOVb9+/RQZGano6GhrQF+7dq1OnDihZ599VpcuXTK7TOCB3Py4tOjoaH311VdKTEzUO++8o48//lhDhgzR6NGjre1vPN88NTVVv/zyi5ycnBjKjmxn586d6tSpkwoUKKDy5ctrxowZKlu2rFq1aqUJEybIYrEoKSlJq1at0tdff20zuScAAA8LY7GAh+DgwYMKCgqSm5ubpOuPksrIyNDQoUNlGIbat2+vkiVLasWKFRoyZIi8vLxMrhh4MDeCef/+/TVnzhx98MEHSkhIUO7cudW1a1dJUu/evWWxWNS/f3+9+eab8vf3V/PmzeXo6MgwYGQ7R44c0bfffqvOnTsrLCxM586d08iRI1WwYEGNHTtWzs7OkqThw4dr//79GjduHKEcAJAl+AsJ+AcMw9B3332nli1bau7cuWrdurV1uOMHH3yga9euaciQIXJ2dlbbtm1VtmxZLV68WBL3mCPnmjVrlubMmaNvvvlG1apVsy53dXVVly5dJEn9+vXT5cuXNWLECLVq1UrS9WueYI7sJCEhQS+//LJOnjypV155RZL05ptv6tChQ4qNjVXz5s311FNP6fTp01q/fr3Wrl2rYsWKmVw1AOBRxYRwwEPw+uuv69tvv9WUKVP0/PPPWwP6mTNnVL58eSUkJGj+/Plq27atyZUC/9zbb7+tixcvau7cudZlNw93l6QRI0bohx9+0MaNG+llRLa2a9cutWvXTh4eHpoxY4aeeeYZpaWlae7cudqwYYPi4uJUtmxZdenSRWXKlDG7XADAI4xwDjygyZMnKy0tTT169JB0vbdl/vz5mj59ujWg//bbb/ryyy9VsGBBde3alV5D5Gg3Rnu8+OKLcnFx0dy5c21GgKSmpio2NlbVq1dXrly5rDNb3+7pBEB2smfPHr322muqWrWq3n77bVWsWNHskgAAjyEmhAMeQP/+/TVy5EjFxcXp1KlTkqQvvvhC7dq101tvvaXRo0dr6dKl6tu3r44ePaqIiAg5OTkpLS3N5MqBe3fzrOzS/89MXaVKFS1evFgHDx60uTXjwoUL+vLLL/XLL79IEsEcOUbFihX15ZdfaufOnfr3v/+t/fv3m10SAOAxRM85cJ+++uor9e3bVytXrlRwcLAk2/vHBw0apGXLlikpKUlFihTRmjVrrBMKATnFzcPU16xZo8uXL+vq1atq37690tPT1bx5c+3atUvLli1T0aJFlZqaqi5duujixYvasmUL8ykgR9q1a5e6deumYsWKaejQoQxjBwDYFeEcuE8DBw7UH3/8oVmzZllD+a332x4/flwODg4qXLiwHBwcmKEaOdZ7772nb775Rl5eXsrIyFB8fLxWrlyp9PR0DR8+XN98843y58+vXLlyydPTU5s2bZKzs3OmfxNATrF9+3b1799f8+bNU0BAgNnlAAAeI4Rz4D69/vrrOnHihDZu3ChJ1mG7KSkp2rRpkxo0aGDTnpCCnGrq1KkaMmSIfvjhBz3zzDP66quv1L59e61atUoNGzaUJK1atUpXrlyRq6urmjZtyuPS8EhITk62PhoTAAB74a8n4B7s2LFD/v7+KliwoCpXrqxt27Zpw4YNqlWrllxcXCRJ8fHxioyM1LVr19S0aVPrtgRz5BS3fpD022+/qXfv3nrmmWe0ePFi9ejRQ5MnT1bDhg2VmJio3Llzq3Hjxjb74HFpeBQQzAEAZiA1AP/DoEGD9MYbb2jLli3KyMhQly5d5Obmpvfee0/Lly9XXFycjhw5oo4dOyojI0ONGjUyu2TgvhmGYQ3ma9euVWpqqg4fPqyEhAStXbtWb7zxhqKiotSlSxcZhqHJkydr3LhxmfbDveYAAAAPhnAO3MWIESM0ffp0ffLJJ2rYsKEcHBzk5uamLVu2yNvbW0OHDlXRokXVtm1bnT9/XjExMXJ0dFR6errZpQP37OYZ1YcOHapevXrp5MmTaty4sdatW6dWrVpp9OjReuuttyRdHyWyceNGXblyxcyyAQAAHimMPQRuwzAM/fXXX/r22281cuRIm/vIr127Jg8PD33//ff67bfftG/fPvn7+6t27drcb4sc6UYw37dvn3bv3q3PP/9cJUqUkKOjo2bNmqVixYqpYMGCunbtmk6ePKlevXrp3LlzGjRokMmVAwAAPDqYEA64g9OnTys4OFjz589X/fr1be7HTUpK0qVLl1SgQAGbbW5+pBqQk0ycOFELFixQenq6Fi9erPz580uS9u/fr+7du+vs2bM6f/68ihcvLmdnZ8XExMjZ2ZlrHgAA4CGhew+4g4CAAOXKlUvLli1T/fr15eDgYA0iu3bt0o4dO9S+fXt5eXlZtyGkIKe4dfK3MmXK6MSJEzp37px27Nih5557TpL05JNPauHChfr999+1d+9elSxZUtWqVWOUCAAAwENGzzlwk7Vr1+rKlSsyDEOtW7fWqFGjtGjRIoWHh6tfv36SpLS0NDVv3ly5c+fWwoULrUOCgZzi5mB++PBhubm5qXDhwjp27JgaNmyocuXKaejQoapcufId90GPOQAAwMNFOAf+a9CgQYqOjla+fPl08OBBderUSa1atdKKFSu0atUqBQYGqkiRItq/f78SExO1c+dOOTs720ymBWR3N1+vAwYM0DfffKOLFy+qXLly6tOnj5566ik9++yzCg4O1nvvvafg4OBM2wEAAODhY7Z2QNLo0aP15ZdfasmSJdq5c6dGjx6tiRMnav78+WrTpo0++ugjeXp66u+//1bt2rW1a9cuOTs7Ky0tjcCCHCMjI8N6vc6fP1/R0dEaPXq0xo4dq2rVqumFF17Qjz/+qDVr1mjnzp0aO3asfvrpJ0niOgcAAMhi3CyIx94ff/yhAwcO6JNPPlHVqlW1ZMkSDR06VIMHD9Znn32mq1evavTo0WrVqpXNdunp6dxvixzlxlD2mJgYrVu3Tv3797de14mJiSpcuLC6du2qdevWadGiRapdu7ZKliyp6tWrm1k2AADAY4Fkgcdenjx51KpVK9WrV0+//PKL+vbtq8jISPXs2VM+Pj7q37+/4uLiFB0drcKFC1u3435b5ERxcXF68803de7cOb333nvW5blz59Zrr72mdevWae7cuZowYYI2b96sChUqmFgtAADA44Nh7Xjsubm5qXnz5vLx8dG6detUrlw5tW/fXpLk6uqqV199VW5ubipYsKDJlQL/nL+/v5YsWaJ8+fJpyZIl2rVrl3Wdr6+v8ubNq8OHD8swDD399NNydHRUenq6iRUDAAA8HgjngGQdnn7kyBElJCTIYrEoOTlZq1atUrNmzbRy5Uo5ODgoIyPD5EqBf65ixYpasmSJ0tPT9emnn2r37t2Srg9tP3TokIoUKWJzjzmjRAAAALIes7UDN/n5559Vp04dlS5dWikpKXJzc9POnTu5txyPpF27dunVV1/VxYsXVaVKFbm4uOj48eP66aef5OLiwgztAAAAdkQ4B26xc+dOLVmyRF5eXurTp4+cnJyUlpZGQMcjad++fWrZsqUKFSqk8PBwdevWTZKUmpoqZ2dnk6sDAAB4fBDOgf+BYI5H3e7du9WtWzdVrFhR7777rkqUKGF2SQAAAI8dwjkAQLt27VK3bt1UrFgxDR06VGXKlDG7JAAAgMcKE8IBAFSpUiVNmDBBf/75p7y9vc0uBwAA4LFDzzkAwCo5OVlubm5mlwEAAPDYIZwDAAAAAGAyhrUDAAAAAGAywjkAAAAAACYjnAMAAAAAYDLCOQAAAAAAJiOcAwDwGLFYLFq6dKnZZQAAgFsQzgEAsLMOHTrIYrGoW7dumdZ1795dFotFHTp0uKd9xcTEyGKx6PLly/fU/s8//1TTpk3vo1oAAGAPhHMAAExQuHBhzZ8/X0lJSdZlycnJmjdvnooUKfLQj3ft2jVJkr+/v1xdXR/6/gEAwD9DOAcAwATPPPOMihQpoiVLlliXLVmyRIULF1alSpWsywzD0OjRo1WsWDG5u7vrqaee0tdffy1JOnHi/9q777CorrwP4N8BZmBgBoYiGZoUKQoqiIgtG8QSkhDL6iqsRMCCvqJYMComCpZogsG6thilmBjFiChqRKOCBSxIERQERIoIhKiIoRnKef/gmRsuDDODdTecz/P4PDK3t/M7555yi+Dq6goA0NbWZtW4jxgxAvPnz0dgYCD09PQwZswYAB2btZeWlsLT0xM6OjrQ0NCAk5MTbty48YaPnqIoiqKo9lTe9Q5QFEVRVHc1ffp0REREwMvLCwAQHh6OGTNmIDExkZln5cqVOHbsGHbv3g0rKytcvnwZn332GXr06IH3338fMTExmDRpEnJzc6GpqQk+n88sGxUVhblz5yIpKQmEkA7br6mpgYuLC4yMjBAXFwexWIy0tDS0tLS88WOnKIqiKIqty4Xz5uZmNDY2vol9oSiKoqhuQVtbG8rKyvD09MTu3btRUFAAAHj48CE8PDyQlZUFTU1NPH36FEePHkVkZCRTm+7p6Yk7d+7g559/xuDBg6GnpwdTU1OIRCJoamoCaG0er6+vj/fffx9r165lttvQ0ABTU1OoqKigoaEBMTExUFNTw5EjRyASiQAAxsbGzLwURVEURb08LpcLZWVlhefnEGmv0qUghKCiokLhAWcoiqIoipLu8ePHaGlpgb6+Pn7//XdwuVwAQGNjI3r06IHKykooKSlBKBSioqICHA6HtTwhBDweDwYGBmhoaMBvv/0GExMTKCn91VutoqICXC4Xurq6rGWLi4vRo0cPqKur48mTJ2hsbIRYLH7zB01RFEVR3ZBIJIJYLO4Qy6VRuOZcUjDX19eHurq6QiunKIqiKKojLpeL5uZmmJqaQldXF+Xl5QAAQ0NDCIVCKCkpQVlZGdra2mhqaoK5uTlUVNghm8PhgMfjoba2lllX+3lUVVVhaGjI+q22thbGxsbQ0tKCmpoa6uvrYW5u/mYPmKIoiqK6GUII6urqUFlZCQAwMDCQu4xChfPm5mamYN7+DTxFURRFUV0jaeKmpqYGVVVVpnCup6cHDocDZWVlKCsrQyQSMS/DtbS0pK6rqamJWVfbwrmSkhJUVFSgpqbWYRkejwc1NTUIhUI8e/YMKioqHQr2FEVRFEW9Gsk4MJWVldDX15fbxF2hSCzpY66urv6Ku0dRFEVRVFscDgd9+/Zl/t+WsrIyxGIxHj58CEIIBAIBWlpaUFNTAyUlJejp6YHH4wEAnj17Bi0tLabWXRE6OjqoqKjA/fv3YWxsDC6Xi7q6OnC5XAgEgtd7oBRFURTVDUnK0I2Nja+ncC5Bm7JTFEVR1OsnK1gbGhpCRUUFFRUVePHiBZSVlaGurs40j+PxeDA0NMSjR49QVFQEXV1dhZupKykpwcrKCqWlpcjPzwchBGpqajA1NX0tx0VRFEVR3V1XytAKDQjX0NCAwsJCmJubS20eR1EURVEURVEURVEUW1fK0koyp1JymZmZYevWrS+9fGRkJPP5GoptxIgRWLRo0bveDeoNedVnh6Ko/30cDgfHjx9/49tJTEwEh8NhfXHm+PHjsLS0hLKyMhYtWkTj8d+Ir68vJkyYwPxN8xPSrV69Gg4ODu96NxhvK19QVFQEDoeDjIwM5rekpCT069cPXC4XEyZMkJpmUNTb8Mqjv5gFnX4d+6GQom/cuzS/r68vnj179kYDf0pKCjQ0NBSa18zMDIsWLWIFCA8PD3zyyScvvf3IyEhMnz6d+VtfXx/Ozs745ptvYGdn99Lr/W9w7Ngx5vNC/5NWSx+86c1tr7pLs/v6+iIqKgpAa5NaQ0NDuLu7Y8OGDdDW1n4Te/hfYfXq1VizZk2H33/99VeMHj36HexR6z4dP36clVF42/pF9Xur28vyyerS/JWVlVi1ahXOnDmD3377Ddra2rC3t8fq1asxdOjQN7SXr1diYiJcXV1RVVXVaSEwJiYGU6ZMQWFhIXr27Nlheu/evfHhhx9i+/btr7Qv0uLR61ZRUYH169fj9OnTePToEfT19eHg4IBFixZh1KhRb2y70gwbNgzl5eWsQfXmzJmD6dOnY8GCBRAKhVBRUXmlePwu5PTu81a31+deTpeXqaiowNdff43Tp0+jtLQUWlpasLKywmeffQZvb++3Mp7Rm8hPKJrHbBtrgdZxHgYNGoSNGzeif//+r3WfZOFwOIiNjWW9tPj8888REBDwVrb//PlzhIaGIiYmBkVFRRCJROjbty/8/f3xz3/+8612nTUxMUF5eTn09PSY3wIDA+Hg4IAzZ85AIBBAXV29Q5rx327n/118q9ubt2dkl+Zvbm7GP/7xDxgYGCAmJob5vbq6Gn379oWPjw+++uorAK2xcOfOnUhPT8eLFy9gYmKC4cOHIyAgAAMGDADQsQykoaEBGxsbfPnll5g4ceJrOELFjBgxAg4ODq/txRKtOX9Fkm/Fviw+nw99ff1X2gdNTU2Ul5ejrKwMp0+fRm1tLdzd3fHnn3++0nrlkQwU+Kbo6OhAKBS+0W10dx999BHKy8tRVFSEffv24eTJk/D393/Xu/XG2dnZoby8nPXvgw8+eKl1vennjGo1adIk3L59G1FRUcjLy0NcXBxGjBiBp0+fvutdU4ii6eW4ceOgq6vLysxLJCUlITc3FzNnznzdu/fSOrv/i4qKMHDgQFy8eBEbN25EVlYW4uPj4erqinnz5r3lvWztl9/2G7M1NTWorKyEm5sb8/m61xGP33Rc/F/z4MEDDBgwAOfOncOGDRuQnp6O8+fPY/HixTh58iTOnz/f6bKv81y+6/yEJNaWl5fjwoULUFFRwaeffvrO9kdCIBC8la8wPXv2DMOGDcOBAwewYsUKpKWl4fLly/Dw8MCyZctQXd21yoVXJRlos+0XKgoKCjBy5EgYGxtDJBJ1SDNeBs0fsCkrKyMqKgrx8fE4ePAg83tAQAB0dHQQHBwMAFi+fDk8PDzg4OCAuLg43L17F3v37kWvXr3wxRdfsNYpKQOVl5cjPT0dbm5umDJlCnJzc9/qsb1O3bpwfunSJTg7O0NVVRUGBgYICgpiPkkDAH/88Qe8vLygoaEBAwMDbNmypUPTqPZNcFavXo2ePXsy35ZdsGABgNa3KsXFxVi8eDE4HA7zsEtrRhcXFwcnJyeoqalBT09P7tsfDocDsVgMAwMDODk5YfHixSguLmbdmMnJyfjggw/A5/NhYmKCBQsWoLa2lpleXl4Od3d38Pl8mJub46effupwbBwOB3v27MH48eOhoaHBvN06efIkBg4cCDU1NVhYWGDNmjWs89jZOQGAXbt2wcrKCmpqanjvvffwr3/9i5nW/lxXVVXB29sb2traUFdXx8cff4z8/HxmuuRcnj17Fn369IFAIGACIiWdqqoqxGIxjI2N8eGHH8LDwwPnzp1jpjc3N2PmzJkwNzcHn8+HjY0Ntm3bxlqHpPlgWFgYDAwMoKuri3nz5rEyVpWVlRg7dixzf7VNlCVKSkowfvx4CAQCaGpqYsqUKfjtt9+Y6ZLmd+Hh4ejZsycEAgHmzp2L5uZmbNy4EWKxGPr6+li/fr3c41ZRUYFYLGb9k4x4nZWVhZEjR4LP50NXVxezZ89GTU1Nh+P9+uuvYWhoCGtrawDAo0eP4OHhAW1tbejq6mL8+PEoKipilktMTISzszM0NDQgEokwfPhwFBcXIzIyEmvWrMHt27eZtCEyMlLuMXQnz549w9WrVxEaGgpXV1eYmprC2dkZK1asgLt7a4sqac0Unz17Bg6Hg8TERAB/NW0+ffo07O3toaamhsGDByMr669afEk6cvz4cVhbW0NNTQ1jxozBw4cPWfu0e/du9OrVCzweDzY2Nvjhhx9Y09unl7NmzYKrqysAQFtbGxwOB76+vh2OlcvlYtq0aYiMjET7IWHCw8MxcOBA2Nvbo7q6GrNnz4a+vj40NTUxcuRI3L59mzV/Z7Gks3gEtNZW2NnZQVVVFWZmZti0aRNrnWZmZvjqq6/g6+sLLS0t+Pn5Sb1m/v7+4HA4uHnzJv71r3/B2toadnZ2CAwMxPXr16UuA7RmyqytraGurg4LCwusWrWKlZbcvn0brq6uEAqF0NTUxMCBA3Hr1i0AQHFxMcaOHQttbW1oaGjAzs4Ov/zyCwB2s/bExESmoDZy5EjmHpEWj+XFt87iItXK398fKioquHXrFqZMmYI+ffqgX79+mDRpEk6fPo2xY8cy80o7l4rEoObmZgQGBkIkEkFXVxfLli3r8Oy0z0/8+eefWLZsGYyMjKChoYHBgwcz6QQgPz+xevVqREVF4cSJE8wz1Hb59iSxViwWw8HBAcuXL8fDhw/x+++/M/PIiz0tLS1Yu3YtjI2NoaqqCgcHB8THx7OOaf78+TAwMICamhrMzMzw9ddfA2h9bgEwNdSSv9s3a1ckniuSX2zviy++QFFREW7cuAEfHx/Y2trC2toafn5+yMjI6PTLEJs3b0a/fv2goaEBExMT+Pv7s86JrGe+qqoKXl5e6NGjB/h8PqysrBAREQGAHS8k/3/y5AlmzJjBxGBpzdrl5aUVTR+7MysrK3z99dcICAhAWVkZTpw4gcOHDyMqKgo8Hg/Xr1/Hxo0bsXnzZmzevBn/+Mc/YG5uDhcXF3z55ZfM9ZWQlIHEYjGsrKzw1VdfQUlJCZmZmcw88soPgPzY11l5xdfXF5cuXcK2bduYtKBt3u9ldNvC+aNHj/DJJ59g0KBBuH37Nnbv3o39+/ezAmtgYCCSkpIQFxeHX3/9FVeuXEFaWlqn6zx69Ci2bNmC7777Dvn5+Th+/Dj69WttKnrs2DEYGxtj7dq1zBseaU6fPo2JEyfC3d0d6enpuHDhApycnBQ+rmfPnuGnn34CAKYJV1ZWFtzc3DBx4kRkZmYiOjoaV69exfz585nlvL29UVZWhsTERMTExGDv3r2orKzssP6QkBCMHz8eWVlZmDFjBs6ePYvPPvsMCxYsQHZ2Nr777jtERkYyBSRZ5+TWrVtYsGAB1q5di9zcXMTHx8usvfT19cWtW7cQFxeHa9eugRCCTz75hBU06urqEBYWhh9++AGXL19GSUkJPv/8c4XPX3f24MEDxMfHs5r+tbS0wNjYGEeOHEF2djaCg4PxxRdf4MiRI6xlExISUFBQgISEBERFRSEyMpJVwPT19UVRUREuXryIo0ePYteuXaz7ixCCCRMm4OnTp7h06RJ+/fVXFBQUwMPDg7WdgoICnDlzBvHx8Th06BDCw8Ph7u6O0tJSXLp0CaGhoVi5cqXMzL8sdXV1+Oijj6CtrY2UlBT8/PPPOH/+POtZAYALFy4gJycHv/76K06dOoW6ujq4urpCIBDg8uXLuHr1KpOZ+/PPP9HU1IQJEybAxcUFmZmZuHbtGmbPng0OhwMPDw8sWbKEVZvf/ri7O4FAAIFAgOPHj+PFixevvL6lS5ciLCwMKSkp0NfXx7hx4zqkI+vXr0dUVBSSkpLw/PlzeHp6MtNjY2OxcOFCLFmyBHfu3GGaRyckJLC20za9XLt2LdOMLzc3F+Xl5R0KGRIzZ87EgwcPcOnSJea32tpaHDlyBDNnzgQhBO7u7qioqMAvv/yC1NRUODo6YtSoUUxLAlmxpLN4lJqaiilTpsDT0xNZWVlYvXo1Vq1a1eFl0bfffou+ffsiNTUVq1at6rD/T58+RXx8PObNmye125esft1CoRCRkZHIzs7Gtm3b8P3332PLli3MdC8vLxgbGyMlJQWpqakICgpi0qx58+bhxYsXuHz5MrKyshAaGio10z9s2DDm5XVMTAzKy8sxbNiwDvPJi28S7eMi1erJkyc4d+5cp/cB0HEE4/bnUpEYtGnTJoSHh2P//v24evUqnj59itjYWJn7Nn36dCQlJeHw4cPIzMzE5MmT8dFHH7Ey7LLyE59//jmmTJnCqhGXdg9JU1NTg4MHD8LS0pKptVYk9mzbtg2bNm1CWFgYMjMz4ebmhnHjxjH7vH37dsTFxeHIkSPIzc3Fjz/+yBTCU1JSAAAREREoLy9n/pZGXjxXNL8o0dLSgsOHD8PLywuGhoYdpgsEAlYNdltKSkrYvn077ty5g6ioKFy8eBHLli1jpst65letWoXs7GycOXMGOTk52L17N6sZu4Skibumpia2bt3aaQxWJC8NyE8fqdaacnt7e3h7e2P27NkIDg5mXhIdOnQIAoGg01acsloyNDc3M63OHB0dmd/llR/kxT5Z5ZVt27Zh6NCh8PPzY9ICExOTVzo/r9zn/H/Vrl27YGJigh07doDD4aB3794oKyvD8uXLERwcjNraWkRFReGnn35i+sZFRERITVgkSkpKIBaLMXr0aHC5XPTs2RPOzs4AWptUKSsrQygUQiwWd7qO9evXw9PTk9Un1t7eXuaxVFdXQyAQgBCCuro6AK1NI3v37g2gNaGYOnUq89bYysoK27dvh4uLC3bv3o2ioiKcP38eKSkpTOZt3759sLKy6rCtqVOnsjIf06ZNQ1BQEHx8fAAAFhYWWLduHZYtW4aQkBCZ56SkpAQaGhr49NNPIRQKYWpqyvQjaS8/Px9xcXFISkpiAuDBgwdhYmKC48ePY/LkyQBam8Ht2bMHvXr1AgDMnz8fa9eulXn+urNTp05BIBCgubkZDQ0NAFrfVEtwuVzWvWhubo7k5GQcOXIEU6ZMYX7X1tbGjh07oKysjN69e8Pd3R0XLlyAn58f8vLycObMGVy/fh2DBw8GAOzfvx99+vzVV/L8+fPIzMxEYWEhk6j98MMPsLOzQ0pKCgYNGgSgNciHh4dDKBTC1tYWrq6uyM3NxS+//AIlJSXY2NggNDQUiYmJGDJkSKfHnZWVxcq029ra4ubNmzh48CDq6+tx4MABJjO5Y8cOjB07FqGhoXjvvfcAtPZr2rdvH1PbHh4eDiUlJezbt48JHBERERCJREhMTISTkxOqq6vx6aefMvdm2+OXZE5kpQ3dmYqKCiIjI+Hn54c9e/bA0dERLi4u8PT0fKk+myEhIRgzZgwAICoqCsbGxoiNjWXu6cbGRuzYsYO5X6OiotCnTx/cvHkTzs7OCAsLg6+vL5N5kNQGh4WFMbXjQMf0srCwEEDr2CCyCqi2trYYPHgwIiIiMGLECADAkSNH0NzcjH//+99ISEhAVlYWKisroaqqCgAICwvD8ePHcfToUcyePVtmLOksHm3evBmjRo1iMpTW1tbIzs7Gt99+y6rlHzlypMyXnvfv3wchhIlBXbFy5Urm/2ZmZliyZAmio6OZDHlJSQmWLl3KrLttnCopKcGkSZOYF8AWFhZSt8Hj8Zjm6zo6Op0+d+vXr5cZ3yTaX2eqleQ+sLGxYf2up6fHxJt58+YhNDSUmSbtXMqLQVu3bsWKFSswadIkAMCePXtw9uzZTveroKAAhw4dQmlpKZOn+/zzzxEfH4+IiAhs2LABgOz8hEAgAJ/Px4sXLxRKtyWxFmh90WZgYIBTp05BSam1jkyR2BMWFobly5czLwpDQ0ORkJCArVu3YufOnSgpKYGVlRXef/99cDgc1ucQe/ToAaD1xZi8/ZUVz+/du6dwflHi8ePHqKqqeqn0oG1rB3Nzc6xbtw5z587Frl27AMh+5ktKSjBgwABmPyUvKtqTNHHncDjQ0tLq9PzIy0tLRuCWlz5SrQXs3bt3My1pgoKCmGl5eXmwsLBgvbDZvHkz0+QdaK1glYwFICkDAUB9fT24XC7TBB5QrPwgL/bJKq9oaWmBx+NBXV39teXhum3NeU5ODoYOHcp6AzN8+HDU1NSgtLQUDx48QGNjI1OQBFovQPsg09bkyZNRX18PCwsL+Pn5ITY2ltX8TREZGRldHihHKBQiIyMDqampTCDZs2cPMz01NRWRkZFM7ZNAIICbmxtaWlpQWFiI3NxcqKiosN4yWVpaSh0UrH0tfmpqKtauXctat+TtUV1dncxzMmbMGJiamsLCwgLTpk3DwYMHmZcL7eXk5EBFRYXJLAOArq4ubGxskJPz1wA16urqzAMJAAYGBjLf6HZ3rq6uyMjIwI0bNxAQEAA3N7cOg8Ps2bMHTk5O6NGjBwQCAb7//nuUlJSw5rGzs2N9p7nteZdcu7b3Tu/evVmFk5ycHJiYmLDeNtra2kIkErGur5mZGavf4HvvvQdbW1smgyP5Td41t7GxQUZGBvNPUqOZk5MDe3t7Vi3P8OHD0dLSwuom0q9fP6ZgDrQ+B/fv34dQKGSeAx0dHTQ0NKCgoAA6Ojrw9fWFm5sbxo4di23bttHuFl00adIklJWVIS4uDm5ubkhMTISjo+NLdQFoO4Ccjo5Oh3Sks/tVMk9OTg6GDx/OWufw4cNZ6wA6ppddMXPmTBw9ehR//PEHgNYXQBMnToRIJEJqaipqamqgq6vLSnsLCwtRUFAA4OViSWfHlZ+fj+bmZoWPS9Kk+GX6ah49ehTvv/8+xGIxBAIBVq1axUpvAgMDMWvWLIwePRrffPMNc7wAsGDBAnz11VcYPnw4QkJCWM0aX4a8+CbxKte5O2h/H9y8eRMZGRmws7Pr0BJG2rmUFYOqq6tRXl7OeqbbP7/tpaWlgRACa2tr1rW9dOkS6356nfkJSayVxNsPP/wQH3/8MYqLiwHIjz3Pnz9HWVmZzHTH19cXGRkZsLGxwYIFC1hd1LpCVjzvSn5R4lXSg4SEBIwZMwZGRkYQCoXw9vbGkydPmKbksp75uXPn4vDhw3BwcMCyZcuQnJzc5e23JS8vLUHTA8WEh4dDXV0dhYWFKC0tZU1rf6/MmDEDGRkZ+O6771BbW8vqtiIpA2VkZCA9PR0bNmzAnDlzcPLkSQCKlR/kxb6ulFdeh25bOCeEdLj4bROQzhITWZ+FNzExQW5uLnbu3Ak+nw9/f3988MEHXRrUhM/nKzyvhJKSEiwtLdG7d2/MmTMH06ZNYzXJaWlpwZw5c1iFkdu3byM/Px+9evXq9Jik/d6+aVpLSwvWrFnDWndWVhby8/OhpqYm85wIhUKkpaXh0KFDMDAwQHBwMOzt7aV+tkLWPra9Ru1HY217LamONDQ0YGlpif79+2P79u148eIFq5biyJEjWLx4MWbMmIFz584hIyMD06dP7zDIibTz3tLSAkCxwCzteZT2u7TtyNp2Z3g8HiwtLZl/kpcCne1H+/2X9hwMHDiQ9RxkZGQgLy8PU6dOBdBak37t2jUMGzYM0dHRsLa2funm992VpP93cHAwkpOT4evry9RgSl7QtH3eu5L2tr/u0u6Dtr9Jiw3tf1P0Sx7SeHp6gsPhIDo6Gvfv38fVq1eZgeBaWlpgYGDQ4X7Lzc3F0qVLAbxcLJEVF9uSd1xWVlbgcDgdXlbIc/36dXh6euLjjz/GqVOnkJ6eji+//JKV3qxevRp3796Fu7s7Ll68CFtbW6YJ86xZs/DgwQNMmzYNWVlZcHJywn/+858u7UNb8uKbxKtc578zS0tLcDgc3Lt3j/W7hYUFLC0tpd6j7c+lojGoK1paWqCsrIzU1FTWtc3JyWF1NXmd+QlJrLW0tISzszP279+P2tpafP/99wAUjz2y0h1HR0cUFhZi3bp1qK+vx5QpU1jj+ChKkXjenqzz0qNHD2hra3c5PSguLsYnn3yCvn37IiYmBqmpqdi5cyeAv9J2Wc+85OXHokWLUFZWhlGjRr1Sjba8vLQETQ/ku3btGrZs2YITJ05g6NChTHctoDV+FBQUsOK3SCSCpaUljIyMOqxLUgaS5GUDAwPh6urKtMhRpPwgL/Z1pbzyOnTbwrmtrS2Sk5NZJz85ORlCoRBGRkbo1asXuFwubt68yUx//vx5hwEE2uPz+Rg3bhy2b9+OxMREXLt2jRlsiMfjsWofpOnfvz8uXLjwCkcGLF68GLdv32YyLI6Ojrh79y6rMCL5x+Px0Lt3bzQ1NSE9PZ1Zx/379xW66RwdHZGbmyt13ZLMsqxzoqKigtGjR2Pjxo3IzMxk+iW3Z2tri6amJty4cYP57cmTJ8jLy2M1D6ZeTUhICMLCwlBWVgYAuHLlCoYNGwZ/f38MGDAAlpaWrJoFRfTp0wdNTU3MoE1A69v3tveXra0tSkpKWINuZWdno7q6+q1eX1tbW2RkZLAGeElKSoKSkhIz8Js0jo6OyM/Ph76+fofnoO1nWAYMGIAVK1YgOTkZffv2ZcaHUCRtoDqytbVlrpWk2WbbFgmdfZqu7UuRqqoq5OXlsZpcdna/Subp06cPrl69ylpncnKy3HtV0tpCkWstFAoxefJkREREIDw8HBYWFkwTd0dHR1RUVEBFRaXD/SbpUykvlki752xtbaUel7W1NasmTR4dHR24ublh586drGdJorPYkpSUBFNTU3z55ZdwcnKClZUVU7PYlrW1NRYvXoxz585h4sSJzCBPQOtL8v/7v//DsWPHsGTJEqbw8zIUiW9U53R1dTFmzBjs2LFD6n2gCHkxSEtLCwYGBqxnuqmpCampqZ2uc8CAAWhubkZlZWWH69qVZqmvkm5zOBwoKSmhvr4egPzYo6mpCUNDQ7npjqamJjw8PPD9998jOjoaMTExzDgUXC73lePMy+QXlZSU4OHhgYMHDzJ5i7Zqa2ultjK9desWmpqasGnTJgwZMgTW1tZSl5f1zPfo0QO+vr748ccfsXXrVuzdu7eLR/wXeXlpSjH19fXw8fHBnDlzMHr0aOzbtw8pKSn47rvvAAD//ve/UVNTw3RdeBnKysqsZ0te+UGR2CervPK683B/++hSXV3doXahpKQE/v7+ePjwIQICAnDv3j2cOHECISEhCAwMhJKSEoRCIXx8fLB06VIkJCTg7t27mDFjBpSUlDp9uxkZGYn9+/fjzp07ePDgAX744Qfw+Xym34+ZmRkuX76MR48e4fHjx1LXERISgkOHDiEkJAQ5OTnIysrCxo0bu3TMmpqamDVrFkJCQkAIwfLly3Ht2jXMmzcPGRkZTP8LSfPl3r17Y/To0Zg9ezZu3ryJ9PR0zJ49G3w+X24zpODgYBw4cICpzcjJyUF0dDTTb1DWOTl16hS2b9+OjIwMFBcX48CBA2hpaZHadcDKygrjx4+Hn58frl69itu3b+Ozzz6DkZERxo8f36XzQ3VuxIgRsLOzY/rcWVpa4tatWzh79izy8vKwatUqmQPJSGNjY4OPPvoIfn5+uHHjBlJTUzFr1ixWrcno0aPRv39/eHl5IS0tDTdv3oS3tzdcXFzeahMxLy8vqKmpwcfHB3fu3EFCQgICAgIwbdo0pr95Z8vp6elh/PjxuHLlCgoLC3Hp0iUsXLgQpaWlKCwsxIoVK3Dt2jUUFxfj3LlzrMBgZmaGwsJCZGRk4PHjx69l0LO/kydPnmDkyJH48ccfmbEJfv75Z2zcuJF5/vl8PoYMGYJvvvkG2dnZuHz5Mqv/cltr167FhQsXcOfOHfj6+kJPT4/17V8ul4uAgADcuHEDaWlpmD59OoYMGcJ0c1q6dCkiIyOxZ88e5OfnY/PmzTh27JjcWhlTU1NwOBycOnUKv//+O2vUYWlmzpyJ5ORk7N69mxlFGGh9XoYOHYoJEybg7NmzKCoqQnJyMlauXMm8VJAXS6TFoyVLluDChQtYt24d8vLyEBUVhR07drxUbdOuXbvQ3NwMZ2dnxMTEID8/Hzk5Odi+fXun36W3tLRESUkJDh8+jIKCAmzfvp01sFd9fT3mz5+PxMREFBcXIykpCSkpKcxztGjRIpw9exaFhYVIS0vDxYsXX+nlnrz4Rsm3a9cuNDU1wcnJCdHR0cjJyWEGK7t3757clz6KxKCFCxfim2++QWxsLO7duwd/f3+ZhUVra2t4eXnB29sbx44dQ2FhIVJSUhAaGtphJGhZzMzMkJmZidzcXDx+/FhmS50XL16goqICFRUVyMnJQUBAAGpqapjR6hWJPUuXLkVoaCiio6ORm5uLoKAgZGRkYOHChQCALVu24PDhw7h37x7y8vLw888/QywWM13IzMzMcOHCBVRUVKCqqkrh42zrZfOLGzZsgImJCQYPHowDBw4gOzsb+fn5CA8Ph4ODg9S0sFevXmhqasJ//vMfJv/YtssmIPuZDw4OxokTJ3D//n3cvXsXp06deqX0QF5emlJMUFAQWlpamJrtnj17YtOmTVi6dCmKioowdOhQLFmyBEuWLEFgYCCuXr2K4uJiXL9+Hfv372debEkQQphnq7CwEHv37sXZs2eZvIEi5Qd5sU9eecXMzAw3btxAUVERHj9+LLf1plxEAfX19SQ7O5vU19crMvt/DR8fHwKgwz8fHx9CCCGJiYlk0KBBhMfjEbFYTJYvX04aGxuZ5Z8/f06mTp1K1NXViVgsJps3bybOzs4kKCiImcfU1JRs2bKFEEJIbGwsGTx4MNHU1CQaGhpkyJAh5Pz588y8165dI/379yeqqqpEcuojIiKIlpYWa79jYmKIg4MD4fF4RE9Pj0ycOLHTY5S2PCGEFBcXExUVFRIdHU0IIeTmzZtkzJgxRCAQEA0NDdK/f3+yfv16Zv6ysjLy8ccfE1VVVWJqakp++uknoq+vT/bs2cPMA4DExsZ22FZ8fDwZNmwY4fP5RFNTkzg7O5O9e/fKPSdXrlwhLi4uRFtbm/D5fNK/f39mfwkhxMXFhSxcuJD5++nTp2TatGlES0uL8Pl84ubmRvLy8mSei9jYWKLgbd7t+Pj4kPHjx3f4/eDBg4TH45GSkhLS0NBAfH19iZaWFhGJRGTu3LkkKCiI2Nvby1zPwoULiYuLC/N3eXk5cXd3J6qqqqRnz57kwIEDrGeHkNZ7dty4cURDQ4MIhUIyefJkUlFRwUwPCQlhbbezbbe/b9qTtp62MjMziaurK1FTUyM6OjrEz8+P/PHHHzK3KTlGb29voqenR1RVVYmFhQXx8/Mj1dXVpKKigkyYMIEYGBgQHo9HTE1NSXBwMGlubiaEENLQ0EAmTZpERCIRAUAiIiI63b/uqKGhgQQFBRFHR0eipaVF1NXViY2NDVm5ciWpq6tj5svOziZDhgwhfD6fODg4kHPnzhEAJCEhgRBCSEJCAgFATp48Sezs7AiPxyODBg0iGRkZzDok6UhMTAyxsLAgPB6PjBw5khQVFbH2adeuXcTCwoJwuVxibW1NDhw4wJreWXq5du1aIhaLCYfDYWKRLDY2NkRJSYk8fPiQ9fvz589JQEAAMTQ0JFwul5iYmBAvLy9SUlLCzCMrlkiLR4QQcvToUWJra0u4XC7p2bMn+fbbb1nbbf/cylJWVkbmzZtHTE1NCY/HI0ZGRmTcuHHM9SCk43launQp0dXVJQKBgHh4eJAtW7Yw6fqLFy+Ip6cnMTExITwejxgaGpL58+czeZP58+eTXr16EVVVVdKjRw8ybdo08vjxY0LIX9e+qqqKEEJIVVUV694gRHoMkRXfpO0/1VFZWRmZP38+MTc3J1wulwgEAuLs7Ey+/fZbUltby8wn7VwqEoMaGxvJwoULiaamJhGJRCQwMJB4e3uz0un2ceHPP/8kwcHBxMzMjHC5XCIWi8k///lPkpmZSQhRLD9RWVnJ5Kva30tttc+LCoVCMmjQIHL06FHWfPJiT3NzM1mzZg0xMjIiXC6X2NvbkzNnzjDT9+7dSxwcHIiGhgbR1NQko0aNImlpacz0uLg4YmlpSVRUVIipqSkhpGM8VCSeK5JflObZs2ckKCiIWFlZER6PR9577z0yevRoEhsbS1paWgghHdOXzZs3EwMDAybPd+DAAdZzLOuZX7duHenTpw/h8/lER0eHjB8/njx48IAQQkhhYSEBQNLT05ltaWlpsWJv+zSDEPl56a6kj91RYmIiUVZWJleuXOkw7cMPPyQjR45k7oXo6GgyYsQIoqWlRbhcLjE2NiZTp04l169fZ5aJiIhgPVuqqqrE2tqarF+/njQ1NTHzySs/ECI79skrr+Tm5jJ5DwCksLCww/F1pSzNIUR+B5qGhgYUFhbC3Nyc1c+qu6mtrYWRkRE2bdrE9P37uyotLYWJiQnOnz/f5UGFKIqi/hslJibC1dUVVVVVnY6WHhkZiUWLFr2xvmQURVF/JzS/SFHydaUs3W0/paaI9PR03Lt3D87OzqiurmY+ofF3bEZ98eJF1NTUoF+/figvL8eyZctgZmYm87vjFEVRFEVRVPdB84sU9WbRwrkcYWFhyM3NBY/Hw8CBA3HlyhVmwJ2/k8bGRnzxxRd48OABhEIhhg0bhoMHD3YYtZOiKIqiKIrqnmh+kaLeLNqsnaIoiqIoiqIoiqLegK6Upf/2o7VTFEVRFEVRFEVR1H+7LhXOFahkpyiKoiiKoiiKoigKXStDK1Q4l/Qjqaure7k9oiiKoiiKoiiKoqhuRlKGVmRsBoUGhFNWVoZIJEJlZSUAQF1dHRwO5xV2kaIoiqIoiqIoiqL+ngghqKurQ2VlJUQiEZSVleUuo9CAcJKVV1RU0G+/UhRFURRFURRFUZQCRCIRxGKxQpXbChfOJZqbm9HY2PjSO0dRFEVRFEVRFEVRf3dcLlehGnOJLhfOKYqiKIqiKIqiKIp6vein1CiKoiiKoiiKoijqHaOFc4qiKIqiKIqiKIp6x2jhnKIoiqIoiqIoiqLeMVo4pyiKoiiKoiiKoqh3jBbOKYqiKIqiKIqiKOodo4VziqIoiqIoiqIoinrHaOGcoiiKoiiKoiiKot6x/wf4Pu71G7RsAgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Create a list of model names\n",
    "models = merged_df['Classifier'].tolist()\n",
    "\n",
    "# Extract the cross-validation scores for each metric\n",
    "cv_scores = merged_df[['test_accuracy', 'test_precision', 'test_recall', 'test_f1']].values\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set the bar width and positions\n",
    "bar_width = 0.15\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "# Loop through each model and create a bar for each metric\n",
    "for i, model in enumerate(models):\n",
    "    ax.bar(r + i * bar_width, cv_scores[i] * 100, bar_width, label=model)\n",
    "    for j, score in enumerate(cv_scores[i]):\n",
    "        ax.text(r[j] + i * bar_width, score * 100 + 1, '{:.2f}'.format(score * 100), ha='center', fontsize=6)\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks(r + bar_width * 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Score (%)')\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Metric')\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the y-axis limits\n",
    "ax.set_ylim(40, 75)  # Adjust the limits as needed\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Test Scores for Baseline Models')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of comparison of the 4 metrics for the 5 baseline models:\n",
    "- Accuracy:\n",
    "In terms of accuracy, Logistic Regression performs the best with a score of around 72.28%, followed by Support Vector Classifier at around 71.19%. Random Forest and XGBoost have lower accuracy scores at 65.41% and 65.54% respectively.\n",
    "\n",
    "- Precision:\n",
    "For precision, the scores are the lowest for all 4 models compared to other metrics. Logistic Regression achieves the highest score of around 58.20%, closely followed by Support Vector Classifier at around 56.60%. Random Forest and XGBoost have lower precision scores of around 49.37% and 49.48%, respectively.\n",
    "\n",
    "- Recall:\n",
    "In terms of recall, the scores do not differ greatly among the models. Random Forest performs the best with a score of around 67.76%, followed by Gradient Boosting Classifier at around 66.58%.\n",
    "\n",
    "- F1 Score:\n",
    "The F1 scores, which combine precision and recall is the next lower score after precision. Logistic Regression is the top performer with a score of around 61.62%, followed by Support Vector Classifier at around 60.68%. Random Forest and XGBoost have lower F1 scores of around 57.12% and 56.30%, respectively.\n",
    "\n",
    "Overall, Logistic Regression and Support Vector Classifier appear to be the strongest performers on the test set, with Logistic Regression having slightly higher scores in accuracy, and F1, while Support Vector Classifier leads in recall.\n",
    "\n",
    "It's important to note that the test scores are generally lower than the training scores, which is expected due to the potential overfitting of the models on the training data. The drop in performance from training to test sets highlights the importance of evaluating models on unseen data to assess their generalization capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
